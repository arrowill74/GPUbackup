{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN in keras with pretrained word2vec weights\n",
    "https://www.kaggle.com/marijakekic/cnn-in-keras-with-pretrained-word2vec-weights/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def writeProgress(msg, count, total):\n",
    "    sys.stdout.write(msg + \"{:.2%}\\r\".format(count/total))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "def read_json(src_path):\n",
    "    with open(src_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "\n",
    "def write_json(data,dst_path):\n",
    "    with open(dst_path, 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery', 'Romance', 'Sci-Fi', 'Sport', 'Thriller', 'War', 'Western']\n"
     ]
    }
   ],
   "source": [
    "columns = read_json('../orderedListGenres.json')\n",
    "print(len(columns), columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1631\n"
     ]
    }
   ],
   "source": [
    "data = read_json('./input/mergeGenresMat.json')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>convert_text</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21bridgesmovie</td>\n",
       "      <td>chadwickboseman bringing bridges alma mater ho...</td>\n",
       "      <td>['Action', 'Crime', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21bridgesmovie</td>\n",
       "      <td>politics jk simmons captain mckenna bridges th...</td>\n",
       "      <td>['Action', 'Crime', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21bridgesmovie</td>\n",
       "      <td>thrilling score music bridges composed henry j...</td>\n",
       "      <td>['Action', 'Crime', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21bridgesmovie</td>\n",
       "      <td>experience manhunt century see bridges playing...</td>\n",
       "      <td>['Action', 'Crime', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21bridgesmovie</td>\n",
       "      <td>discover truth bridges starring chadwickbosema...</td>\n",
       "      <td>['Action', 'Crime', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30636</th>\n",
       "      <td>zombieland</td>\n",
       "      <td>got ta look real close one use zombieland skil...</td>\n",
       "      <td>['Action', 'Comedy', 'Horror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30637</th>\n",
       "      <td>zombieland</td>\n",
       "      <td>actually lit zombieland artist dinotomic</td>\n",
       "      <td>['Action', 'Comedy', 'Horror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30638</th>\n",
       "      <td>zombieland</td>\n",
       "      <td>horror comedy cast else could ask zombieland p...</td>\n",
       "      <td>['Action', 'Comedy', 'Horror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30639</th>\n",
       "      <td>zombieland</td>\n",
       "      <td>said like actually said wrong zombieland playing</td>\n",
       "      <td>['Action', 'Comedy', 'Horror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30640</th>\n",
       "      <td>zombieland</td>\n",
       "      <td>getting leg cramp zland actually killer make s...</td>\n",
       "      <td>['Action', 'Comedy', 'Horror']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30641 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             username                                       convert_text  \\\n",
       "0      21bridgesmovie  chadwickboseman bringing bridges alma mater ho...   \n",
       "1      21bridgesmovie  politics jk simmons captain mckenna bridges th...   \n",
       "2      21bridgesmovie  thrilling score music bridges composed henry j...   \n",
       "3      21bridgesmovie  experience manhunt century see bridges playing...   \n",
       "4      21bridgesmovie  discover truth bridges starring chadwickbosema...   \n",
       "...               ...                                                ...   \n",
       "30636      zombieland  got ta look real close one use zombieland skil...   \n",
       "30637      zombieland           actually lit zombieland artist dinotomic   \n",
       "30638      zombieland  horror comedy cast else could ask zombieland p...   \n",
       "30639      zombieland   said like actually said wrong zombieland playing   \n",
       "30640      zombieland  getting leg cramp zland actually killer make s...   \n",
       "\n",
       "                               genres  \n",
       "0        ['Action', 'Crime', 'Drama']  \n",
       "1        ['Action', 'Crime', 'Drama']  \n",
       "2        ['Action', 'Crime', 'Drama']  \n",
       "3        ['Action', 'Crime', 'Drama']  \n",
       "4        ['Action', 'Crime', 'Drama']  \n",
       "...                               ...  \n",
       "30636  ['Action', 'Comedy', 'Horror']  \n",
       "30637  ['Action', 'Comedy', 'Horror']  \n",
       "30638  ['Action', 'Comedy', 'Horror']  \n",
       "30639  ['Action', 'Comedy', 'Horror']  \n",
       "30640  ['Action', 'Comedy', 'Horror']  \n",
       "\n",
       "[30641 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_IG=pd.read_csv('./stopword/train_IG.csv')\n",
    "train_data_IG = train_data_IG.dropna()\n",
    "train_data_IG = train_data_IG.reset_index(drop=True)\n",
    "train_data_IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>convert_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21bridgesmovie</td>\n",
       "      <td>embattled nypd detective thrust citywide manhu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47metersdown</td>\n",
       "      <td>four teen girls diving ruined underwater city ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abeautifuldaymovie</td>\n",
       "      <td>based true story reallife friendship fred roge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abominablemovie</td>\n",
       "      <td>three teenagers must help yeti return family a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adastramovie</td>\n",
       "      <td>astronaut roy mcbride undertakes mission acros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>wrinklestheclown</td>\n",
       "      <td>florida parents hire wrinkles clown scare misb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>xmenmovies</td>\n",
       "      <td>jean grey begins develop incredible powers cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>yardiefilm</td>\n",
       "      <td>british crime drama film directed idris elba b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>yesterdaymovie</td>\n",
       "      <td>struggling musician realizes person earth reme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>zombieland</td>\n",
       "      <td>columbus tallahassee wichita little rock move ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               username                                       convert_text\n",
       "0        21bridgesmovie  embattled nypd detective thrust citywide manhu...\n",
       "1          47metersdown  four teen girls diving ruined underwater city ...\n",
       "2    abeautifuldaymovie  based true story reallife friendship fred roge...\n",
       "3       abominablemovie  three teenagers must help yeti return family a...\n",
       "4          adastramovie  astronaut roy mcbride undertakes mission acros...\n",
       "..                  ...                                                ...\n",
       "160    wrinklestheclown  florida parents hire wrinkles clown scare misb...\n",
       "161          xmenmovies  jean grey begins develop incredible powers cor...\n",
       "162          yardiefilm  british crime drama film directed idris elba b...\n",
       "163      yesterdaymovie  struggling musician realizes person earth reme...\n",
       "164          zombieland  columbus tallahassee wichita little rock move ...\n",
       "\n",
       "[165 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('./stopword/test_imdb.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>convert_text</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21bridgesmovie</td>\n",
       "      <td>chadwickboseman bringing bridges alma mater ho...</td>\n",
       "      <td>['Action', 'Crime', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21bridgesmovie</td>\n",
       "      <td>politics jk simmons captain mckenna bridges th...</td>\n",
       "      <td>['Action', 'Crime', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21bridgesmovie</td>\n",
       "      <td>thrilling score music bridges composed henry j...</td>\n",
       "      <td>['Action', 'Crime', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21bridgesmovie</td>\n",
       "      <td>experience manhunt century see bridges playing...</td>\n",
       "      <td>['Action', 'Crime', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21bridgesmovie</td>\n",
       "      <td>discover truth bridges starring chadwickbosema...</td>\n",
       "      <td>['Action', 'Crime', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30801</th>\n",
       "      <td>wrinklestheclown</td>\n",
       "      <td>florida parents hire wrinkles clown scare misb...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30802</th>\n",
       "      <td>xmenmovies</td>\n",
       "      <td>jean grey begins develop incredible powers cor...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30803</th>\n",
       "      <td>yardiefilm</td>\n",
       "      <td>british crime drama film directed idris elba b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30804</th>\n",
       "      <td>yesterdaymovie</td>\n",
       "      <td>struggling musician realizes person earth reme...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30805</th>\n",
       "      <td>zombieland</td>\n",
       "      <td>columbus tallahassee wichita little rock move ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30806 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               username                                       convert_text  \\\n",
       "0        21bridgesmovie  chadwickboseman bringing bridges alma mater ho...   \n",
       "1        21bridgesmovie  politics jk simmons captain mckenna bridges th...   \n",
       "2        21bridgesmovie  thrilling score music bridges composed henry j...   \n",
       "3        21bridgesmovie  experience manhunt century see bridges playing...   \n",
       "4        21bridgesmovie  discover truth bridges starring chadwickbosema...   \n",
       "...                 ...                                                ...   \n",
       "30801  wrinklestheclown  florida parents hire wrinkles clown scare misb...   \n",
       "30802        xmenmovies  jean grey begins develop incredible powers cor...   \n",
       "30803        yardiefilm  british crime drama film directed idris elba b...   \n",
       "30804    yesterdaymovie  struggling musician realizes person earth reme...   \n",
       "30805        zombieland  columbus tallahassee wichita little rock move ...   \n",
       "\n",
       "                             genres  \n",
       "0      ['Action', 'Crime', 'Drama']  \n",
       "1      ['Action', 'Crime', 'Drama']  \n",
       "2      ['Action', 'Crime', 'Drama']  \n",
       "3      ['Action', 'Crime', 'Drama']  \n",
       "4      ['Action', 'Crime', 'Drama']  \n",
       "...                             ...  \n",
       "30801                           NaN  \n",
       "30802                           NaN  \n",
       "30803                           NaN  \n",
       "30804                           NaN  \n",
       "30805                           NaN  \n",
       "\n",
       "[30806 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_data_IG, test_data],ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>convert_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21bridgesmovie</td>\n",
       "      <td>chadwickboseman bringing bridges alma mater ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47metersdown</td>\n",
       "      <td>sharks hungry meters uncaged hits theaters aug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abeautifuldaymovie</td>\n",
       "      <td>two weeks take trip back neighborhood beautifu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abominablemovie</td>\n",
       "      <td>abominable movie loved one wish list get digit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adastramovie</td>\n",
       "      <td>photographer stephenwilkes photo shoot natgeo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>wrinklestheclown</td>\n",
       "      <td>tag someone deserves visit wrinkles wrinkles c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>xmenmovies</td>\n",
       "      <td>darkphoenix fanartfriday fameart xmen director...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>yardiefilm</td>\n",
       "      <td>shoutout amlameenbaby sbtvonline pull yardie y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>yesterdaymovie</td>\n",
       "      <td>feelgood movie summer yesterday movie theaters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>zombieland</td>\n",
       "      <td>omg like totally zoeydeutch birthday today hap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               username                                       convert_text\n",
       "0        21bridgesmovie  chadwickboseman bringing bridges alma mater ho...\n",
       "1          47metersdown  sharks hungry meters uncaged hits theaters aug...\n",
       "2    abeautifuldaymovie  two weeks take trip back neighborhood beautifu...\n",
       "3       abominablemovie  abominable movie loved one wish list get digit...\n",
       "4          adastramovie  photographer stephenwilkes photo shoot natgeo ...\n",
       "..                  ...                                                ...\n",
       "160    wrinklestheclown  tag someone deserves visit wrinkles wrinkles c...\n",
       "161          xmenmovies  darkphoenix fanartfriday fameart xmen director...\n",
       "162          yardiefilm  shoutout amlameenbaby sbtvonline pull yardie y...\n",
       "163      yesterdaymovie  feelgood movie summer yesterday movie theaters...\n",
       "164          zombieland  omg like totally zoeydeutch birthday today hap...\n",
       "\n",
       "[165 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat = df.groupby(['username'])['convert_text'].apply(' '.join).reset_index()\n",
    "concat.to_csv('./concatUsername.csv')\n",
    "concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 2)\n",
      "username        0\n",
      "convert_text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(concat.shape)\n",
    "print(concat.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 165\n"
     ]
    }
   ],
   "source": [
    "ids = concat['username'].tolist()\n",
    "texts = concat['convert_text'].tolist()\n",
    "print(len(ids), len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [data[id] for id in ids]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30968 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS=30000\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS,filters='—!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'',\n",
    "                      lower=True)\n",
    "\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username                                           spidermanmovie\n",
       "convert_text    wait amazing spiderman theaters today see imax...\n",
       "Name: 127, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 127\n",
    "concat.iloc[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7488 7488\n",
      "1937\n"
     ]
    }
   ],
   "source": [
    "wordstring = concat.iloc[idx, :].convert_text\n",
    "wordlist = wordstring.split()\n",
    "wordfreq = [wordlist.count(w) for w in wordlist] # a list comprehension\n",
    "print(len(wordlist), len(wordfreq))\n",
    "freq_dic = dict(zip(wordlist, wordfreq))\n",
    "print(len(freq_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spiderman', 330),\n",
       " ('spidermanhomecoming', 185),\n",
       " ('amazing', 169),\n",
       " ('regram', 144),\n",
       " ('link', 109),\n",
       " ('bio', 109),\n",
       " ('spidermanfarfromhome', 82),\n",
       " ('see', 75),\n",
       " ('andrew', 71),\n",
       " ('garfield', 68),\n",
       " ('today', 63),\n",
       " ('get', 59),\n",
       " ('spidey', 59),\n",
       " ('premiere', 55),\n",
       " ('emma', 47),\n",
       " ('spideysighting', 47),\n",
       " ('tomholland', 45),\n",
       " ('stone', 45),\n",
       " ('watch', 45),\n",
       " ('tix', 42),\n",
       " ('digital', 42),\n",
       " ('new', 40),\n",
       " ('iamjamiefoxx', 39),\n",
       " ('peter', 37),\n",
       " ('world', 35),\n",
       " ('theaters', 34),\n",
       " ('day', 32),\n",
       " ('cast', 30),\n",
       " ('movie', 30),\n",
       " ('amazingspiderman', 29),\n",
       " ('latergram', 29),\n",
       " ('days', 29),\n",
       " ('weekend', 29),\n",
       " ('bluray', 29),\n",
       " ('one', 28),\n",
       " ('trailer', 27),\n",
       " ('tonight', 26),\n",
       " ('make', 26),\n",
       " ('fan', 26),\n",
       " ('look', 25),\n",
       " ('us', 24),\n",
       " ('tickets', 24),\n",
       " ('beamazing', 24),\n",
       " ('tomorrow', 23),\n",
       " ('spiderfans', 23),\n",
       " ('parker', 23),\n",
       " ('happy', 23),\n",
       " ('love', 23),\n",
       " ('danedehaan', 23),\n",
       " ('check', 22),\n",
       " ('nyc', 22),\n",
       " ('time', 22),\n",
       " ('nt', 22),\n",
       " ('photo', 22),\n",
       " ('theamazingspiderman', 21),\n",
       " ('thanks', 21),\n",
       " ('gwen', 21),\n",
       " ('imax', 20),\n",
       " ('zendaya', 20),\n",
       " ('back', 20),\n",
       " ('goodmorningamerica', 20),\n",
       " ('red', 20),\n",
       " ('carpet', 20),\n",
       " ('school', 19),\n",
       " ('hero', 19),\n",
       " ('best', 19),\n",
       " ('special', 18),\n",
       " ('week', 18),\n",
       " ('go', 18),\n",
       " ('may', 18),\n",
       " ('press', 17),\n",
       " ('miss', 17),\n",
       " ('favorite', 17),\n",
       " ('hd', 17),\n",
       " ('electro', 16),\n",
       " ('like', 16),\n",
       " ('ultra', 16),\n",
       " ('film', 15),\n",
       " ('experience', 15),\n",
       " ('find', 15),\n",
       " ('first', 15),\n",
       " ('london', 15),\n",
       " ('take', 15),\n",
       " ('marc', 15),\n",
       " ('great', 15),\n",
       " ('worldwide', 14),\n",
       " ('head', 14),\n",
       " ('ready', 14),\n",
       " ('suit', 14),\n",
       " ('dailybugle', 14),\n",
       " ('art', 14),\n",
       " ('tom', 14),\n",
       " ('man', 14),\n",
       " ('home', 14),\n",
       " ('stacy', 14),\n",
       " ('night', 13),\n",
       " ('big', 13),\n",
       " ('queens', 13),\n",
       " ('exclusive', 13),\n",
       " ('beijing', 13),\n",
       " ('swings', 13),\n",
       " ('share', 13),\n",
       " ('webb', 13),\n",
       " ('catch', 12),\n",
       " ('end', 12),\n",
       " ('battle', 12),\n",
       " ('swinging', 12),\n",
       " ('sure', 12),\n",
       " ('answer', 12),\n",
       " ('superhero', 12),\n",
       " ('everyone', 12),\n",
       " ('event', 12),\n",
       " ('birthday', 12),\n",
       " ('fans', 12),\n",
       " ('selfie', 12),\n",
       " ('chance', 12),\n",
       " ('super', 12),\n",
       " ('heroes', 11),\n",
       " ('gmazing', 11),\n",
       " ('enter', 11),\n",
       " ('two', 11),\n",
       " ('pm', 11),\n",
       " ('sharing', 11),\n",
       " ('getspiderman', 11),\n",
       " ('way', 11),\n",
       " ('july', 11),\n",
       " ('gwensday', 11),\n",
       " ('lauraharrier', 10),\n",
       " ('instagram', 10),\n",
       " ('visit', 10),\n",
       " ('click', 10),\n",
       " ('director', 10),\n",
       " ('year', 10),\n",
       " ('action', 10),\n",
       " ('reports', 10),\n",
       " ('know', 10),\n",
       " ('playing', 10),\n",
       " ('high', 10),\n",
       " ('nycservice', 10),\n",
       " ('available', 10),\n",
       " ('got', 10),\n",
       " ('would', 10),\n",
       " ('yet', 10),\n",
       " ('little', 10),\n",
       " ('neighborhood', 10),\n",
       " ('greatest', 10),\n",
       " ('join', 10),\n",
       " ('featured', 10),\n",
       " ('live', 10),\n",
       " ('wait', 9),\n",
       " ('even', 9),\n",
       " ('lifeisaloha', 9),\n",
       " ('story', 9),\n",
       " ('team', 9),\n",
       " ('spiderfan', 9),\n",
       " ('want', 9),\n",
       " ('oscorp', 9),\n",
       " ('throughthewebb', 9),\n",
       " ('weeks', 9),\n",
       " ('tuesday', 9),\n",
       " ('start', 9),\n",
       " ('via', 9),\n",
       " ('tune', 9),\n",
       " ('could', 9),\n",
       " ('pharrell', 9),\n",
       " ('homecoming', 9),\n",
       " ('spider', 9),\n",
       " ('right', 9),\n",
       " ('aunt', 9),\n",
       " ('friendly', 9),\n",
       " ('swing', 9),\n",
       " ('questions', 9),\n",
       " ('never', 8),\n",
       " ('filming', 8),\n",
       " ('tag', 8),\n",
       " ('thank', 8),\n",
       " ('tour', 8),\n",
       " ('people', 8),\n",
       " ('vulture', 8),\n",
       " ('marisatomei', 8),\n",
       " ('caught', 8),\n",
       " ('next', 8),\n",
       " ('green', 8),\n",
       " ('tbt', 8),\n",
       " ('aliciakeys', 8),\n",
       " ('add', 8),\n",
       " ('around', 8),\n",
       " ('friends', 8),\n",
       " ('win', 8),\n",
       " ('starting', 8),\n",
       " ('extras', 8),\n",
       " ('earthhour', 8),\n",
       " ('game', 8),\n",
       " ('hope', 8),\n",
       " ('stops', 8),\n",
       " ('talk', 8),\n",
       " ('robertdowneyjr', 7),\n",
       " ('set', 7),\n",
       " ('harry', 7),\n",
       " ('read', 7),\n",
       " ('looks', 7),\n",
       " ('web', 7),\n",
       " ('york', 7),\n",
       " ('goblin', 7),\n",
       " ('play', 7),\n",
       " ('takes', 7),\n",
       " ('ever', 7),\n",
       " ('soundtrack', 7),\n",
       " ('captainamericapremiere', 7),\n",
       " ('including', 7),\n",
       " ('morning', 7),\n",
       " ('call', 7),\n",
       " ('crew', 7),\n",
       " ('star', 7),\n",
       " ('times', 7),\n",
       " ('ned', 7),\n",
       " ('city', 7),\n",
       " ('show', 7),\n",
       " ('last', 6),\n",
       " ('stop', 6),\n",
       " ('marvel', 6),\n",
       " ('official', 6),\n",
       " ('junior', 6),\n",
       " ('osborn', 6),\n",
       " ('code', 6),\n",
       " ('free', 6),\n",
       " ('comic', 6),\n",
       " ('part', 6),\n",
       " ('minutes', 6),\n",
       " ('certified', 6),\n",
       " ('fresh', 6),\n",
       " ('holland', 6),\n",
       " ('good', 6),\n",
       " ('begins', 6),\n",
       " ('submit', 6),\n",
       " ('real', 6),\n",
       " ('webslinger', 6),\n",
       " ('hanging', 6),\n",
       " ('snaps', 6),\n",
       " ('enemies', 6),\n",
       " ('berlin', 6),\n",
       " ('think', 6),\n",
       " ('square', 6),\n",
       " ('shows', 6),\n",
       " ('cover', 6),\n",
       " ('going', 6),\n",
       " ('calling', 6),\n",
       " ('nye', 6),\n",
       " ('help', 6),\n",
       " ('soon', 6),\n",
       " ('planet', 6),\n",
       " ('trip', 5),\n",
       " ('tonyrevolori', 5),\n",
       " ('field', 5),\n",
       " ('every', 5),\n",
       " ('let', 5),\n",
       " ('shazam', 5),\n",
       " ('jnwtts', 5),\n",
       " ('came', 5),\n",
       " ('making', 5),\n",
       " ('auntmayzing', 5),\n",
       " ('month', 5),\n",
       " ('friday', 5),\n",
       " ('power', 5),\n",
       " ('throwbackthursday', 5),\n",
       " ('spideytrivia', 5),\n",
       " ('question', 5),\n",
       " ('report', 5),\n",
       " ('content', 5),\n",
       " ('extended', 5),\n",
       " ('meets', 5),\n",
       " ('name', 5),\n",
       " ('coming', 5),\n",
       " ('work', 5),\n",
       " ('rome', 5),\n",
       " ('screening', 5),\n",
       " ('fun', 5),\n",
       " ('unlock', 5),\n",
       " ('future', 5),\n",
       " ('video', 5),\n",
       " ('snap', 5),\n",
       " ('become', 5),\n",
       " ('say', 5),\n",
       " ('final', 5),\n",
       " ('webheads', 5),\n",
       " ('allnew', 5),\n",
       " ('three', 5),\n",
       " ('camera', 5),\n",
       " ('students', 5),\n",
       " ('everything', 5),\n",
       " ('filmmakers', 5),\n",
       " ('stay', 5),\n",
       " ('sonypictures', 5),\n",
       " ('full', 5),\n",
       " ('state', 5),\n",
       " ('bring', 5),\n",
       " ('tell', 5),\n",
       " ('nick', 4),\n",
       " ('fury', 4),\n",
       " ('stan', 4),\n",
       " ('come', 4),\n",
       " ('caption', 4),\n",
       " ('amazon', 4),\n",
       " ('sunday', 4),\n",
       " ('kid', 4),\n",
       " ('sally', 4),\n",
       " ('receive', 4),\n",
       " ('together', 4),\n",
       " ('sinister', 4),\n",
       " ('secrets', 4),\n",
       " ('jonah', 4),\n",
       " ('jameson', 4),\n",
       " ('sydney', 4),\n",
       " ('getting', 4),\n",
       " ('interview', 4),\n",
       " ('critics', 4),\n",
       " ('give', 4),\n",
       " ('entertainmentweekly', 4),\n",
       " ('et', 4),\n",
       " ('featuring', 4),\n",
       " ('kendricklamar', 4),\n",
       " ('hans', 4),\n",
       " ('zimmer', 4),\n",
       " ('hangs', 4),\n",
       " ('electroarrives', 4),\n",
       " ('deleted', 4),\n",
       " ('scenes', 4),\n",
       " ('perfect', 4),\n",
       " ('rottentomatoes', 4),\n",
       " ('found', 4),\n",
       " ('said', 4),\n",
       " ('says', 4),\n",
       " ('kids', 4),\n",
       " ('meet', 4),\n",
       " ('news', 4),\n",
       " ('sb', 4),\n",
       " ('jake', 4),\n",
       " ('beautiful', 4),\n",
       " ('poster', 4),\n",
       " ('unite', 4),\n",
       " ('photos', 4),\n",
       " ('using', 4),\n",
       " ('screen', 4),\n",
       " ('costume', 4),\n",
       " ('bronx', 4),\n",
       " ('across', 4),\n",
       " ('pose', 4),\n",
       " ('app', 4),\n",
       " ('double', 4),\n",
       " ('create', 4),\n",
       " ('happens', 4),\n",
       " ('behind', 4),\n",
       " ('works', 4),\n",
       " ('something', 4),\n",
       " ('smiles', 4),\n",
       " ('away', 4),\n",
       " ('early', 4),\n",
       " ('life', 4),\n",
       " ('follow', 4),\n",
       " ('hits', 4),\n",
       " ('six', 4),\n",
       " ('still', 4),\n",
       " ('nbcsnl', 4),\n",
       " ('empire', 4),\n",
       " ('theellenshow', 4),\n",
       " ('hey', 3),\n",
       " ('struggle', 3),\n",
       " ('ultimate', 3),\n",
       " ('local', 3),\n",
       " ('thing', 3),\n",
       " ('interviews', 3),\n",
       " ('pay', 3),\n",
       " ('rest', 3),\n",
       " ('second', 3),\n",
       " ('gets', 3),\n",
       " ('single', 3),\n",
       " ('contest', 3),\n",
       " ('premieres', 3),\n",
       " ('moment', 3),\n",
       " ('credits', 3),\n",
       " ('daily', 3),\n",
       " ('bugle', 3),\n",
       " ('friend', 3),\n",
       " ('kind', 3),\n",
       " ('lip', 3),\n",
       " ('mtvawards', 3),\n",
       " ('theater', 3),\n",
       " ('matter', 3),\n",
       " ('mission', 3),\n",
       " ('became', 3),\n",
       " ('bigger', 3),\n",
       " ('webslinging', 3),\n",
       " ('issue', 3),\n",
       " ('pick', 3),\n",
       " ('meant', 3),\n",
       " ('hear', 3),\n",
       " ('song', 3),\n",
       " ('teamironman', 3),\n",
       " ('michael', 3),\n",
       " ('keaton', 3),\n",
       " ('use', 3),\n",
       " ('jimmykimmellive', 3),\n",
       " ('old', 3),\n",
       " ('anyone', 3),\n",
       " ('meeting', 3),\n",
       " ('makes', 3),\n",
       " ('spideysightings', 3),\n",
       " ('tumblr', 3),\n",
       " ('spiders', 3),\n",
       " ('bbbsa', 3),\n",
       " ('looking', 3),\n",
       " ('collection', 3),\n",
       " ('earth', 3),\n",
       " ('surprise', 3),\n",
       " ('itunes', 3),\n",
       " ('many', 3),\n",
       " ('shot', 3),\n",
       " ('joined', 3),\n",
       " ('gone', 3),\n",
       " ('global', 3),\n",
       " ('bosslogic', 3),\n",
       " ('jakegyllenhaal', 3),\n",
       " ('yahoomovies', 3),\n",
       " ('inspired', 3),\n",
       " ('choice', 3),\n",
       " ('comes', 3),\n",
       " ('poses', 3),\n",
       " ('details', 3),\n",
       " ('st', 3),\n",
       " ('jon', 3),\n",
       " ('guys', 3),\n",
       " ('side', 3),\n",
       " ('five', 3),\n",
       " ('inside', 3),\n",
       " ('harryholland', 3),\n",
       " ('project', 3),\n",
       " ('jimmyrich', 3),\n",
       " ('proud', 3),\n",
       " ('suits', 3),\n",
       " ('helping', 3),\n",
       " ('almost', 3),\n",
       " ('important', 3),\n",
       " ('promoting', 3),\n",
       " ('thedailybugletumblrcom', 3),\n",
       " ('siriusxm', 3),\n",
       " ('foxxhole', 3),\n",
       " ('radio', 3),\n",
       " ('spikelsb', 3),\n",
       " ('bad', 3),\n",
       " ('footage', 3),\n",
       " ('webcast', 3),\n",
       " ('four', 3),\n",
       " ('family', 3),\n",
       " ('made', 3),\n",
       " ('guy', 3),\n",
       " ('wworphans', 3),\n",
       " ('line', 3),\n",
       " ('gives', 3),\n",
       " ('pics', 3),\n",
       " ('rooftop', 3),\n",
       " ('skills', 3),\n",
       " ('excited', 3),\n",
       " ('mj', 3),\n",
       " ('taking', 3),\n",
       " ('tony', 3),\n",
       " ('dr', 3),\n",
       " ('group', 3),\n",
       " ('dream', 3),\n",
       " ('chicago', 3),\n",
       " ('pt', 3),\n",
       " ('credit', 3),\n",
       " ('sequence', 3),\n",
       " ('thursday', 3),\n",
       " ('spotted', 3),\n",
       " ('responsibility', 3),\n",
       " ('volunteers', 3),\n",
       " ('witness', 3),\n",
       " ('holiday', 3),\n",
       " ('jacob', 3),\n",
       " ('batalon', 3),\n",
       " ('showing', 3),\n",
       " ('cut', 3),\n",
       " ('popsugar', 3),\n",
       " ('singapore', 3),\n",
       " ('awesome', 3),\n",
       " ('webbing', 3),\n",
       " ('hour', 3),\n",
       " ('done', 3),\n",
       " ('mr', 3),\n",
       " ('stark', 3),\n",
       " ('listen', 3),\n",
       " ('celebrate', 3),\n",
       " ('forget', 3),\n",
       " ('facebook', 3),\n",
       " ('talks', 3),\n",
       " ('things', 3),\n",
       " ('arrives', 3),\n",
       " ('called', 3),\n",
       " ('yesterday', 3),\n",
       " ('download', 3),\n",
       " ('flight', 3),\n",
       " ('creating', 3),\n",
       " ('thwip', 3),\n",
       " ('paint', 3),\n",
       " ('mural', 3),\n",
       " ('lights', 3),\n",
       " ('comments', 3),\n",
       " ('stars', 3),\n",
       " ('drops', 3),\n",
       " ('copy', 3),\n",
       " ('truth', 3),\n",
       " ('beaherocontest', 3),\n",
       " ('seen', 3),\n",
       " ('return', 3),\n",
       " ('andpark', 3),\n",
       " ('twitter', 3),\n",
       " ('stand', 3),\n",
       " ('attacks', 3),\n",
       " ('pic', 2),\n",
       " ('summer', 2),\n",
       " ('edition', 2),\n",
       " ('surprised', 2),\n",
       " ('amazingusps', 2),\n",
       " ('score', 2),\n",
       " ('hang', 2),\n",
       " ('latest', 2),\n",
       " ('avengers', 2),\n",
       " ('mysterious', 2),\n",
       " ('tokyo', 2),\n",
       " ('faces', 2),\n",
       " ('enemy', 2),\n",
       " ('voguemagazine', 2),\n",
       " ('stunning', 2),\n",
       " ('comment', 2),\n",
       " ('swung', 2),\n",
       " ('took', 2),\n",
       " ('hours', 2),\n",
       " ('dane', 2),\n",
       " ('dehaan', 2),\n",
       " ('worldemojiday', 2),\n",
       " ('phone', 2),\n",
       " ('google', 2),\n",
       " ('view', 2),\n",
       " ('boy', 2),\n",
       " ('fox', 2),\n",
       " ('learn', 2),\n",
       " ('everywhere', 2),\n",
       " ('norman', 2),\n",
       " ('surprises', 2),\n",
       " ('concept', 2),\n",
       " ('daughter', 2),\n",
       " ('oscars', 2),\n",
       " ('environment', 2),\n",
       " ('additional', 2),\n",
       " ('scene', 2),\n",
       " ('father', 2),\n",
       " ('universe', 2),\n",
       " ('villain', 2),\n",
       " ('website', 2),\n",
       " ('grew', 2),\n",
       " ('absolutely', 2),\n",
       " ('crazy', 2),\n",
       " ('reallife', 2),\n",
       " ('sneak', 2),\n",
       " ('place', 2),\n",
       " ('page', 2),\n",
       " ('theamazingspidermantumblrcom', 2),\n",
       " ('brought', 2),\n",
       " ('winners', 2),\n",
       " ('winter', 2),\n",
       " ('season', 2),\n",
       " ('upgrade', 2),\n",
       " ('responders', 2),\n",
       " ('price', 2),\n",
       " ('spend', 2),\n",
       " ('crawling', 2),\n",
       " ('ceremony', 2),\n",
       " ('yankee', 2),\n",
       " ('stadium', 2),\n",
       " ('socialsquare', 2),\n",
       " ('livestream', 2),\n",
       " ('artwork', 2),\n",
       " ('rhino', 2),\n",
       " ('text', 2),\n",
       " ('brothers', 2),\n",
       " ('sisters', 2),\n",
       " ('knew', 2),\n",
       " ('adorable', 2),\n",
       " ('plan', 2),\n",
       " ('teamelectro', 2),\n",
       " ('tingling', 2),\n",
       " ('program', 2),\n",
       " ('prizes', 2),\n",
       " ('rules', 2),\n",
       " ('legend', 2),\n",
       " ('lee', 2),\n",
       " ('friendship', 2),\n",
       " ('enjoy', 2),\n",
       " ('young', 2),\n",
       " ('spent', 2),\n",
       " ('past', 2),\n",
       " ('watts', 2),\n",
       " ('atlanta', 2),\n",
       " ('better', 2),\n",
       " ('mexico', 2),\n",
       " ('davynewkirk', 2),\n",
       " ('jeanneyangstyle', 2),\n",
       " ('kellyandmichael', 2),\n",
       " ('debut', 2),\n",
       " ('swipe', 2),\n",
       " ('elementary', 2),\n",
       " ('spideyfamily', 2),\n",
       " ('clip', 2),\n",
       " ('hands', 2),\n",
       " ('halloween', 2),\n",
       " ('ces', 2),\n",
       " ('officially', 2),\n",
       " ('guyinthechair', 2),\n",
       " ('hand', 2),\n",
       " ('town', 2),\n",
       " ('hall', 2),\n",
       " ('ad', 2),\n",
       " ('thought', 2),\n",
       " ('onto', 2),\n",
       " ('courtesy', 2),\n",
       " ('prepare', 2),\n",
       " ('someone', 2),\n",
       " ('taiwan', 2),\n",
       " ('left', 2),\n",
       " ('banana', 2),\n",
       " ('psa', 2),\n",
       " ('keeping', 2),\n",
       " ('giving', 2),\n",
       " ('snapchat', 2),\n",
       " ('max', 2),\n",
       " ('books', 2),\n",
       " ('sirericcochran', 2),\n",
       " ('mob', 2),\n",
       " ('superhuman', 2),\n",
       " ('arrived', 2),\n",
       " ('far', 2),\n",
       " ('really', 2),\n",
       " ('emmastone', 2),\n",
       " ('catches', 2),\n",
       " ('working', 2),\n",
       " ('classmates', 2),\n",
       " ('guest', 2),\n",
       " ('vfvanities', 2),\n",
       " ('places', 2),\n",
       " ('leaves', 2),\n",
       " ('well', 2),\n",
       " ('long', 2),\n",
       " ('release', 2),\n",
       " ('ta', 2),\n",
       " ('eggs', 2),\n",
       " ('stunt', 2),\n",
       " ('saw', 2),\n",
       " ('brand', 2),\n",
       " ('intheater', 2),\n",
       " ('banner', 2),\n",
       " ('exclusively', 2),\n",
       " ('fandango', 2),\n",
       " ('ticket', 2),\n",
       " ('fate', 2),\n",
       " ('store', 2),\n",
       " ('sacrifice', 2),\n",
       " ('countdown', 2),\n",
       " ('showdown', 2),\n",
       " ('candid', 2),\n",
       " ('forward', 2),\n",
       " ('travel', 2),\n",
       " ('june', 2),\n",
       " ('chair', 2),\n",
       " ('neverbeforeseen', 2),\n",
       " ('august', 2),\n",
       " ('newsstands', 2),\n",
       " ('fit', 2),\n",
       " ('stage', 2),\n",
       " ('worlds', 2),\n",
       " ('spidermanhangout', 2),\n",
       " ('message', 2),\n",
       " ('biggest', 2),\n",
       " ('short', 2),\n",
       " ('behindthescenes', 2),\n",
       " ('confetti', 2),\n",
       " ('party', 2),\n",
       " ('fight', 2),\n",
       " ('askspiderman', 2),\n",
       " ('talented', 2),\n",
       " ('igndotcom', 2),\n",
       " ('fallontonight', 2),\n",
       " ('tuned', 2),\n",
       " ('grace', 2),\n",
       " ('initiative', 2),\n",
       " ('spideyhalloween', 2),\n",
       " ('coffee', 2),\n",
       " ('turning', 2),\n",
       " ('teaser', 2),\n",
       " ('hunt', 2),\n",
       " ('flame', 2),\n",
       " ('changed', 2),\n",
       " ('discover', 2),\n",
       " ('much', 2),\n",
       " ('united', 2),\n",
       " ('wanting', 2),\n",
       " ('hansfzimmer', 2),\n",
       " ('music', 2),\n",
       " ('close', 2),\n",
       " ('fix', 2),\n",
       " ('waiting', 2),\n",
       " ('hosts', 2),\n",
       " ('spends', 2),\n",
       " ('participated', 2),\n",
       " ('ravencroft', 2),\n",
       " ('encounter', 2),\n",
       " ('ca', 2),\n",
       " ('already', 2),\n",
       " ('national', 2),\n",
       " ('top', 2),\n",
       " ('shooter', 2),\n",
       " ('changes', 2),\n",
       " ('ride', 2),\n",
       " ('yahoomoviesuk', 2),\n",
       " ('always', 2),\n",
       " ('afterparty', 2),\n",
       " ('quick', 2),\n",
       " ('change', 2),\n",
       " ('seeing', 2),\n",
       " ('talenthouse', 2),\n",
       " ('thinkbigger', 2),\n",
       " ('congratulations', 2),\n",
       " ('receiving', 2),\n",
       " ('hollywood', 2),\n",
       " ('walk', 2),\n",
       " ('fame', 2),\n",
       " ('supplies', 2),\n",
       " ('tweet', 2),\n",
       " ('nearest', 2),\n",
       " ('fastest', 2),\n",
       " ('asks', 2),\n",
       " ('nypd', 2),\n",
       " ('focus', 2),\n",
       " ('activity', 2),\n",
       " ('finally', 2),\n",
       " ('fellow', 2),\n",
       " ('heads', 2),\n",
       " ('exciting', 2),\n",
       " ('walmartcomspiderman', 2),\n",
       " ('needs', 2),\n",
       " ('glasses', 2),\n",
       " ('filled', 2),\n",
       " ('chat', 2),\n",
       " ('bali', 2),\n",
       " ('smile', 2),\n",
       " ('crime', 2),\n",
       " ('mystery', 2),\n",
       " ('mysterio', 2),\n",
       " ('collaborator', 2),\n",
       " ('hi', 2),\n",
       " ('aka', 2),\n",
       " ('dance', 2),\n",
       " ('iron', 2),\n",
       " ('stopped', 2),\n",
       " ('discuss', 2),\n",
       " ('must', 2),\n",
       " ('hold', 2),\n",
       " ('warm', 2),\n",
       " ('business', 2),\n",
       " ('everyday', 2),\n",
       " ('please', 2),\n",
       " ('along', 2),\n",
       " ('answers', 2),\n",
       " ('finds', 2),\n",
       " ('cart', 2),\n",
       " ('secret', 2),\n",
       " ('curt', 2),\n",
       " ('connors', 2),\n",
       " ('smythe', 2),\n",
       " ('helps', 2),\n",
       " ('volunteer', 2),\n",
       " ('sonypicturesuk', 2),\n",
       " ('room', 2),\n",
       " ('sync', 2),\n",
       " ('signing', 2),\n",
       " ('nycc', 2),\n",
       " ('hanglikespidey', 2),\n",
       " ('engineer', 2),\n",
       " ('landing', 2),\n",
       " ('returns', 2),\n",
       " ('break', 2),\n",
       " ('boss', 2),\n",
       " ('uncover', 2),\n",
       " ('havoc', 2),\n",
       " ('elementals', 2),\n",
       " ('cool', 1),\n",
       " ('thus', 1),\n",
       " ('samuelljackson', 1),\n",
       " ('witty', 1),\n",
       " ('nofilter', 1),\n",
       " ('also', 1),\n",
       " ('darnellappling', 1),\n",
       " ('running', 1),\n",
       " ('invites', 1),\n",
       " ('preorder', 1),\n",
       " ('collector', 1),\n",
       " ('screenings', 1),\n",
       " ('uspostalservice', 1),\n",
       " ('delivery', 1),\n",
       " ('spideyexcuses', 1),\n",
       " ('selection', 1),\n",
       " ('certain', 1),\n",
       " ('believe', 1),\n",
       " ('ranked', 1),\n",
       " ('reporter', 1),\n",
       " ('drew', 1),\n",
       " ('snippet', 1),\n",
       " ('entering', 1),\n",
       " ('shall', 1),\n",
       " ('maybe', 1),\n",
       " ('omazecomrdj', 1),\n",
       " ('dogooderest', 1),\n",
       " ('dogooders', 1),\n",
       " ('flights', 1),\n",
       " ('hotel', 1),\n",
       " ('stranger', 1),\n",
       " ('characters', 1),\n",
       " ('explore', 1),\n",
       " ('publisher', 1),\n",
       " ('synch', 1),\n",
       " ('rise', 1),\n",
       " ('georgejcottle', 1),\n",
       " ('badass', 1),\n",
       " ('stunts', 1),\n",
       " ('ask', 1),\n",
       " ('used', 1),\n",
       " ('professionals', 1),\n",
       " ('vs', 1),\n",
       " ('near', 1),\n",
       " ('face', 1),\n",
       " ('overcome', 1),\n",
       " ('quote', 1),\n",
       " ('destiny', 1),\n",
       " ('looked', 1),\n",
       " ('bbq', 1),\n",
       " ('makeup', 1),\n",
       " ('worldrenowned', 1),\n",
       " ('nuclear', 1),\n",
       " ('scientist', 1),\n",
       " ('otto', 1),\n",
       " ('octavius', 1),\n",
       " ('collaborating', 1),\n",
       " ('claims', 1),\n",
       " ('melissa', 1),\n",
       " ('hutchins', 1),\n",
       " ('begs', 1),\n",
       " ('differ', 1),\n",
       " ('access', 1),\n",
       " ('spidermanapp', 1),\n",
       " ('ios', 1),\n",
       " ('dreams', 1),\n",
       " ('somebody', 1),\n",
       " ('marveltakeover', 1),\n",
       " ('nflhonors', 1),\n",
       " ('wolverine', 1),\n",
       " ('nfl', 1),\n",
       " ('honors', 1),\n",
       " ('tasm', 1),\n",
       " ('cutest', 1),\n",
       " ('emojis', 1),\n",
       " ('problem', 1),\n",
       " ('ghosting', 1),\n",
       " ('total', 1),\n",
       " ('spin', 1),\n",
       " ('electrical', 1),\n",
       " ('engineering', 1),\n",
       " ('options', 1),\n",
       " ('limited', 1),\n",
       " ('editions', 1),\n",
       " ('zcoon', 1),\n",
       " ('trust', 1),\n",
       " ('promises', 1),\n",
       " ('broken', 1),\n",
       " ('pintsized', 1),\n",
       " ('pumps', 1),\n",
       " ('crowd', 1),\n",
       " ('genetic', 1),\n",
       " ('disease', 1),\n",
       " ('sdcc', 1),\n",
       " ('believes', 1),\n",
       " ('paulbettany', 1),\n",
       " ('casting', 1),\n",
       " ('soar', 1),\n",
       " ('either', 1),\n",
       " ('woke', 1),\n",
       " ('webbed', 1),\n",
       " ('dvrs', 1),\n",
       " ('whatever', 1),\n",
       " ('tv', 1),\n",
       " ('nowadays', 1),\n",
       " ('actor', 1),\n",
       " ('posted', 1),\n",
       " ('yearold', 1),\n",
       " ('rushed', 1),\n",
       " ('computer', 1),\n",
       " ('lucky', 1),\n",
       " ('went', 1),\n",
       " ('belt', 1),\n",
       " ('adapted', 1),\n",
       " ('role', 1),\n",
       " ('physical', 1),\n",
       " ('training', 1),\n",
       " ('demands', 1),\n",
       " ('freerunning', 1),\n",
       " ('gymnastics', 1),\n",
       " ('frequents', 1),\n",
       " ('account', 1),\n",
       " ('familiar', 1),\n",
       " ('signature', 1),\n",
       " ('backflips', 1),\n",
       " ('dressed', 1),\n",
       " ('joyous', 1),\n",
       " ('december', 1),\n",
       " ('peek', 1),\n",
       " ('america', 1),\n",
       " ('gmamazing', 1),\n",
       " ('boroughblog', 1),\n",
       " ('uptodate', 1),\n",
       " ('greatestbattle', 1),\n",
       " ('broncos', 1),\n",
       " ('seahawks', 1),\n",
       " ('reblog', 1),\n",
       " ('favorites', 1),\n",
       " ('cineeurope', 1),\n",
       " ('riders', 1),\n",
       " ('sits', 1),\n",
       " ('kroq', 1),\n",
       " ('trading', 1),\n",
       " ('openingday', 1),\n",
       " ('baseball', 1),\n",
       " ('rooting', 1),\n",
       " ('received', 1),\n",
       " ('minor', 1),\n",
       " ('karen', 1),\n",
       " ('rumors', 1),\n",
       " ('true', 1),\n",
       " ('reveals', 1),\n",
       " ('title', 1),\n",
       " ('logo', 1),\n",
       " ('sonyatcinemacon', 1),\n",
       " ('pretending', 1),\n",
       " ('deepest', 1),\n",
       " ('respect', 1),\n",
       " ('fire', 1),\n",
       " ('police', 1),\n",
       " ('men', 1),\n",
       " ('women', 1),\n",
       " ('happiest', 1),\n",
       " ('happier', 1),\n",
       " ('disneychannel', 1),\n",
       " ('freeform', 1),\n",
       " ('ohmydisney', 1),\n",
       " ('nationalselfieday', 1),\n",
       " ('vibes', 1),\n",
       " ('interwebs', 1),\n",
       " ('webhead', 1),\n",
       " ('quite', 1),\n",
       " ('ball', 1),\n",
       " ('opening', 1),\n",
       " ('dudeman', 1),\n",
       " ('clock', 1),\n",
       " ('tower', 1),\n",
       " ('grabs', 1),\n",
       " ('hoops', 1),\n",
       " ('activate', 1),\n",
       " ('enhanced', 1),\n",
       " ('reconnaissance', 1),\n",
       " ('mode', 1),\n",
       " ('realized', 1),\n",
       " ('osbornarmy', 1),\n",
       " ('stick', 1),\n",
       " ('figures', 1),\n",
       " ('compete', 1),\n",
       " ('dbox', 1),\n",
       " ('tech', 1),\n",
       " ('nobody', 1),\n",
       " ('decisions', 1),\n",
       " ('wonder', 1),\n",
       " ('mile', 1),\n",
       " ('light', 1),\n",
       " ('fourlegged', 1),\n",
       " ('uk', 1),\n",
       " ('remember', 1),\n",
       " ('shouts', 1),\n",
       " ('megaphone', 1),\n",
       " ('reunited', 1),\n",
       " ('delivers', 1),\n",
       " ('accurate', 1),\n",
       " ('representation', 1),\n",
       " ('teenagers', 1),\n",
       " ('thanksgiving', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(freq_dic.items(), key=lambda d: d[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequences_train = tokenizer.texts_to_sequences(texts)\n",
    "sequences_valid = tokenizer.texts_to_sequences(val_data.convert_text)\n",
    "\n",
    "X_train = pad_sequences(sequences_train)\n",
    "X_val = pad_sequences(sequences_valid,maxlen=X_train.shape[1])\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "y_train = np.asarray(labels[train_data.index.values])\n",
    "y_val = np.asarray(labels[val_data.index.values])\n",
    "\n",
    "print('Shape of X train and X validation tensor:', X_train.shape,X_val.shape)\n",
    "print('Shape of label train and validation tensor:', y_train.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "outOfDict = []\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format('./model/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "EMBEDDING_DIM=300\n",
    "vocabulary_size=min(len(word_index)+1,NUM_WORDS)\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i>=NUM_WORDS:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n",
    "        outOfDict.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write_json(outOfDict, 'unstemmed_outOfDict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# del(word_vectors)\n",
    "\n",
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(vocabulary_size,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 儲存路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAVE_NAME = 'merge_stride7-starwars'\n",
    "HISTORY_SAVE = './history/' + SAVE_NAME + '.csv'\n",
    "WEIGHTS_SAVE = './weight/' + SAVE_NAME + '.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout,concatenate\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "sequence_length = X_train.shape[1]\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 100\n",
    "drop = 0.5\n",
    "stride = 7\n",
    "\n",
    "inputs = Input(shape=(sequence_length,))\n",
    "embedding = embedding_layer(inputs)\n",
    "reshape = Reshape((sequence_length,EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, (filter_sizes[0], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "conv_1 = Conv2D(num_filters, (filter_sizes[1], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "conv_2 = Conv2D(num_filters, (filter_sizes[2], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "\n",
    "maxpool_0 = MaxPooling2D((sequence_length - filter_sizes[0] + 1, 1), strides=(stride,1))(conv_0)\n",
    "maxpool_1 = MaxPooling2D((sequence_length - filter_sizes[1] + 1, 1), strides=(stride,1))(conv_1)\n",
    "maxpool_2 = MaxPooling2D((sequence_length - filter_sizes[2] + 1, 1), strides=(stride,1))(conv_2)\n",
    "\n",
    "merged_tensor = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1)\n",
    "flatten = Flatten()(merged_tensor)\n",
    "reshape = Reshape((3*num_filters,))(flatten)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "output = Dense(units=20, activation='sigmoid',kernel_regularizer=regularizers.l2(0.01))(dropout)\n",
    "\n",
    "# this creates a model that includes\n",
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-3)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['acc'])\n",
    "callbacks = [EarlyStopping(monitor='val_loss')]\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1, validation_data=(X_val, y_val), callbacks=callbacks)  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save model weights\n",
    "model.save(WEIGHTS_SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save history\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "his_df = pd.DataFrame(data = {\n",
    "    'Epoch' : epochs,\n",
    "    'Loss' : loss,\n",
    "    'Acc' : acc,\n",
    "    'Val_loss' : val_loss,\n",
    "    'Val_acc' : val_acc\n",
    "})\n",
    "his_df = his_df[['Epoch', 'Loss', 'Acc', 'Val_loss', 'Val_acc']]\n",
    "his_df.to_csv(HISTORY_SAVE, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 繪製結果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequences_test=tokenizer.texts_to_sequences(test_data.convert_text)\n",
    "X_test = pad_sequences(sequences_test,maxlen=X_train.shape[1])\n",
    "# pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = pred #pred_bool.astype(int)\n",
    "\n",
    "results=pd.DataFrame(predictions, columns=columns)\n",
    "results[\"username\"] = test_data.username\n",
    "ordered_cols = [\"username\"] + columns\n",
    "results = results[ordered_cols] #To get the same column order\n",
    "results.to_csv(\"./output/\"+ SAVE_NAME + \"_result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label top n dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_df= pd.read_csv('./input/true_df.csv')\n",
    "true_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"./output/\"+ SAVE_NAME + \"_result.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = read_json('../genresDic.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def countAcc(predList, trueList):\n",
    "    fraction = 0\n",
    "    denominator = len(trueList)\n",
    "    for g in predList:\n",
    "        if g in trueList:\n",
    "            fraction += 1 \n",
    "    return fraction / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "li = []\n",
    "for i, row in true_df.iterrows():\n",
    "    username = row['username']\n",
    "    if username == results.loc[i,:]['username']: # username equals\n",
    "        print(i, username)\n",
    "        truth = labels[username]\n",
    "        numTrue = sum(row[1:])\n",
    "        print('count:', numTrue)\n",
    "        \n",
    "        s = results.loc[i,:][1:]\n",
    "        top_n = s.sort_values(ascending=False)[:numTrue]\n",
    "        inList = list(top_n.index)\n",
    "        \n",
    "        onehot = []\n",
    "        for g in columns:\n",
    "            onehot.append(int(g in inList))\n",
    "            \n",
    "        acc = countAcc(inList, truth)\n",
    "        print(acc, inList, truth)\n",
    "        \n",
    "        appList = [username, acc, truth, inList] + onehot\n",
    "        li.append(appList)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame(li, columns = ['username', 'acc', 'truth', 'top_n'] + columns)\n",
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_df.to_csv(\"./output/\"+ SAVE_NAME + \"_bi.csv\", index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_df['acc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "## 測試reload model準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAVE_NAME = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WEIGHTS_LOAD = './weight/merge_stride8-starwars.h5'\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(WEIGHTS_LOAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequences_test=tokenizer.texts_to_sequences(test_data.convert_text)\n",
    "X_test = pad_sequences(sequences_test,maxlen=X_train.shape[1])\n",
    "pred = model.predict(X_test)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = pred\n",
    "\n",
    "results=pd.DataFrame(predictions, columns=columns)\n",
    "results[\"username\"] = test_data.username\n",
    "ordered_cols = [\"username\"] + columns\n",
    "results = results[ordered_cols] #To get the same column order\n",
    "results.to_csv(\"./output/\"+ SAVE_NAME + \"_result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = read_json('../genresDic.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "li = []\n",
    "for i, row in true_df.iterrows():\n",
    "    username = row['username']\n",
    "    if username == results.loc[i,:]['username']: # username equals\n",
    "        print(i, username)\n",
    "        truth = labels[username]\n",
    "        numTrue = sum(row[1:])\n",
    "        print('count:', numTrue)\n",
    "        \n",
    "        s = results.loc[i,:][1:]\n",
    "        top_n = s.sort_values(ascending=False)[:numTrue]\n",
    "        inList = list(top_n.index)\n",
    "        \n",
    "        onehot = []\n",
    "        for g in columns:\n",
    "            onehot.append(int(g in inList))\n",
    "            \n",
    "        acc = countAcc(inList, truth)\n",
    "        print(acc, inList, truth)\n",
    "        \n",
    "        appList = [username, acc, truth, inList] + onehot\n",
    "        li.append(appList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame(li, columns = ['username', 'acc', 'truth', 'top_n'] + columns)\n",
    "acc_df['acc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 萃取97部電影imdb的feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extract_layer = Model(inputs=model.input,\n",
    "                      outputs=model.get_layer('flatten_4').output)\n",
    "#以这个model的预测值作为输出\n",
    "extract_output = extract_layer.predict(X_test)\n",
    "print(extract_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = test_data.username.tolist()\n",
    "print(len(idx), idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res=pd.DataFrame(extract_output, index = idx)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.to_csv(\"./output/TextFeatureVec.csv\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
