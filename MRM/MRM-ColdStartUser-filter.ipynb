{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "def writeProgress(msg, count, total):\n",
    "    sys.stdout.write(msg + \"{:.2%}\\r\".format(count/total))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: (165, 2372)\n",
      "Movie genre: (165, 20)\n",
      "User following: (1582, 165)\n",
      "User genre: (1582, 20)\n"
     ]
    }
   ],
   "source": [
    "all_npy = np.load('./npy/all_2372.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "\n",
    "print('All features:', all_npy.shape)\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582 165\n",
      "64 2372 240\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "print(usr_nb, movie_nb)\n",
    "\n",
    "# usr_test_amount = 150\n",
    "# movie_test_amount = 32\n",
    "# print(usr_test_amount, movie_test_amount)\n",
    "\n",
    "latent_dim = 64 # latent dims\n",
    "ft_dim = all_npy.shape[1] # feature dims\n",
    "embedding_dims = 240\n",
    "print(latent_dim, ft_dim, embedding_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize usr_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 20)\n"
     ]
    }
   ],
   "source": [
    "usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "for i in range(len(usr_genre)):\n",
    "    usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "print(usr_genre_norm.shape)\n",
    "# print('Before:', usr_genre)\n",
    "# print('After:', usr_genre_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & testing split\n",
    "## Prepare\n",
    "### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followings: 10\n",
      "Max number of followings: 133\n",
      "Avg of followers: 14.820480404551201\n"
     ]
    }
   ],
   "source": [
    "#The number of following movie for each user\n",
    "each_user = np.sum(usr_following, axis=1)\n",
    "# print(each_user)\n",
    "\n",
    "print('Min number of followings:', np.min(each_user))\n",
    "print('Max number of followings:', np.max(each_user))\n",
    "print('Avg of followers:', np.mean(each_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<= 15: 1142\n",
      "(1142,) [   0    1    2 ... 1578 1580 1581]\n"
     ]
    }
   ],
   "source": [
    "print('<= 15:', np.sum(each_user <= 15))\n",
    "less_idx = np.nonzero(each_user <= 15)[0]\n",
    "print(less_idx.shape, less_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(usr_nb):\n",
    "    if not i in less_idx:\n",
    "        each_user[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followings: 0\n",
      "Max number of followings: 15\n",
      "Avg of followers: 8.36283185840708\n"
     ]
    }
   ],
   "source": [
    "print('Min number of followings:', np.min(each_user))\n",
    "print('Max number of followings:', np.max(each_user))\n",
    "print('Avg of followers:', np.mean(each_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 326, 1448,  927,  926,  139,  895,  529,  117, 1403,  848,  545,\n",
       "         99,  825,  824, 1436,  804,  953,  800,  570, 1472, 1473, 1478,\n",
       "        606, 1486,   53, 1495, 1498, 1503,   43,   39, 1345, 1326, 1514,\n",
       "       1043, 1155,  307, 1145,  314,  268, 1125, 1105,  357, 1223,  231,\n",
       "       1235,  400, 1240, 1034,  464,  211,  408,  195,  428,  431, 1291,\n",
       "        439,  981, 1303, 1311,  967,  460,  959,  730, 1156,  688,  676,\n",
       "         13,  645,  679,  654,  633, 1571,  524,  675,   92,  822, 1225,\n",
       "        873, 1290,  235, 1327,  561,  815, 1537,  188,  312,   81,  156,\n",
       "         74, 1333,  423, 1451,  708, 1174, 1005,   93, 1382,  183, 1181,\n",
       "       1553])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(each_user.argsort()[::-1][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [326, 1448, 927, 926, 139, 895, 529, 117, 1403, 848]\n"
     ]
    }
   ],
   "source": [
    "test_idx = list(each_user.argsort()[::-1][:100])\n",
    "print(len(test_idx), test_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_user[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 165)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldarea = usr_following[test_idx, :]\n",
    "coldarea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followings: 0\n",
      "Max number of followings: 41\n",
      "Avg of followers: 8.921212121212122\n"
     ]
    }
   ],
   "source": [
    "#The number of following movie for each user\n",
    "each_movie = np.sum(coldarea, axis=0)\n",
    "\n",
    "print('Min number of followings:', np.min(each_movie))\n",
    "print('Max number of followings:', np.max(each_movie))\n",
    "print('Avg of followers:', np.mean(each_movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 12,  9, 11, 14,  7,  1,  0,  3, 22,  7,  7, 24,  7,  2,  1,  2,\n",
       "        2,  6,  8,  5,  7, 13,  6, 10, 16,  3,  0, 28,  3, 22,  3,  4,  6,\n",
       "       22,  2,  2,  8,  1,  6, 17,  4,  5,  6, 36,  5,  2,  5,  2, 15, 15,\n",
       "        1,  7,  9,  1, 12,  1, 12, 27,  3, 19,  2, 10,  5, 10,  0, 20,  3,\n",
       "       24,  6,  3,  1,  7,  2,  7, 13,  7,  7, 17,  9, 19, 17,  3,  3, 20,\n",
       "        5, 17, 28,  3,  8,  4,  9,  2,  8,  1,  2,  6,  1,  3, 19,  2, 14,\n",
       "       20,  9,  8,  5,  8,  4,  8,  1,  1,  7, 29,  0,  3,  2,  3,  1, 13,\n",
       "       18, 10, 10, 20, 11,  5, 14, 20, 18, 17, 25,  1,  7,  3,  6, 18,  7,\n",
       "        3, 13,  7,  1,  3,  9,  9,  7, 24,  1,  2, 17,  4,  9,  2,  5,  7,\n",
       "        2, 12,  2, 41,  1,  5, 12,  0, 27,  0,  8, 33])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159,) [  0   1   2   3   4   5   6   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  64  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110\n",
      " 111 112 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129\n",
      " 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147\n",
      " 148 149 150 151 152 153 154 155 156 157 158 159 161 163 164]\n"
     ]
    }
   ],
   "source": [
    "less_idx = np.nonzero(each_movie > 0)[0]\n",
    "print(less_idx.shape, less_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n",
      "159 32\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(test_idx)\n",
    "usr_test_amount = len(test_idx)\n",
    "\n",
    "less_idx = list(less_idx)\n",
    "movie_nb = len(less_idx)  # the number of movies\n",
    "movie_test_amount = 32 #math.floor(len(less_idx)*0.5)\n",
    "\n",
    "print(usr_nb, usr_test_amount)\n",
    "print(movie_nb, movie_test_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter original npy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: (159, 2372)\n",
      "Movie genre: (159, 20)\n",
      "User following: (100, 159)\n",
      "User genre: (100, 20)\n"
     ]
    }
   ],
   "source": [
    "all_npy = all_npy[less_idx, :]\n",
    "movie_genre = movie_genre[less_idx, :]\n",
    "usr_following = usr_following[test_idx, :][:, less_idx]\n",
    "usr_genre_norm = usr_genre_norm[test_idx, :]\n",
    "\n",
    "print('All features:', all_npy.shape)\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init\n",
    "random.seed(42)\n",
    "train_t = []\n",
    "train_f = []\n",
    "test_t = []\n",
    "test_f = []\n",
    "\n",
    "for i in range(usr_nb):\n",
    "    # init\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    t_for_test = []\n",
    "    f_for_test = []\n",
    "    \n",
    "    temp_t = []\n",
    "    temp_f = []\n",
    "    for j in range(movie_nb):\n",
    "        if usr_following[i][j] == 1:\n",
    "            temp_t.append(j)\n",
    "        else:\n",
    "            temp_f.append(j)\n",
    "            \n",
    "    t_for_test = random.sample(temp_t, math.ceil(0.5*len(temp_t)))\n",
    "    f_for_test = random.sample(temp_f, movie_test_amount-len(t_for_test))\n",
    "    \n",
    "    test_t.append(t_for_test)\n",
    "    test_f.append(f_for_test)\n",
    "    \n",
    "    t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "    f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "    train_t.append(t_for_train)\n",
    "    train_f.append(f_for_train)\n",
    "    \n",
    "    if not (len(t_for_train) + len(f_for_train) + len(t_for_test) + len(f_for_test)) == len(less_idx):\n",
    "        print('Error!!!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 100\n",
      "The length of train_f: 100\n",
      "The length of test_t: 100\n",
      "The length of test_f: 100\n"
     ]
    }
   ],
   "source": [
    "test_idx = [i for i in range(usr_test_amount)]\n",
    "\n",
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_f))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 700 7.0\n",
      "Testing: 772 7.72\n"
     ]
    }
   ],
   "source": [
    "#average num of following for training user\n",
    "total_train = 0\n",
    "for t in train_t:\n",
    "    total_train += len(t)\n",
    "avg = total_train / usr_test_amount\n",
    "print('Training:', total_train, avg)\n",
    "\n",
    "#average num of following for testing user\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test / usr_test_amount\n",
    "print('Testing:', total_test, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_auxilary = [i for i in range(movie_nb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation model\n",
    "## Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(SAVE_NAME):\n",
    "    print('==================================================')\n",
    "    print(SAVE_NAME)\n",
    "    print('Start time:', time.ctime())\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    loss_acc_list = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_yes_id=[]\n",
    "\n",
    "    for q in range(6):\n",
    "        print('Epoch:',q)\n",
    "        train_auc = 0\n",
    "        total_loss = 0\n",
    "        xuij_auc = 0\n",
    "        length = 0\n",
    "\n",
    "        for z in range(usr_nb):\n",
    "            writeProgress('Progress:', z, usr_nb)\n",
    "            \"\"\"\n",
    "            yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "            yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "            r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "            \"\"\"\n",
    "            yes = []\n",
    "            yesr = []\n",
    "\n",
    "    #         #選全部的Positive\n",
    "    #         sample = random.sample(train_t[z],len(train_t[z]))\n",
    "            #選全部的電影\n",
    "            sample = all_auxilary\n",
    "\n",
    "            #change\n",
    "            r_3 = np.zeros(len(sample))\n",
    "\n",
    "            for b in range(len(sample)):\n",
    "                yes.append(all_npy[sample[b]])\n",
    "                yesr.append(movie_genre[sample[b]] * usr_genre_norm[z])\n",
    "\n",
    "            for b in range(len(yesr)):\n",
    "                r_3[b]=max(yesr[b])\n",
    "            #print('r_3:',r_3)\n",
    "\n",
    "            yes = np.array(yes)\n",
    "\n",
    "            # positive sample\n",
    "            train_t_sample = train_t[z]\n",
    "            for ta in train_t_sample:\n",
    "                #print(ta,'--> positive feedback')\n",
    "\n",
    "                pos = sample.index(ta)\n",
    "\n",
    "                image_1=np.expand_dims(all_npy[ta],0)\n",
    "                train_f_sample = random.sample(train_f[z],10)\n",
    "\n",
    "                for b in train_f_sample:\n",
    "                    image_2 = np.expand_dims(all_npy[b],0)\n",
    "\n",
    "                    _last_be_relu, _norm_par, _a_list, r3, _auc, _loss, _ = sess.run(\n",
    "                        [last_be_relu, norm_par, a_list_smooth, a_list_soft, auc, loss, train_op], \n",
    "                        feed_dict={user: [z], i: [ta], j: [b], xf: yes, \n",
    "                                   l_id:sample, l_id_len:[len(sample)],\n",
    "                                   positive_id: train_t[z], positive_len:[len(train_t[z])],\n",
    "                                   r: r_3, image_i: image_1, image_j: image_2})\n",
    "\n",
    "                    '''Observe all params\n",
    "                    print('u,vi,vj',_norm_par[:3])\n",
    "                    print('w1,wu,wy,wa,wv',_norm_par[3:7])\n",
    "                    print('beta',_norm_par[7])\n",
    "                    print('Embedding',_norm_par[8])\n",
    "                    print('after softmax:', r3)\n",
    "                    print('before softmax:', _a_list)\n",
    "                    print('---------------------------------------------------')\n",
    "                    '''\n",
    "                    train_auc += _auc\n",
    "                    total_loss += _loss\n",
    "                    length += 1\n",
    "\n",
    "        print(\"{:<20}{}\".format('total_loss', total_loss/length))\n",
    "        print(\"{:<20}{}\".format('train_auc:', train_auc/length))\n",
    "\n",
    "        loss_acc_list.append([total_loss/length, train_auc/length])\n",
    "\n",
    "        print('\\tCurrent time:', time.ctime(), ' sec')\n",
    "        print('==================================================')\n",
    "\n",
    "    print('Total cost time:',time.time()-t0, ' sec')\n",
    "\n",
    "    print('End time:', time.ctime())\n",
    "    \n",
    "    U, Y, A, E, Au, Ay, Aa, Av, B = sess.run([user_latent, item_latent, aux_item, embedding, Wu, Wy, Wa, Wv, Beta])\n",
    "    np.savez('./weight/coldstart/' + SAVE_NAME + '.npz',\n",
    "             U=U, Y=Y, A=A, E=E, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av, B=B)\n",
    "    \n",
    "    return loss_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-25-7d4ad3c7fb45>:141: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "==================================================\n",
      "MRM_E240_user_filter\n",
      "Start time: Fri May 15 21:27:57 2020\n",
      "Epoch: 0\n",
      "total_loss          [[0.52958584]]\n",
      "train_auc:          0.7528571428571429\n",
      "\tCurrent time: Fri May 15 21:31:47 2020  sec\n",
      "==================================================\n",
      "Epoch: 1\n",
      "total_loss          [[0.30963007]]\n",
      "train_auc:          0.8677142857142857\n",
      "\tCurrent time: Fri May 15 21:35:37 2020  sec\n",
      "==================================================\n",
      "Epoch: 2\n",
      "total_loss          [[0.17317505]]\n",
      "train_auc:          0.9335714285714286\n",
      "\tCurrent time: Fri May 15 21:39:27 2020  sec\n",
      "==================================================\n",
      "Epoch: 3\n",
      "total_loss          [[0.09839618]]\n",
      "train_auc:          0.9655714285714285\n",
      "\tCurrent time: Fri May 15 21:43:17 2020  sec\n",
      "==================================================\n",
      "Epoch: 4\n",
      "total_loss          [[0.06665129]]\n",
      "train_auc:          0.9788571428571429\n",
      "\tCurrent time: Fri May 15 21:47:07 2020  sec\n",
      "==================================================\n",
      "Epoch: 5\n",
      "total_loss          [[0.04534691]]\n",
      "train_auc:          0.9887142857142858\n",
      "\tCurrent time: Fri May 15 21:50:57 2020  sec\n",
      "==================================================\n",
      "Total cost time: 1379.4170551300049  sec\n",
      "End time: Fri May 15 21:50:57 2020\n",
      "Epoch: range(1, 7)\n",
      "Loss: [0.5295858383178711, 0.30963006615638733, 0.17317505180835724, 0.0983961820602417, 0.06665129214525223, 0.04534691199660301]\n",
      "Acc: [0.7528571428571429, 0.8677142857142857, 0.9335714285714286, 0.9655714285714285, 0.9788571428571429, 0.9887142857142858]\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAVE_NAME = 'MRM_E{}_{}'.format(embedding_dims, \"user_filter\")\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "user = tf.placeholder(tf.int32,shape=(1,))\n",
    "i = tf.placeholder(tf.int32, shape=(1,))\n",
    "j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "#多少個auxliary \n",
    "xf = tf.placeholder(tf.float32, shape=(None, ft_dim))\n",
    "l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "r = tf.placeholder(tf.float32,shape=(None,))\n",
    "positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "\n",
    "image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "with tf.variable_scope(\"item_level\"):\n",
    "    user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=8))\n",
    "    item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=9)) \n",
    "    aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                               initializer=tf.random_normal_initializer(0,0.1,seed=10))\n",
    "\n",
    "#     W1 = tf.get_variable(\"W1\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wu = tf.get_variable(\"Wu\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wy = tf.get_variable(\"Wy\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wa = tf.get_variable(\"Wa\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wv = tf.get_variable(\"Wv\", [usr_nb, movie_nb, embedding_dims], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#     Wve = tf.get_variable(\"Wve\", [embedding_dims, ft_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "with tf.variable_scope('feature_level'):\n",
    "    embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                           initializer=tf.random_normal_initializer(0.01, 0.001, seed=10))\n",
    "\n",
    "#lookup the latent factors by user and id\n",
    "u = tf.nn.embedding_lookup(user_latent, user)\n",
    "vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "# w1 = tf.nn.embedding_lookup(W1, user)\n",
    "wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user))\n",
    "wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user))\n",
    "wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user))\n",
    "wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user))\n",
    "\n",
    "beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n",
    "\n",
    "a_list = tf.Variable([])\n",
    "q = tf.constant(0)\n",
    "\n",
    "def att_cond(q,a_list):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def att_body(q,a_list):\n",
    "    xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "\n",
    "    a_list = tf.concat([a_list,[(tf.nn.relu(tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                            tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                            tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                            tf.matmul(wvui, tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "    q += 1\n",
    "    return q, a_list\n",
    "\n",
    "_, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "\n",
    "norm_par = [wu,wy,wa,wv]\n",
    "\n",
    "wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "\n",
    "last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "\n",
    "aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "q = tf.constant(0)\n",
    "\n",
    "def sum_att_cond(q,aux_np):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def sum_att_body(q,aux_np):\n",
    "    aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "    q += 1\n",
    "    return q, aux_np\n",
    "\n",
    "_, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "#矩陣中對應函數各自相乘\n",
    "# ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "l2_norm = tf.add_n([\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "            0.00001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "\n",
    "            0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "            0.00001 * tf.reduce_sum(tf.multiply(embedding,embedding))\n",
    "          ])\n",
    "\n",
    "loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "\n",
    "loss_acc_list = training(SAVE_NAME)\n",
    "\n",
    "# training history\n",
    "epochs = range(1, len(loss_acc_list) + 1)\n",
    "print('Epoch:', epochs)\n",
    "loss = [ls[0].tolist()[0][0] for ls in loss_acc_list]\n",
    "print('Loss:', loss)\n",
    "acc = [ls[1] for ls in loss_acc_list]\n",
    "print('Acc:', acc)\n",
    "print('==================================================')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1\n",
    "\n",
    "def topN(RSls, n):\n",
    "    maxn = np.argsort(RSls)[::-1][:n]\n",
    "    return maxn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def allSortPrepare(testRS):\n",
    "    all_sort = []\n",
    "\n",
    "    for i in range(usr_test_amount):\n",
    "        all_sort.append(topN(list(testRS[i]),len(testRS[i])))\n",
    "\n",
    "    all_sort = np.asarray(all_sort)\n",
    "    print(all_sort.shape)\n",
    "    return all_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DCG(prec_list): #找出前n名的[1,1,1,0,...]\n",
    "    dcg = 0\n",
    "    for i in range(len(prec_list)):\n",
    "        dcg += (2**prec_list[i]-1)/math.log2(i+2)\n",
    "    return dcg\n",
    "\n",
    "def NDCG(target, testRS, num_ndcg, all_sort): #target是真正的喜好\n",
    "    total_ndcg = 0\n",
    "    \n",
    "    for m in range(usr_test_amount): # the number of testing users\n",
    "        idcg = DCG(target[m][:num_ndcg])\n",
    "        \n",
    "        pre_list = []\n",
    "        for s in all_sort[m][:num_ndcg]:\n",
    "            #print(m,s,target[m][s])\n",
    "            pre_list.append(target[m][s]) #把prec_list 的 score加進去\n",
    "        \n",
    "        dcg = DCG(pre_list)\n",
    "        ndcg = dcg/idcg\n",
    "        total_ndcg += ndcg\n",
    "        \n",
    "    avg_ndcg = total_ndcg/usr_test_amount\n",
    "    return avg_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(target,testRS):\n",
    "    total_prec = 0\n",
    "    for u in range(usr_test_amount):\n",
    "        y_true = target[u]\n",
    "        y_scores = testRS[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/usr_test_amount\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(testRS, target, sumtarget, all_sort):\n",
    "    # NDCG\n",
    "    num_ndcgs = [5, 10]\n",
    "    for num_ndcg in num_ndcgs:\n",
    "        print('NDCG@', num_ndcg)\n",
    "        print('NDCG score:', NDCG(target, testRS, num_ndcg, all_sort))\n",
    "        print('*****')\n",
    "\n",
    "    print('\\n==============================\\n')\n",
    "\n",
    "    # MAP\n",
    "    print('MAP:', MAP(target,testRS))\n",
    "    print('\\n==============================\\n')\n",
    "    \n",
    "    # Top N\n",
    "    N = [1, 5]\n",
    "    correct = 0\n",
    "\n",
    "    for n in N:\n",
    "        print('Top', n)\n",
    "        correct = 0\n",
    "\n",
    "        for i in range(len(testRS)):\n",
    "            topn = topN(testRS[i], n)\n",
    "            sum_target = int(np.sum(target[i]))\n",
    "\n",
    "            TP = 0\n",
    "            for i in topn:\n",
    "                if i < sum_target:\n",
    "                    TP += 1\n",
    "\n",
    "            correct += TP\n",
    "\n",
    "        prec = correct/(len(testRS)*n) #150*n\n",
    "        recall = correct/sumtarget\n",
    "\n",
    "        print('prec:', prec)\n",
    "        print('recall:', recall)\n",
    "        print('F1_score:', F1_score(prec, recall))\n",
    "        print('*****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "usr_test_amount = 100\n",
    "movie_test_amount = 32\n",
    "'''\n",
    "def testing(U, Y, A, E, Au, Ay, Aa, Av, B):\n",
    "    #with Embedding\n",
    "    result = np.zeros((usr_test_amount, movie_nb))\n",
    "    RS = np.zeros((usr_test_amount, movie_nb))\n",
    "\n",
    "    #test_idx --> Test 的 index length = 150\n",
    "    sum_alpha = 0\n",
    "    test_yes_id = []\n",
    "\n",
    "    for s in range(usr_test_amount):\n",
    "#         print(s, test_idx[s])\n",
    "\n",
    "        yes = []\n",
    "        sample = train_t[test_idx[s]]\n",
    "        alpha = np.zeros([len(sample)])\n",
    "\n",
    "        for a in range(len(sample)):\n",
    "            r = np.max(movie_genre[sample[a]] * usr_genre_norm[test_idx[s]]) #sample a 的category vec *user_category vec\n",
    "\n",
    "    # #         ''' Observe each part in attention\n",
    "    #         WuUu = np.sum(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0).T))\n",
    "    #         WyYy = np.sum(np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T))\n",
    "    #         WaAa = np.sum(np.dot(Aa[test_idx[s]],np.expand_dims(A[sample[a]],0).T))\n",
    "    #         WvVy = np.sum(np.dot(np.dot(Av[test_idx[s]], E),np.expand_dims(all_npy[sample[a]],0).T))\n",
    "    #         print('The sum of each par -->',\n",
    "    #               '\\nw1:',testW1,\n",
    "    #               '\\nWuU:',WuUu,\n",
    "    #               '\\nwyY:',WyYy,\n",
    "    #               '\\nWaA:',WaAa,\n",
    "    #               '\\nWvV:',WvVy)\n",
    "    # #         '''\n",
    "\n",
    "            alpha_a = (np.dot(Au[test_idx[s]][sample[a]],np.expand_dims(U[test_idx[s]],0).T) + \n",
    "                       np.dot(Ay[test_idx[s]][sample[a]],np.expand_dims(Y[sample[a]],0).T) + \n",
    "                       np.dot(Aa[test_idx[s]][sample[a]],np.expand_dims(A[sample[a]],0).T) +\n",
    "                       np.dot(Av[test_idx[s]][sample[a]],np.dot(E,np.expand_dims(all_npy[sample[a]],0).T)))\n",
    "\n",
    "\n",
    "            # relu part\n",
    "            alpha[a]=np.sum((relu(alpha_a)))*r\n",
    "            # tanh part\n",
    "    #         alpha[a]=np.sum((np.tanh(alpha_a)))*r\n",
    "\n",
    "        mul = np.zeros((1,latent_dim))\n",
    "        added_alpha = np.add(alpha,0.0000000001)\n",
    "        norm_alpha = added_alpha/np.sum(added_alpha)\n",
    "        sum_alpha += np.sum(alpha)\n",
    "\n",
    "#         print(\"{:<15}{}\".format('sum_alpha:', sum_alpha))\n",
    "#         print('==================================================')\n",
    "\n",
    "        for i in range(len(sample)):\n",
    "            mul += norm_alpha[i] * A[sample[i]] # attention alpha*Ai part\n",
    "        new_mul = mul + U[test_idx[s]]  #(U+auxilary)\n",
    "\n",
    "        for k in range(movie_nb):\n",
    "            result[s][k] = np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "            RS[s][k] = np.dot(new_mul,Y[k].T) + np.dot(B[test_idx[s]], np.dot(E, all_npy[k].T))\n",
    "        \n",
    "    #取出test的資料\n",
    "    print(RS.shape)\n",
    "\n",
    "    testRS = np.zeros((usr_test_amount, movie_test_amount)) #shape 150 * 32\n",
    "    target = np.zeros((usr_test_amount, movie_test_amount)) #shape 150 * 32\n",
    "\n",
    "    for z in range(usr_test_amount):\n",
    "        user_id = test_idx[z]\n",
    "        # positive target YouTuber list\n",
    "        youtube_t = test_t[z] \n",
    "        # not target YouTuber list\n",
    "        youtube_f = test_f[z]\n",
    "\n",
    "    #     print(user_id)\n",
    "    #     print(youtube_t)\n",
    "    #     print(youtube_f)\n",
    "\n",
    "        #前面放target的RS\n",
    "        for i in range(len(youtube_t)):\n",
    "            testRS[z][i] = RS[z][youtube_t[i]]\n",
    "            target[z][i] = 1\n",
    "\n",
    "        for i in range(len(youtube_f)):\n",
    "            testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]\n",
    "\n",
    "    #     print(testRS[z])\n",
    "    #     print(target[z])\n",
    "    #     print('==============================')\n",
    "\n",
    "    print(target.shape, testRS.shape)\n",
    "    sumtarget = np.sum(target)\n",
    "    print('num of positive data in testing:', sumtarget) # whole matrix: 4800\n",
    "\n",
    "    # for metrics\n",
    "    metrics(testRS, target, sumtarget, allSortPrepare(testRS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE_NAME = 'MRM_E240_user_filter_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FILE = './weight/coldstart/' + SAVE_NAME + '.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent factor and Each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRM_E240_user_filter\n",
      "User latent shape:  (100, 64)\n",
      "photo latent shape:  (159, 64)\n",
      "Auxilary latent shape:  (159, 64)\n",
      "Embedding shape: (240, 2372)\n",
      "Wu weight shape: (100, 159, 64)\n",
      "Wy weight shape: (100, 159, 64)\n",
      "Wa weight shape: (100, 159, 64)\n",
      "Wv weight shape: (100, 159, 240)\n",
      "Beta shape: (100, 240)\n",
      "(100, 159)\n",
      "(100, 32) (100, 32)\n",
      "num of positive data in testing: 772.0\n",
      "(100, 32)\n",
      "NDCG@ 5\n",
      "NDCG score: 0.47961205153019165\n",
      "*****\n",
      "NDCG@ 10\n",
      "NDCG score: 0.5239102046789831\n",
      "*****\n",
      "\n",
      "==============================\n",
      "\n",
      "MAP: 0.5027238930536495\n",
      "\n",
      "==============================\n",
      "\n",
      "Top 1\n",
      "prec: 0.54\n",
      "recall: 0.06994818652849741\n",
      "F1_score: 0.12385321100917429\n",
      "*****\n",
      "Top 5\n",
      "prec: 0.458\n",
      "recall: 0.2966321243523316\n",
      "F1_score: 0.360062893081761\n",
      "*****\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(SAVE_NAME)\n",
    "\n",
    "params = np.load(SAVE_FILE)\n",
    "\n",
    "U = params['U']\n",
    "Y = params['Y']\n",
    "A = params['A']\n",
    "E = params['E']\n",
    "Au = params['Wu']\n",
    "Ay = params['Wy']\n",
    "Aa = params['Wa']\n",
    "Av = params['Wv']\n",
    "B = params['B']\n",
    "\n",
    "print('User latent shape: ',U.shape)\n",
    "print('photo latent shape: ', Y.shape)\n",
    "print('Auxilary latent shape: ',A.shape)\n",
    "print('Embedding shape:', E.shape)\n",
    "print('Wu weight shape:', Au.shape)\n",
    "print('Wy weight shape:', Ay.shape)\n",
    "print('Wa weight shape:', Aa.shape)\n",
    "print('Wv weight shape:', Av.shape)\n",
    "print('Beta shape:',B.shape)\n",
    "\n",
    "testing(U, Y, A, E, Au, Ay, Aa, Av, B)\n",
    "print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
