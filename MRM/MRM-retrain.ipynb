{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "def writeProgress(msg, count, total):\n",
    "    sys.stdout.write(msg + \"{:.2%}\\r\".format(count/total))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: (165, 4876)\n",
      "Movie genre: (165, 20)\n",
      "User following: (1582, 165)\n",
      "User genre: (1582, 20)\n"
     ]
    }
   ],
   "source": [
    "all_npy = np.load('./npy/all_4876.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "\n",
    "print('All features:', all_npy.shape)\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582 165\n",
      "150 32\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "\n",
    "print(usr_nb, movie_nb)\n",
    "\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 32\n",
    "\n",
    "print(usr_test_amount, movie_test_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize usr_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 20)\n"
     ]
    }
   ],
   "source": [
    "usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "for i in range(len(usr_genre)):\n",
    "    usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "print(usr_genre_norm.shape)\n",
    "# print('Before:', usr_genre)\n",
    "# print('After:', usr_genre_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & testing split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followers: 1\n",
      "Max number of followers: 520\n",
      "Avg of followers: 142.0969696969697\n",
      "The num of followers over 5: 163\n"
     ]
    }
   ],
   "source": [
    "#The number of followers for each movie\n",
    "moive_followers = np.sum(usr_following, axis=0)\n",
    "# print(moive_followers)\n",
    "\n",
    "print('Min number of followers:', np.min(moive_followers))\n",
    "print('Max number of followers:', np.max(moive_followers))\n",
    "print('Avg of followers:', np.mean(moive_followers))\n",
    "\n",
    "asc = np.sort(moive_followers)\n",
    "# print(asc)\n",
    "desc = np.flip(asc)\n",
    "# print(desc)\n",
    "\n",
    "over5 = 0\n",
    "for num in moive_followers:\n",
    "    if num >= 5:\n",
    "        over5 += 1\n",
    "print('The num of followers over 5:', over5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 50: 125\n",
      "Over 100: 89\n",
      "Over 150: 58\n",
      "Over 200: 42\n",
      "Over 250: 31\n",
      "Over 300: 21\n"
     ]
    }
   ],
   "source": [
    "print('Over 50:', np.sum(moive_followers >= 50))\n",
    "print('Over 100:', np.sum(moive_followers >= 100))\n",
    "print('Over 150:', np.sum(moive_followers >= 150))\n",
    "print('Over 200:', np.sum(moive_followers >= 200))\n",
    "print('Over 250:', np.sum(moive_followers >= 250))\n",
    "print('Over 300:', np.sum(moive_followers >= 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42,) [  0   2   3   4   9  12  24  28  30  34  40  44  49  55  57  58  60  66\n",
      "  68  78  80  81  84  86  87  99 101 102 112 119 122 123 125 126 127 128\n",
      " 129 134 144 156 161 164]\n",
      "32 [0, 2, 3, 12, 24, 28, 30, 44, 49, 55, 57, 58, 60, 66, 78, 80, 81, 84, 86, 87, 102, 112, 119, 122, 123, 125, 127, 128, 129, 144, 161, 164]\n"
     ]
    }
   ],
   "source": [
    "over200_idx = np.nonzero(moive_followers >= 200)[0]\n",
    "print(over200_idx.shape, over200_idx)\n",
    "\n",
    "random.seed(42)\n",
    "movie_test_idx = sorted(random.sample(list(over200_idx), movie_test_amount))\n",
    "print(len(movie_test_idx), movie_test_idx) # 32 [0, 2, 3, 12, 24, 28, 30, 44, 49, 55, 57, 58, 60, 66, 78, 80, 81, 84, 86, 87, 102, 112, 119, 122, 123, 125, 127, 128, 129, 144, 161, 164]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followings: 10\n",
      "Max number of followings: 133\n",
      "Avg of followers: 14.820480404551201\n"
     ]
    }
   ],
   "source": [
    "#The number of following movie for each user\n",
    "each_user = np.sum(usr_following, axis=1)\n",
    "# print(each_user)\n",
    "\n",
    "print('Min number of followings:', np.min(each_user))\n",
    "print('Max number of followings:', np.max(each_user))\n",
    "print('Avg of followers:', np.mean(each_user))\n",
    "\n",
    "asc = np.sort(each_user)\n",
    "# print(each_user)\n",
    "# print(asc)\n",
    "desc = np.flip(asc)\n",
    "# print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 10: 1582\n",
      "Over 12: 937\n",
      "Over 14: 613\n",
      "Over 16: 440\n",
      "Over 18: 315\n",
      "Over 20: 229\n"
     ]
    }
   ],
   "source": [
    "print('Over 10:', np.sum(each_user >= 10))\n",
    "print('Over 12:', np.sum(each_user >= 12))\n",
    "print('Over 14:', np.sum(each_user >= 14))\n",
    "print('Over 16:', np.sum(each_user >= 16))\n",
    "print('Over 18:', np.sum(each_user >= 18))\n",
    "print('Over 20:', np.sum(each_user >= 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582\n",
      "150 [13, 51, 54, 61, 65, 88, 93, 96, 114, 130]\n"
     ]
    }
   ],
   "source": [
    "usr_idx = [i for i in range(len(usr_following))]\n",
    "print(len(usr_idx))\n",
    "\n",
    "random.seed(42)\n",
    "test_idx = sorted(random.sample(usr_idx, usr_test_amount))\n",
    "print(len(test_idx), test_idx[:10]) # 150 [13, 51, 54, 61, 65, 88, 93, 96, 114, 130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init\n",
    "train_t = []\n",
    "train_f = []\n",
    "test_t = []\n",
    "test_f = []\n",
    "\n",
    "for i in range(usr_nb):\n",
    "    # init\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    t_for_test = []\n",
    "    f_for_test = []\n",
    "    \n",
    "    if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "        for j in range(movie_nb):\n",
    "            if usr_following[i][j] == 1:\n",
    "                t_for_train.append(j)\n",
    "            else:\n",
    "                f_for_train.append(j)\n",
    "                \n",
    "        train_t.append(t_for_train)\n",
    "        train_f.append(f_for_train)\n",
    "#         print(len(t_for_train) + len(f_for_train))\n",
    "        \n",
    "    else: #if in test id, choose half of true and other \n",
    "        temp_t = []\n",
    "        temp_f = []\n",
    "        \n",
    "        for j in range(movie_nb):\n",
    "            if usr_following[i][j] == 1:\n",
    "                temp_t.append(j)\n",
    "            else:\n",
    "                temp_f.append(j)\n",
    "        \n",
    "        # random choose half true and half false for test \n",
    "        t_for_test = random.sample(temp_t, math.ceil(0.5*len(temp_t)))\n",
    "        f_for_test  = random.sample(temp_f, movie_test_amount-len(t_for_test))\n",
    "        \n",
    "        test_t.append(t_for_test)\n",
    "        test_f.append(f_for_test)\n",
    "        \n",
    "        #the others for training\n",
    "        t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "        f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "        train_t.append(t_for_train)\n",
    "        train_f.append(f_for_train)\n",
    "        \n",
    "    if not (len(t_for_train) + len(f_for_train) + len(t_for_test) + len(f_for_test)) == movie_nb:\n",
    "        print('Error!!!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 1582\n",
      "The length of train_f: 1582\n",
      "The length of test_t: 150\n",
      "The length of test_f: 150\n"
     ]
    }
   ],
   "source": [
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_f))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 14.139064475347661\n",
      "Testing: 7.1866666666666665\n"
     ]
    }
   ],
   "source": [
    "#average num of following for training user\n",
    "total_train = 0\n",
    "for t in train_t:\n",
    "    total_train += len(t)\n",
    "avg = total_train / usr_nb\n",
    "print('Training:', avg)\n",
    "\n",
    "#average num of following for testing user\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test / usr_test_amount\n",
    "print('Testing:', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_auxilary = [i for i in range(movie_nb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAVE_NAME = 'MRM_ALL_Embedding200_L2_retrain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 4876 200\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128 # latent dims\n",
    "ft_dim = all_npy.shape[1] # feature dims\n",
    "embedding_dims = 200\n",
    "\n",
    "print(latent_dim, ft_dim, embedding_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "user = tf.placeholder(tf.int32,shape=(1,))\n",
    "i = tf.placeholder(tf.int32, shape=(1,))\n",
    "j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "#多少個auxliary \n",
    "xf = tf.placeholder(tf.float32, shape=(None, ft_dim))\n",
    "l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "r = tf.placeholder(tf.float32,shape=(None,))\n",
    "positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "\n",
    "image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "with tf.variable_scope(\"item_level\"):\n",
    "    user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=3)) \n",
    "    aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                               initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    \n",
    "#     W1 = tf.get_variable(\"W1\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wu = tf.get_variable(\"Wu\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wy = tf.get_variable(\"Wy\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wa = tf.get_variable(\"Wa\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wv = tf.get_variable(\"Wv\", [usr_nb, movie_nb, embedding_dims], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#     Wve = tf.get_variable(\"Wve\", [embedding_dims, ft_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "with tf.variable_scope('feature_level'):\n",
    "    embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                           initializer=tf.random_normal_initializer(0.01, 0.001, seed=10))\n",
    "    \n",
    "#lookup the latent factors by user and id\n",
    "u = tf.nn.embedding_lookup(user_latent, user)\n",
    "vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "# w1 = tf.nn.embedding_lookup(W1, user)\n",
    "wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user))\n",
    "wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user))\n",
    "wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user))\n",
    "wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user))\n",
    "\n",
    "beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-20-a7e9e21703c5>:86: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "a_list = tf.Variable([])\n",
    "q = tf.constant(0)\n",
    "\n",
    "def att_cond(q,a_list):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def att_body(q,a_list):\n",
    "    xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    \n",
    "    a_list = tf.concat([a_list,[(tf.nn.relu(tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                            tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                            tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                            tf.matmul(wvui,tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "    q += 1\n",
    "    return q, a_list\n",
    "\n",
    "_, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "\n",
    "norm_par = [wu,wy,wa,wv]\n",
    "\n",
    "wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "\n",
    "last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "\n",
    "aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "q = tf.constant(0)\n",
    "\n",
    "def sum_att_cond(q,aux_np):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def sum_att_body(q,aux_np):\n",
    "    aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "    q += 1\n",
    "    return q, aux_np\n",
    "\n",
    "_, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "#矩陣中對應函數各自相乘\n",
    "# ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "l2_norm = tf.add_n([\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "  \n",
    "            0.01 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "            \n",
    "            0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(embedding,embedding))\n",
    "          ])\n",
    "\n",
    "loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "auc = tf.reduce_mean(tf.to_float(xuij > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: Thu Mar 12 10:58:24 2020\n",
      "Epoch: 0\n",
      "total_loss          [[0.61387082]]\n",
      "train_auc:          0.7867176323319027\n",
      "\tCurrent time: Thu Mar 12 16:18:20 2020  sec\n",
      "==================================================\n",
      "Total cost time: 19192.753071784973  sec\n",
      "End time: Thu Mar 12 16:18:20 2020\n"
     ]
    }
   ],
   "source": [
    "print('Start time:', time.ctime())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "loss_acc_list = []\n",
    "t0 = time.time()\n",
    "\n",
    "train_yes_id=[]\n",
    "\n",
    "for q in range(1):\n",
    "    print('Epoch:',q)\n",
    "    train_auc = 0\n",
    "    total_loss = 0\n",
    "    xuij_auc = 0\n",
    "    length = 0\n",
    "    \n",
    "    for z in range(usr_nb):\n",
    "        writeProgress('Progress:', z, usr_nb)\n",
    "        \"\"\"\n",
    "        yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "        yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "        r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "        \"\"\"\n",
    "        yes = []\n",
    "        yesr = []\n",
    "        \n",
    "#         #選全部的Positive\n",
    "#         sample = random.sample(train_t[z],len(train_t[z]))\n",
    "        #選全部的電影\n",
    "        sample = all_auxilary\n",
    "        \n",
    "        #change\n",
    "        r_3 = np.zeros(len(sample))\n",
    "         \n",
    "        for b in range(len(sample)):\n",
    "            yes.append(all_npy[sample[b]])\n",
    "            yesr.append(movie_genre[sample[b]] * usr_genre_norm[z])\n",
    "        \n",
    "        for b in range(len(yesr)):\n",
    "            r_3[b]=max(yesr[b])\n",
    "        #print('r_3:',r_3)\n",
    "        \n",
    "        yes = np.array(yes)\n",
    "        \n",
    "        # positive sample\n",
    "        train_t_sample = train_t[z]\n",
    "        for ta in train_t_sample:\n",
    "            #print(ta,'--> positive feedback')\n",
    "            \n",
    "            pos = sample.index(ta)\n",
    "            \n",
    "            image_1=np.expand_dims(all_npy[ta],0)\n",
    "            train_f_sample = random.sample(train_f[z],10)\n",
    "            \n",
    "            for b in train_f_sample:\n",
    "                image_2 = np.expand_dims(all_npy[b],0)\n",
    "                \n",
    "                _last_be_relu, _norm_par, _a_list, r3, _auc, _loss, _ = sess.run(\n",
    "                    [last_be_relu, norm_par, a_list_smooth, a_list_soft, auc, loss, train_op], \n",
    "                    feed_dict={user: [z], i: [ta], j: [b], xf: yes, \n",
    "                               l_id:sample, l_id_len:[len(sample)],\n",
    "                               positive_id: train_t[z], positive_len:[len(train_t[z])],\n",
    "                               r: r_3, image_i: image_1, image_j: image_2})\n",
    "                \n",
    "                ''' check weight\n",
    "                print('params:', len(_norm_par))\n",
    "                print('u,vi,vj',_norm_par[:3])\n",
    "                print('wu, wy, wa, wv',_norm_par[3:7])\n",
    "                print('beta', _norm_par[7])\n",
    "                print('Embedding', _norm_par[8])\n",
    "                print('before softmax:', _a_list)\n",
    "                print('after softmax:', r3)\n",
    "                print('---------------------------------------------------')\n",
    "                '''\n",
    "\n",
    "                train_auc += _auc\n",
    "                total_loss += _loss\n",
    "                length += 1\n",
    "    \n",
    "    print(\"{:<20}{}\".format('total_loss', total_loss/length))\n",
    "    print(\"{:<20}{}\".format('train_auc:', train_auc/length))\n",
    "    \n",
    "    loss_acc_list.append([total_loss/length, train_auc/length])\n",
    "    \n",
    "    print('\\tCurrent time:', time.ctime(), ' sec')\n",
    "    print('==================================================')\n",
    "    \n",
    "print('Total cost time:',time.time()-t0, ' sec')\n",
    "\n",
    "print('End time:', time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "loss= [[0.61387082]]\n",
      "acc= 0.7867176323319027\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(loss_acc_list)):\n",
    "    print('Iteration:',i)\n",
    "    print('loss=',loss_acc_list[i][0])\n",
    "    print('acc=',loss_acc_list[i][1])\n",
    "    print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(1, 2)\n",
      "[0.6138708199213162]\n",
      "[0.7867176323319027]\n"
     ]
    }
   ],
   "source": [
    "# training history\n",
    "epochs = range(1, len(loss_acc_list) + 1)\n",
    "print(epochs)\n",
    "loss = [ls[0].tolist()[0][0] for ls in loss_acc_list]\n",
    "print(loss)\n",
    "acc = [ls[1] for ls in loss_acc_list]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 繪製結果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent factor and Each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "U, Y, A, E, Au, Ay, Aa, Av, B = sess.run([user_latent, item_latent, aux_item, embedding, Wu, Wy, Wa, Wv, Beta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User latent shape:  (1582, 128)\n",
      "photo latent shape:  (165, 128)\n",
      "Embedding shape: (200, 4876)\n",
      "Auxilary latent shape:  (165, 128)\n",
      "Wu weight shape: (1582, 165, 128)\n",
      "Wy weight shape: (1582, 165, 128)\n",
      "Wa weight shape: (1582, 165, 128)\n",
      "Wv weight shape: (1582, 165, 200)\n",
      "Beta shape: (1582, 200)\n"
     ]
    }
   ],
   "source": [
    "print('User latent shape: ',U.shape)\n",
    "print('photo latent shape: ', Y.shape)\n",
    "print('Embedding shape:', E.shape)\n",
    "print('Auxilary latent shape: ',A.shape)\n",
    "print('Wu weight shape:',Au.shape)\n",
    "print('Wy weight shape:', Ay.shape)\n",
    "print('Wa weight shape:', Aa.shape)\n",
    "print('Wv weight shape:', Av.shape)\n",
    "print('Beta shape:',B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savez('./weight/' + SAVE_NAME + '.npz', \n",
    "         U=U, Y=Y, A=A, E=E, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av, B=B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.lib.npyio.NpzFile object at 0x7f8edde210b8>\n"
     ]
    }
   ],
   "source": [
    "params = np.load('./weight/' + SAVE_NAME + '.npz')\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
