{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "def writeProgress(msg, count, total):\n",
    "    sys.stdout.write(msg + \"{:.2%}\\r\".format(count/total))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: (165, 2372)\n",
      "Movie genre: (165, 20)\n",
      "User following: (1582, 165)\n",
      "User genre: (1582, 20)\n"
     ]
    }
   ],
   "source": [
    "all_npy = np.load('./npy/all_2372.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "\n",
    "print('All features:', all_npy.shape)\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582 165\n",
      "64 2372 240\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "print(usr_nb, movie_nb)\n",
    "\n",
    "# usr_test_amount = 150\n",
    "# movie_test_amount = 32\n",
    "# print(usr_test_amount, movie_test_amount)\n",
    "\n",
    "latent_dim = 64 # latent dims\n",
    "ft_dim = all_npy.shape[1] # feature dims\n",
    "embedding_dims = 240\n",
    "print(latent_dim, ft_dim, embedding_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize usr_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 20)\n"
     ]
    }
   ],
   "source": [
    "usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "for i in range(len(usr_genre)):\n",
    "    usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "print(usr_genre_norm.shape)\n",
    "# print('Before:', usr_genre)\n",
    "# print('After:', usr_genre_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & testing split\n",
    "## Prepare\n",
    "### Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followers: 1\n",
      "Max number of followers: 520\n",
      "Avg of followers: 142.0969696969697\n",
      "The num of followers over 5: 163\n"
     ]
    }
   ],
   "source": [
    "#The number of followers for each movie\n",
    "moive_followers = np.sum(usr_following, axis=0)\n",
    "# print(moive_followers)\n",
    "\n",
    "print('Min number of followers:', np.min(moive_followers))\n",
    "print('Max number of followers:', np.max(moive_followers))\n",
    "print('Avg of followers:', np.mean(moive_followers))\n",
    "\n",
    "asc = np.sort(moive_followers)\n",
    "# print(asc)\n",
    "desc = np.flip(asc)\n",
    "# print(desc)\n",
    "\n",
    "over5 = 0\n",
    "for num in moive_followers:\n",
    "    if num >= 5:\n",
    "        over5 += 1\n",
    "print('The num of followers over 5:', over5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<= 10: 3\n",
      "<= 20: 13\n",
      "<= 30: 21\n",
      "<= 40: 32\n",
      "<= 50: 40\n",
      "<= 100: 76\n",
      "(76,) [  6   7   8  11  13  14  15  16  17  19  20  23  26  27  29  31  32  33\n",
      "  35  36  38  39  41  43  45  46  47  48  51  54  56  59  61  63  65  67\n",
      "  69  70  71  73  76  82  83  88  90  92  94  95  97  98 105 107 109 110\n",
      " 113 115 116 117 124 130 132 133 135 136 138 139 140 145 146 148 150 155\n",
      " 157 158 160 162]\n"
     ]
    }
   ],
   "source": [
    "print('<= 10:', np.sum(moive_followers <= 10))\n",
    "print('<= 20:', np.sum(moive_followers <= 20))\n",
    "print('<= 30:', np.sum(moive_followers <= 30))\n",
    "print('<= 40:', np.sum(moive_followers <= 40))\n",
    "print('<= 50:', np.sum(moive_followers <= 50))\n",
    "print('<= 100:', np.sum(moive_followers <= 100))\n",
    "less_idx = np.nonzero(moive_followers <= 100)[0]\n",
    "print(less_idx.shape, less_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 165)\n",
      "(165, 1582)\n"
     ]
    }
   ],
   "source": [
    "print(usr_following.shape)\n",
    "usr_following = usr_following.T\n",
    "print(usr_following.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 6\n",
      "Sum: 37\n",
      "37\n",
      "==================================================\n",
      "Index: 7\n",
      "Sum: 1\n",
      "38\n",
      "==================================================\n",
      "Index: 8\n",
      "Sum: 37\n",
      "69\n",
      "==================================================\n",
      "Index: 11\n",
      "Sum: 75\n",
      "141\n",
      "==================================================\n",
      "Index: 13\n",
      "Sum: 97\n",
      "221\n",
      "==================================================\n",
      "Index: 14\n",
      "Sum: 23\n",
      "235\n",
      "==================================================\n",
      "Index: 15\n",
      "Sum: 18\n",
      "248\n",
      "==================================================\n",
      "Index: 16\n",
      "Sum: 31\n",
      "269\n",
      "==================================================\n",
      "Index: 17\n",
      "Sum: 61\n",
      "314\n",
      "==================================================\n",
      "Index: 19\n",
      "Sum: 78\n",
      "357\n",
      "==================================================\n",
      "Index: 20\n",
      "Sum: 61\n",
      "394\n",
      "==================================================\n",
      "Index: 23\n",
      "Sum: 72\n",
      "433\n",
      "==================================================\n",
      "Index: 26\n",
      "Sum: 90\n",
      "484\n",
      "==================================================\n",
      "Index: 27\n",
      "Sum: 23\n",
      "497\n",
      "==================================================\n",
      "Index: 29\n",
      "Sum: 32\n",
      "510\n",
      "==================================================\n",
      "Index: 31\n",
      "Sum: 58\n",
      "532\n",
      "==================================================\n",
      "Index: 32\n",
      "Sum: 61\n",
      "572\n",
      "==================================================\n",
      "Index: 33\n",
      "Sum: 80\n",
      "624\n",
      "==================================================\n",
      "Index: 35\n",
      "Sum: 11\n",
      "628\n",
      "==================================================\n",
      "Index: 36\n",
      "Sum: 78\n",
      "652\n",
      "==================================================\n",
      "Index: 38\n",
      "Sum: 28\n",
      "659\n",
      "==================================================\n",
      "Index: 39\n",
      "Sum: 49\n",
      "677\n",
      "==================================================\n",
      "Index: 41\n",
      "Sum: 82\n",
      "717\n",
      "==================================================\n",
      "Index: 43\n",
      "Sum: 70\n",
      "743\n",
      "==================================================\n",
      "Index: 45\n",
      "Sum: 81\n",
      "778\n",
      "==================================================\n",
      "Index: 46\n",
      "Sum: 77\n",
      "810\n",
      "==================================================\n",
      "Index: 47\n",
      "Sum: 89\n",
      "838\n",
      "==================================================\n",
      "Index: 48\n",
      "Sum: 49\n",
      "849\n",
      "==================================================\n",
      "Index: 51\n",
      "Sum: 19\n",
      "851\n",
      "==================================================\n",
      "Index: 54\n",
      "Sum: 18\n",
      "854\n",
      "==================================================\n",
      "Index: 56\n",
      "Sum: 22\n",
      "861\n",
      "==================================================\n",
      "Index: 59\n",
      "Sum: 24\n",
      "864\n",
      "==================================================\n",
      "Index: 61\n",
      "Sum: 41\n",
      "879\n",
      "==================================================\n",
      "Index: 63\n",
      "Sum: 58\n",
      "893\n",
      "==================================================\n",
      "Index: 65\n",
      "Sum: 4\n",
      "894\n",
      "==================================================\n",
      "Index: 67\n",
      "Sum: 76\n",
      "903\n",
      "==================================================\n",
      "Index: 69\n",
      "Sum: 40\n",
      "909\n",
      "==================================================\n",
      "Index: 70\n",
      "Sum: 41\n",
      "922\n",
      "==================================================\n",
      "Index: 71\n",
      "Sum: 20\n",
      "926\n",
      "==================================================\n",
      "Index: 73\n",
      "Sum: 43\n",
      "931\n",
      "==================================================\n",
      "Index: 76\n",
      "Sum: 93\n",
      "956\n",
      "==================================================\n",
      "Index: 82\n",
      "Sum: 78\n",
      "987\n",
      "==================================================\n",
      "Index: 83\n",
      "Sum: 82\n",
      "1003\n",
      "==================================================\n",
      "Index: 88\n",
      "Sum: 44\n",
      "1007\n",
      "==================================================\n",
      "Index: 90\n",
      "Sum: 68\n",
      "1015\n",
      "==================================================\n",
      "Index: 92\n",
      "Sum: 73\n",
      "1029\n",
      "==================================================\n",
      "Index: 94\n",
      "Sum: 73\n",
      "1036\n",
      "==================================================\n",
      "Index: 95\n",
      "Sum: 31\n",
      "1039\n",
      "==================================================\n",
      "Index: 97\n",
      "Sum: 9\n",
      "1042\n",
      "==================================================\n",
      "Index: 98\n",
      "Sum: 72\n",
      "1051\n",
      "==================================================\n",
      "Index: 105\n",
      "Sum: 71\n",
      "1063\n",
      "==================================================\n",
      "Index: 107\n",
      "Sum: 97\n",
      "1079\n",
      "==================================================\n",
      "Index: 109\n",
      "Sum: 59\n",
      "1083\n",
      "==================================================\n",
      "Index: 110\n",
      "Sum: 33\n",
      "1086\n",
      "==================================================\n",
      "Index: 113\n",
      "Sum: 12\n",
      "1087\n",
      "==================================================\n",
      "Index: 115\n",
      "Sum: 35\n",
      "1093\n",
      "==================================================\n",
      "Index: 116\n",
      "Sum: 39\n",
      "1098\n",
      "==================================================\n",
      "Index: 117\n",
      "Sum: 63\n",
      "1104\n",
      "==================================================\n",
      "Index: 124\n",
      "Sum: 52\n",
      "1109\n",
      "==================================================\n",
      "Index: 130\n",
      "Sum: 19\n",
      "1111\n",
      "==================================================\n",
      "Index: 132\n",
      "Sum: 37\n",
      "1117\n",
      "==================================================\n",
      "Index: 133\n",
      "Sum: 48\n",
      "1123\n",
      "==================================================\n",
      "Index: 135\n",
      "Sum: 64\n",
      "1125\n",
      "==================================================\n",
      "Index: 136\n",
      "Sum: 46\n",
      "1126\n",
      "==================================================\n",
      "Index: 138\n",
      "Sum: 83\n",
      "1133\n",
      "==================================================\n",
      "Index: 139\n",
      "Sum: 14\n",
      "1136\n",
      "==================================================\n",
      "Index: 140\n",
      "Sum: 20\n",
      "1136\n",
      "==================================================\n",
      "Index: 145\n",
      "Sum: 25\n",
      "1136\n",
      "==================================================\n",
      "Index: 146\n",
      "Sum: 26\n",
      "1137\n",
      "==================================================\n",
      "Index: 148\n",
      "Sum: 64\n",
      "1144\n",
      "==================================================\n",
      "Index: 150\n",
      "Sum: 96\n",
      "1159\n",
      "==================================================\n",
      "Index: 155\n",
      "Sum: 40\n",
      "1166\n",
      "==================================================\n",
      "Index: 157\n",
      "Sum: 66\n",
      "1170\n",
      "==================================================\n",
      "Index: 158\n",
      "Sum: 89\n",
      "1178\n",
      "==================================================\n",
      "Index: 160\n",
      "Sum: 29\n",
      "1185\n",
      "==================================================\n",
      "Index: 162\n",
      "Sum: 11\n",
      "1185\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "st = set()\n",
    "for idx in less_idx:\n",
    "    print('Index:', idx)\n",
    "    print('Sum:', usr_following[idx].sum())\n",
    "#     print(usr_following[idx])\n",
    "    li = list(np.where(usr_following[idx] == 1)[0])\n",
    "#     print(li)\n",
    "    st = st | set(li)\n",
    "    print(len(st))\n",
    "    print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1185 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "test_idx = list(st)\n",
    "test_idx.sort()\n",
    "print(len(test_idx), test_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1185 76\n"
     ]
    }
   ],
   "source": [
    "usr_test_amount = len(test_idx)\n",
    "movie_test_amount = len(less_idx)\n",
    "print(usr_test_amount, movie_test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 165)\n"
     ]
    }
   ],
   "source": [
    "usr_following = usr_following.T\n",
    "print(usr_following.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat of user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1185, 76)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldarea = usr_following[test_idx, :][:, less_idx]\n",
    "coldarea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followings: 1\n",
      "Max number of followings: 52\n",
      "Avg of followers: 3.220253164556962\n"
     ]
    }
   ],
   "source": [
    "#The number of following movie for each user\n",
    "each_user = np.sum(coldarea, axis=1)\n",
    "# print(each_user)\n",
    "\n",
    "print('Min number of followings:', np.min(each_user))\n",
    "print('Max number of followings:', np.max(each_user))\n",
    "print('Avg of followers:', np.mean(each_user))\n",
    "\n",
    "asc = np.sort(each_user)\n",
    "# print(each_user)\n",
    "# print(asc)\n",
    "desc = np.flip(asc)\n",
    "# print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">= 1 : 1185\n",
      ">= 2 : 831\n",
      ">= 3 : 554\n",
      ">= 4 : 377\n",
      ">= 5 : 228\n",
      ">= 6 : 161\n",
      ">= 7 : 108\n",
      ">= 8 : 76\n",
      ">= 9 : 53\n",
      ">= 10 : 39\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    print('>=', i, ':', np.sum(each_user >= i))\n",
    "# print('>', i, ':', np.sum(each_user > 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_idx = []\n",
    "for i in test_idx:\n",
    "    add = 0\n",
    "    for j in less_idx:\n",
    "        if usr_following[i][j] == 1:\n",
    "            add += 1\n",
    "            \n",
    "    if add >= 6:\n",
    "        new_test_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [11, 21, 24, 30, 31, 43, 48, 52, 57, 71]\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "test_idx = random.sample(new_test_idx, 100)\n",
    "test_idx.sort()\n",
    "print(len(test_idx), test_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 32\n"
     ]
    }
   ],
   "source": [
    "usr_test_amount = len(test_idx)\n",
    "movie_test_amount = 32 #math.floor(len(less_idx)*0.5)\n",
    "print(usr_test_amount, movie_test_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init\n",
    "random.seed(42)\n",
    "train_t = []\n",
    "train_f = []\n",
    "test_t = []\n",
    "test_f = []\n",
    "\n",
    "for i in test_idx:\n",
    "    # init\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    t_for_test = []\n",
    "    f_for_test = []\n",
    "    \n",
    "    temp_t = []\n",
    "    temp_f = []\n",
    "    for j in less_idx:\n",
    "        if usr_following[i][j] == 1:\n",
    "            temp_t.append(j)\n",
    "        else:\n",
    "            temp_f.append(j)\n",
    "            \n",
    "    t_for_test = random.sample(temp_t, math.ceil(0.5*len(temp_t)))\n",
    "    f_for_test = random.sample(temp_f, movie_test_amount-len(t_for_test))\n",
    "    \n",
    "    test_t.append(t_for_test)\n",
    "    test_f.append(f_for_test)\n",
    "    \n",
    "    t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "    f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "    train_t.append(t_for_train)\n",
    "    train_f.append(f_for_train)\n",
    "    \n",
    "    if not (len(t_for_train) + len(f_for_train) + len(t_for_test) + len(f_for_test)) == len(less_idx):\n",
    "        print('Error!!!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 100\n",
      "The length of train_f: 100\n",
      "The length of test_t: 100\n",
      "The length of test_f: 100\n"
     ]
    }
   ],
   "source": [
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_f))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 4.41\n",
      "Testing: 4.82\n"
     ]
    }
   ],
   "source": [
    "#average num of following for training user\n",
    "total_train = 0\n",
    "for t in train_t:\n",
    "    total_train += len(t)\n",
    "avg = total_train / usr_test_amount\n",
    "print('Training:', avg)\n",
    "\n",
    "#average num of following for testing user\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test / usr_test_amount\n",
    "print('Testing:', avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_auxilary = [i for i in range(movie_nb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation model\n",
    "## Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(SAVE_NAME):\n",
    "    print('==================================================')\n",
    "    print(SAVE_NAME)\n",
    "    print('Start time:', time.ctime())\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    loss_acc_list = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_yes_id=[]\n",
    "\n",
    "    for q in range(6):\n",
    "        print('Epoch:',q)\n",
    "        train_auc = 0\n",
    "        total_loss = 0\n",
    "        xuij_auc = 0\n",
    "        length = 0\n",
    "\n",
    "        for z in range(usr_test_amount):\n",
    "            writeProgress('Progress:', z, usr_test_amount)\n",
    "            \"\"\"\n",
    "            yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "            yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "            r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "            \"\"\"\n",
    "            yes = []\n",
    "            yesr = []\n",
    "\n",
    "    #         #選全部的Positive\n",
    "    #         sample = random.sample(train_t[z],len(train_t[z]))\n",
    "            #選全部的電影\n",
    "            sample = all_auxilary\n",
    "\n",
    "            #change\n",
    "            r_3 = np.zeros(len(sample))\n",
    "\n",
    "            for b in range(len(sample)):\n",
    "                yes.append(all_npy[sample[b]])\n",
    "                yesr.append(movie_genre[sample[b]] * usr_genre_norm[z])\n",
    "\n",
    "            for b in range(len(yesr)):\n",
    "                r_3[b]=max(yesr[b])\n",
    "            #print('r_3:',r_3)\n",
    "\n",
    "            yes = np.array(yes)\n",
    "\n",
    "            # positive sample\n",
    "            train_t_sample = train_t[z]\n",
    "            for ta in train_t_sample:\n",
    "                #print(ta,'--> positive feedback')\n",
    "\n",
    "                pos = sample.index(ta)\n",
    "\n",
    "                image_1 = np.expand_dims(all_npy[ta],0)\n",
    "                train_f_sample = train_f[z] #random.sample(train_f[z],10)\n",
    "\n",
    "                for b in train_f_sample:\n",
    "                    image_2 = np.expand_dims(all_npy[b],0)\n",
    "\n",
    "                    _last_be_relu, _norm_par, _a_list, r3, _auc, _loss, _ = sess.run(\n",
    "                        [last_be_relu, norm_par, a_list_smooth, a_list_soft, auc, loss, train_op], \n",
    "                        feed_dict={user: [z], i: [ta], j: [b], xf: yes, \n",
    "                                   l_id:sample, l_id_len:[len(sample)],\n",
    "                                   positive_id: train_t[z], positive_len:[len(train_t[z])],\n",
    "                                   r: r_3, image_i: image_1, image_j: image_2})\n",
    "\n",
    "                    '''Observe all params\n",
    "                    print('u,vi,vj',_norm_par[:3])\n",
    "                    print('w1,wu,wy,wa,wv',_norm_par[3:7])\n",
    "                    print('beta',_norm_par[7])\n",
    "                    print('Embedding',_norm_par[8])\n",
    "                    print('after softmax:', r3)\n",
    "                    print('before softmax:', _a_list)\n",
    "                    print('---------------------------------------------------')\n",
    "                    '''\n",
    "                    train_auc += _auc\n",
    "                    total_loss += _loss\n",
    "                    length += 1\n",
    "\n",
    "        print(\"{:<20}{}\".format('total_loss', total_loss/length))\n",
    "        print(\"{:<20}{}\".format('train_auc:', train_auc/length))\n",
    "\n",
    "        loss_acc_list.append([total_loss/length, train_auc/length])\n",
    "\n",
    "        print('\\tCurrent time:', time.ctime(), ' sec')\n",
    "        print('==================================================')\n",
    "\n",
    "    print('Total cost time:',time.time()-t0, ' sec')\n",
    "\n",
    "    print('End time:', time.ctime())\n",
    "    \n",
    "    U, Y, A, E, Au, Ay, Aa, Av, B = sess.run([user_latent, item_latent, aux_item, embedding, Wu, Wy, Wa, Wv, Beta])\n",
    "    np.savez('./weight/coldstart/' + SAVE_NAME + '.npz',\n",
    "             U=U, Y=Y, A=A, E=E, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av, B=B)\n",
    "    \n",
    "    return loss_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-26-8457192f1bab>:141: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "==================================================\n",
      "MRM_E240_movie\n",
      "Start time: Thu May  7 12:50:55 2020\n",
      "Epoch: 0\n",
      "total_loss          [[0.24241042]]\n",
      "train_auc:          0.9055189506135526\n",
      "\tCurrent time: Thu May  7 13:53:13 2020  sec\n",
      "==================================================\n",
      "Epoch: 1\n",
      "total_loss          [[0.04433526]]\n",
      "train_auc:          0.9912954119567189\n",
      "\tCurrent time: Thu May  7 14:56:07 2020  sec\n",
      "==================================================\n",
      "Epoch: 2\n",
      "total_loss          [[0.01241636]]\n",
      "train_auc:          0.9995768603034516\n",
      "\tCurrent time: Thu May  7 15:58:57 2020  sec\n",
      "==================================================\n",
      "Epoch: 3\n",
      "total_loss          [[0.0065547]]\n",
      "train_auc:          0.9998791029438433\n",
      "\tCurrent time: Thu May  7 17:01:31 2020  sec\n",
      "==================================================\n",
      "Epoch: 4\n",
      "total_loss          [[0.00496377]]\n",
      "train_auc:          0.9998791029438433\n",
      "\tCurrent time: Thu May  7 18:03:59 2020  sec\n",
      "==================================================\n",
      "Epoch: 5\n",
      "total_loss          [[0.00408915]]\n",
      "train_auc:          1.0\n",
      "\tCurrent time: Thu May  7 19:06:36 2020  sec\n",
      "==================================================\n",
      "Total cost time: 22538.325130701065  sec\n",
      "End time: Thu May  7 19:06:36 2020\n",
      "Epoch: range(1, 7)\n",
      "Loss: [0.24241042137145996, 0.0443352647125721, 0.012416357174515724, 0.00655469810590148, 0.00496377469971776, 0.004089148249477148]\n",
      "Acc: [0.9055189506135526, 0.9912954119567189, 0.9995768603034516, 0.9998791029438433, 0.9998791029438433, 1.0]\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAVE_NAME = 'MRM_E{}_{}'.format(embedding_dims, \"movie\")\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "user = tf.placeholder(tf.int32,shape=(1,))\n",
    "i = tf.placeholder(tf.int32, shape=(1,))\n",
    "j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "#多少個auxliary \n",
    "xf = tf.placeholder(tf.float32, shape=(None, ft_dim))\n",
    "l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "r = tf.placeholder(tf.float32,shape=(None,))\n",
    "positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "\n",
    "image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "with tf.variable_scope(\"item_level\"):\n",
    "    user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=8))\n",
    "    item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=9)) \n",
    "    aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                               initializer=tf.random_normal_initializer(0,0.1,seed=10))\n",
    "\n",
    "#     W1 = tf.get_variable(\"W1\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wu = tf.get_variable(\"Wu\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wy = tf.get_variable(\"Wy\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wa = tf.get_variable(\"Wa\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wv = tf.get_variable(\"Wv\", [usr_nb, movie_nb, embedding_dims], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#     Wve = tf.get_variable(\"Wve\", [embedding_dims, ft_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "with tf.variable_scope('feature_level'):\n",
    "    embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                           initializer=tf.random_normal_initializer(0.01, 0.001, seed=10))\n",
    "\n",
    "#lookup the latent factors by user and id\n",
    "u = tf.nn.embedding_lookup(user_latent, user)\n",
    "vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "# w1 = tf.nn.embedding_lookup(W1, user)\n",
    "wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user))\n",
    "wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user))\n",
    "wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user))\n",
    "wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user))\n",
    "\n",
    "beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n",
    "\n",
    "a_list = tf.Variable([])\n",
    "q = tf.constant(0)\n",
    "\n",
    "def att_cond(q,a_list):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def att_body(q,a_list):\n",
    "    xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "\n",
    "    a_list = tf.concat([a_list,[(tf.nn.relu(tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                            tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                            tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                            tf.matmul(wvui, tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "    q += 1\n",
    "    return q, a_list\n",
    "\n",
    "_, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "\n",
    "norm_par = [wu,wy,wa,wv]\n",
    "\n",
    "wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "\n",
    "last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "\n",
    "aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "q = tf.constant(0)\n",
    "\n",
    "def sum_att_cond(q,aux_np):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def sum_att_body(q,aux_np):\n",
    "    aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "    q += 1\n",
    "    return q, aux_np\n",
    "\n",
    "_, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "#矩陣中對應函數各自相乘\n",
    "# ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "l2_norm = tf.add_n([\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "            0.00001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "\n",
    "            0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "            0.00001 * tf.reduce_sum(tf.multiply(embedding,embedding))\n",
    "          ])\n",
    "\n",
    "loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "\n",
    "loss_acc_list = training(SAVE_NAME)\n",
    "\n",
    "# training history\n",
    "epochs = range(1, len(loss_acc_list) + 1)\n",
    "print('Epoch:', epochs)\n",
    "loss = [ls[0].tolist()[0][0] for ls in loss_acc_list]\n",
    "print('Loss:', loss)\n",
    "acc = [ls[1] for ls in loss_acc_list]\n",
    "print('Acc:', acc)\n",
    "print('==================================================')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1\n",
    "\n",
    "def topN(RSls, n):\n",
    "    maxn = np.argsort(RSls)[::-1][:n]\n",
    "    return maxn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def allSortPrepare(testRS):\n",
    "    all_sort = []\n",
    "\n",
    "    for i in range(usr_test_amount):\n",
    "        all_sort.append(topN(list(testRS[i]),len(testRS[i])))\n",
    "\n",
    "    all_sort = np.asarray(all_sort)\n",
    "    print(all_sort.shape)\n",
    "    return all_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DCG(prec_list): #找出前n名的[1,1,1,0,...]\n",
    "    dcg = 0\n",
    "    for i in range(len(prec_list)):\n",
    "        dcg += (2**prec_list[i]-1)/math.log2(i+2)\n",
    "    return dcg\n",
    "\n",
    "def NDCG(target, testRS, num_ndcg, all_sort): #target是真正的喜好\n",
    "    total_ndcg = 0\n",
    "    \n",
    "    for m in range(usr_test_amount): # the number of testing users\n",
    "        idcg = DCG(target[m][:num_ndcg])\n",
    "        \n",
    "        pre_list = []\n",
    "        for s in all_sort[m][:num_ndcg]:\n",
    "            #print(m,s,target[m][s])\n",
    "            pre_list.append(target[m][s]) #把prec_list 的 score加進去\n",
    "        \n",
    "        dcg = DCG(pre_list)\n",
    "        ndcg = dcg/idcg\n",
    "        total_ndcg += ndcg\n",
    "        \n",
    "    avg_ndcg = total_ndcg/usr_test_amount\n",
    "    return avg_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(target,testRS):\n",
    "    total_prec = 0\n",
    "    for u in range(usr_test_amount):\n",
    "        y_true = target[u]\n",
    "        y_scores = testRS[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/usr_test_amount\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(testRS, target, sumtarget, all_sort):\n",
    "    print('\\n==============================\\n')\n",
    "    # Top N\n",
    "    N = [1, 5]\n",
    "    correct = 0\n",
    "\n",
    "    for n in N:\n",
    "        print('Top', n)\n",
    "        correct = 0\n",
    "\n",
    "        for i in range(len(testRS)):\n",
    "            topn = topN(testRS[i], n)\n",
    "            sum_target = int(np.sum(target[i]))\n",
    "\n",
    "            TP = 0\n",
    "            for i in topn:\n",
    "                if i < sum_target:\n",
    "                    TP += 1\n",
    "\n",
    "            correct += TP\n",
    "\n",
    "        prec = correct/(len(testRS)*n) #150*n\n",
    "        recall = correct/sumtarget\n",
    "\n",
    "        print('prec:', prec)\n",
    "        print('recall:', recall)\n",
    "        print('F1_score:', F1_score(prec, recall))\n",
    "        print('*****')\n",
    "\n",
    "    print('\\n==============================\\n')\n",
    "\n",
    "    # NDCG\n",
    "    num_ndcgs = [5, 10]\n",
    "    for num_ndcg in num_ndcgs:\n",
    "        print('NDCG@', num_ndcg)\n",
    "        print('NDCG score:', NDCG(target, testRS, num_ndcg, all_sort))\n",
    "        print('*****')\n",
    "\n",
    "    print('\\n==============================\\n')\n",
    "\n",
    "    # MAP\n",
    "    print('MAP:', MAP(target,testRS))\n",
    "    print('\\n==============================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def testing(U, Y, A, E, Au, Ay, Aa, Av, B):\n",
    "    #with Embedding\n",
    "    result = np.zeros((usr_test_amount, movie_nb))\n",
    "    RS = np.zeros((usr_test_amount, movie_nb))\n",
    "\n",
    "    #test_idx --> Test 的 index length = 150\n",
    "    sum_alpha = 0\n",
    "    test_yes_id = []\n",
    "\n",
    "    for s in range(usr_test_amount):\n",
    "#         print(s, test_idx[s])\n",
    "        \n",
    "        yes = []\n",
    "        sample = [i for i in range(movie_nb)]\n",
    "        alpha = np.zeros([len(sample)])\n",
    "        \n",
    "        for a in range(len(sample)):\n",
    "            r = np.max(movie_genre[sample[a]] * usr_genre_norm[test_idx[s]]) #sample a 的category vec *user_category vec\n",
    "\n",
    "    # #         ''' Observe each part in attention\n",
    "    #         WuUu = np.sum(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0).T))\n",
    "    #         WyYy = np.sum(np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T))\n",
    "    #         WaAa = np.sum(np.dot(Aa[test_idx[s]],np.expand_dims(A[sample[a]],0).T))\n",
    "    #         WvVy = np.sum(np.dot(np.dot(Av[test_idx[s]], E),np.expand_dims(all_npy[sample[a]],0).T))\n",
    "    #         print('The sum of each par -->',\n",
    "    #               '\\nw1:',testW1,\n",
    "    #               '\\nWuU:',WuUu,\n",
    "    #               '\\nwyY:',WyYy,\n",
    "    #               '\\nWaA:',WaAa,\n",
    "    #               '\\nWvV:',WvVy)\n",
    "    # #         '''\n",
    "\n",
    "            alpha_a = (np.dot(Au[test_idx[s]][sample[a]],np.expand_dims(U[test_idx[s]],0).T) + \n",
    "                       np.dot(Ay[test_idx[s]][sample[a]],np.expand_dims(Y[sample[a]],0).T) + \n",
    "                       np.dot(Aa[test_idx[s]][sample[a]],np.expand_dims(A[sample[a]],0).T) +\n",
    "                       np.dot(Av[test_idx[s]][sample[a]],np.dot(E,np.expand_dims(all_npy[sample[a]],0).T)))\n",
    "\n",
    "\n",
    "            # relu part\n",
    "            alpha[a]=np.sum((relu(alpha_a)))*r\n",
    "            # tanh part\n",
    "    #         alpha[a]=np.sum((np.tanh(alpha_a)))*r\n",
    "\n",
    "        mul = np.zeros((1,latent_dim))\n",
    "        added_alpha = np.add(alpha,0.0000000001)\n",
    "        norm_alpha = added_alpha/np.sum(added_alpha)\n",
    "        sum_alpha += np.sum(alpha)\n",
    "\n",
    "#         print(\"{:<15}{}\".format('sum_alpha:', sum_alpha))\n",
    "#         print('==================================================')\n",
    "\n",
    "        for i in range(len(sample)):\n",
    "            mul += norm_alpha[i] * A[sample[i]] # attention alpha*Ai part\n",
    "        new_mul = mul + U[test_idx[s]]  #(U+auxilary)\n",
    "\n",
    "        for k in range(movie_test_amount):\n",
    "            result[s][k] = np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "            RS[s][k] = np.dot(new_mul,Y[k].T) + np.dot(B[test_idx[s]], np.dot(E, all_npy[k].T))\n",
    "        \n",
    "    #取出test的資料\n",
    "    print(RS.shape)\n",
    "\n",
    "    testRS = np.zeros((usr_test_amount, movie_test_amount)) #shape 150 * 32\n",
    "    target = np.zeros((usr_test_amount, movie_test_amount)) #shape 150 * 32\n",
    "\n",
    "    for z in range(usr_test_amount):\n",
    "        user_id = test_idx[z]\n",
    "        # positive target YouTuber list\n",
    "        youtube_t = test_t[z] \n",
    "        # not target YouTuber list\n",
    "        youtube_f = test_f[z]\n",
    "\n",
    "#         print(user_id)\n",
    "#         print(youtube_t)\n",
    "#         print(youtube_f)\n",
    "\n",
    "        #前面放target的RS\n",
    "        for i in range(len(youtube_t)):\n",
    "            testRS[z][i] = RS[z][youtube_t[i]]\n",
    "            target[z][i] = 1\n",
    "\n",
    "        for i in range(len(youtube_f)):\n",
    "            testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]\n",
    "\n",
    "    #     print(testRS[z])\n",
    "    #     print(target[z])\n",
    "    #     print('==============================')\n",
    "\n",
    "    print(target.shape, testRS.shape)\n",
    "    sumtarget = np.sum(target)\n",
    "    print('num of positive data in testing:', sumtarget) # whole matrix: 4800\n",
    "\n",
    "    # for metrics\n",
    "    metrics(testRS, target, sumtarget, allSortPrepare(testRS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = 'MRM_E240_movie_<=100_32_100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FILE = './weight/coldstart/' + SAVE_NAME + '.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent factor and Each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRM_E240_movie_<=100_32_100\n",
      "User latent shape:  (1582, 64)\n",
      "photo latent shape:  (165, 64)\n",
      "Auxilary latent shape:  (165, 64)\n",
      "Embedding shape: (240, 2372)\n",
      "Wu weight shape: (1582, 165, 64)\n",
      "Wy weight shape: (1582, 165, 64)\n",
      "Wa weight shape: (1582, 165, 64)\n",
      "Wv weight shape: (1582, 165, 240)\n",
      "Beta shape: (1582, 240)\n",
      "(100, 165)\n",
      "(100, 32) (100, 32)\n",
      "num of positive data in testing: 482.0\n",
      "(100, 32)\n",
      "\n",
      "==============================\n",
      "\n",
      "Top 1\n",
      "prec: 0.02\n",
      "recall: 0.004149377593360996\n",
      "F1_score: 0.006872852233676976\n",
      "*****\n",
      "Top 5\n",
      "prec: 0.408\n",
      "recall: 0.42323651452282157\n",
      "F1_score: 0.41547861507128303\n",
      "*****\n",
      "\n",
      "==============================\n",
      "\n",
      "NDCG@ 5\n",
      "NDCG score: 0.3562973377804742\n",
      "*****\n",
      "NDCG@ 10\n",
      "NDCG score: 0.39045624699467774\n",
      "*****\n",
      "\n",
      "==============================\n",
      "\n",
      "MAP: 0.1566400499466107\n",
      "\n",
      "==============================\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(SAVE_NAME)\n",
    "\n",
    "params = np.load(SAVE_FILE)\n",
    "\n",
    "U = params['U']\n",
    "Y = params['Y']\n",
    "A = params['A']\n",
    "E = params['E']\n",
    "Au = params['Wu']\n",
    "Ay = params['Wy']\n",
    "Aa = params['Wa']\n",
    "Av = params['Wv']\n",
    "B = params['B']\n",
    "\n",
    "print('User latent shape: ',U.shape)\n",
    "print('photo latent shape: ', Y.shape)\n",
    "print('Auxilary latent shape: ',A.shape)\n",
    "print('Embedding shape:', E.shape)\n",
    "print('Wu weight shape:', Au.shape)\n",
    "print('Wy weight shape:', Ay.shape)\n",
    "print('Wa weight shape:', Aa.shape)\n",
    "print('Wv weight shape:', Av.shape)\n",
    "print('Beta shape:',B.shape)\n",
    "\n",
    "testing(U, Y, A, E, Au, Ay, Aa, Av, B)\n",
    "print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
