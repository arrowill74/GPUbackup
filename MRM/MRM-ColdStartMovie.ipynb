{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "def writeProgress(msg, count, total):\n",
    "    sys.stdout.write(msg + \"{:.2%}\\r\".format(count/total))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: (165, 2372)\n",
      "Movie genre: (165, 20)\n",
      "User following: (1582, 165)\n",
      "User genre: (1582, 20)\n"
     ]
    }
   ],
   "source": [
    "all_npy = np.load('./npy/all_2372.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "\n",
    "print('All features:', all_npy.shape)\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582 165\n",
      "64 2372 240\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "print(usr_nb, movie_nb)\n",
    "\n",
    "# usr_test_amount = 150\n",
    "# movie_test_amount = 32\n",
    "# print(usr_test_amount, movie_test_amount)\n",
    "\n",
    "latent_dim = 64 # latent dims\n",
    "ft_dim = all_npy.shape[1] # feature dims\n",
    "embedding_dims = 240\n",
    "print(latent_dim, ft_dim, embedding_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize usr_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 20)\n"
     ]
    }
   ],
   "source": [
    "usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "for i in range(len(usr_genre)):\n",
    "    usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "print(usr_genre_norm.shape)\n",
    "# print('Before:', usr_genre)\n",
    "# print('After:', usr_genre_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & testing split\n",
    "## Prepare\n",
    "### Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followers: 1\n",
      "Max number of followers: 520\n",
      "Avg of followers: 142.0969696969697\n",
      "The num of followers over 5: 163\n"
     ]
    }
   ],
   "source": [
    "#The number of followers for each movie\n",
    "moive_followers = np.sum(usr_following, axis=0)\n",
    "# print(moive_followers)\n",
    "\n",
    "print('Min number of followers:', np.min(moive_followers))\n",
    "print('Max number of followers:', np.max(moive_followers))\n",
    "print('Avg of followers:', np.mean(moive_followers))\n",
    "\n",
    "asc = np.sort(moive_followers)\n",
    "# print(asc)\n",
    "desc = np.flip(asc)\n",
    "# print(desc)\n",
    "\n",
    "over5 = 0\n",
    "for num in moive_followers:\n",
    "    if num >= 5:\n",
    "        over5 += 1\n",
    "print('The num of followers over 5:', over5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<= 10: 3\n",
      "<= 20: 13\n",
      "<= 30: 21\n",
      "<= 40: 32\n",
      "<= 50: 40\n",
      "<= 100: 76\n",
      "(76,) [  6   7   8  11  13  14  15  16  17  19  20  23  26  27  29  31  32  33\n",
      "  35  36  38  39  41  43  45  46  47  48  51  54  56  59  61  63  65  67\n",
      "  69  70  71  73  76  82  83  88  90  92  94  95  97  98 105 107 109 110\n",
      " 113 115 116 117 124 130 132 133 135 136 138 139 140 145 146 148 150 155\n",
      " 157 158 160 162]\n"
     ]
    }
   ],
   "source": [
    "print('<= 10:', np.sum(moive_followers <= 10))\n",
    "print('<= 20:', np.sum(moive_followers <= 20))\n",
    "print('<= 30:', np.sum(moive_followers <= 30))\n",
    "print('<= 40:', np.sum(moive_followers <= 40))\n",
    "print('<= 50:', np.sum(moive_followers <= 50))\n",
    "print('<= 100:', np.sum(moive_followers <= 100))\n",
    "less_idx = np.nonzero(moive_followers <= 100)[0]\n",
    "print(less_idx.shape, less_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 165)\n",
      "(165, 1582)\n"
     ]
    }
   ],
   "source": [
    "print(usr_following.shape)\n",
    "usr_following = usr_following.T\n",
    "print(usr_following.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 6\n",
      "Sum: 37\n",
      "37\n",
      "==================================================\n",
      "Index: 7\n",
      "Sum: 1\n",
      "38\n",
      "==================================================\n",
      "Index: 8\n",
      "Sum: 37\n",
      "69\n",
      "==================================================\n",
      "Index: 11\n",
      "Sum: 75\n",
      "141\n",
      "==================================================\n",
      "Index: 13\n",
      "Sum: 97\n",
      "221\n",
      "==================================================\n",
      "Index: 14\n",
      "Sum: 23\n",
      "235\n",
      "==================================================\n",
      "Index: 15\n",
      "Sum: 18\n",
      "248\n",
      "==================================================\n",
      "Index: 16\n",
      "Sum: 31\n",
      "269\n",
      "==================================================\n",
      "Index: 17\n",
      "Sum: 61\n",
      "314\n",
      "==================================================\n",
      "Index: 19\n",
      "Sum: 78\n",
      "357\n",
      "==================================================\n",
      "Index: 20\n",
      "Sum: 61\n",
      "394\n",
      "==================================================\n",
      "Index: 23\n",
      "Sum: 72\n",
      "433\n",
      "==================================================\n",
      "Index: 26\n",
      "Sum: 90\n",
      "484\n",
      "==================================================\n",
      "Index: 27\n",
      "Sum: 23\n",
      "497\n",
      "==================================================\n",
      "Index: 29\n",
      "Sum: 32\n",
      "510\n",
      "==================================================\n",
      "Index: 31\n",
      "Sum: 58\n",
      "532\n",
      "==================================================\n",
      "Index: 32\n",
      "Sum: 61\n",
      "572\n",
      "==================================================\n",
      "Index: 33\n",
      "Sum: 80\n",
      "624\n",
      "==================================================\n",
      "Index: 35\n",
      "Sum: 11\n",
      "628\n",
      "==================================================\n",
      "Index: 36\n",
      "Sum: 78\n",
      "652\n",
      "==================================================\n",
      "Index: 38\n",
      "Sum: 28\n",
      "659\n",
      "==================================================\n",
      "Index: 39\n",
      "Sum: 49\n",
      "677\n",
      "==================================================\n",
      "Index: 41\n",
      "Sum: 82\n",
      "717\n",
      "==================================================\n",
      "Index: 43\n",
      "Sum: 70\n",
      "743\n",
      "==================================================\n",
      "Index: 45\n",
      "Sum: 81\n",
      "778\n",
      "==================================================\n",
      "Index: 46\n",
      "Sum: 77\n",
      "810\n",
      "==================================================\n",
      "Index: 47\n",
      "Sum: 89\n",
      "838\n",
      "==================================================\n",
      "Index: 48\n",
      "Sum: 49\n",
      "849\n",
      "==================================================\n",
      "Index: 51\n",
      "Sum: 19\n",
      "851\n",
      "==================================================\n",
      "Index: 54\n",
      "Sum: 18\n",
      "854\n",
      "==================================================\n",
      "Index: 56\n",
      "Sum: 22\n",
      "861\n",
      "==================================================\n",
      "Index: 59\n",
      "Sum: 24\n",
      "864\n",
      "==================================================\n",
      "Index: 61\n",
      "Sum: 41\n",
      "879\n",
      "==================================================\n",
      "Index: 63\n",
      "Sum: 58\n",
      "893\n",
      "==================================================\n",
      "Index: 65\n",
      "Sum: 4\n",
      "894\n",
      "==================================================\n",
      "Index: 67\n",
      "Sum: 76\n",
      "903\n",
      "==================================================\n",
      "Index: 69\n",
      "Sum: 40\n",
      "909\n",
      "==================================================\n",
      "Index: 70\n",
      "Sum: 41\n",
      "922\n",
      "==================================================\n",
      "Index: 71\n",
      "Sum: 20\n",
      "926\n",
      "==================================================\n",
      "Index: 73\n",
      "Sum: 43\n",
      "931\n",
      "==================================================\n",
      "Index: 76\n",
      "Sum: 93\n",
      "956\n",
      "==================================================\n",
      "Index: 82\n",
      "Sum: 78\n",
      "987\n",
      "==================================================\n",
      "Index: 83\n",
      "Sum: 82\n",
      "1003\n",
      "==================================================\n",
      "Index: 88\n",
      "Sum: 44\n",
      "1007\n",
      "==================================================\n",
      "Index: 90\n",
      "Sum: 68\n",
      "1015\n",
      "==================================================\n",
      "Index: 92\n",
      "Sum: 73\n",
      "1029\n",
      "==================================================\n",
      "Index: 94\n",
      "Sum: 73\n",
      "1036\n",
      "==================================================\n",
      "Index: 95\n",
      "Sum: 31\n",
      "1039\n",
      "==================================================\n",
      "Index: 97\n",
      "Sum: 9\n",
      "1042\n",
      "==================================================\n",
      "Index: 98\n",
      "Sum: 72\n",
      "1051\n",
      "==================================================\n",
      "Index: 105\n",
      "Sum: 71\n",
      "1063\n",
      "==================================================\n",
      "Index: 107\n",
      "Sum: 97\n",
      "1079\n",
      "==================================================\n",
      "Index: 109\n",
      "Sum: 59\n",
      "1083\n",
      "==================================================\n",
      "Index: 110\n",
      "Sum: 33\n",
      "1086\n",
      "==================================================\n",
      "Index: 113\n",
      "Sum: 12\n",
      "1087\n",
      "==================================================\n",
      "Index: 115\n",
      "Sum: 35\n",
      "1093\n",
      "==================================================\n",
      "Index: 116\n",
      "Sum: 39\n",
      "1098\n",
      "==================================================\n",
      "Index: 117\n",
      "Sum: 63\n",
      "1104\n",
      "==================================================\n",
      "Index: 124\n",
      "Sum: 52\n",
      "1109\n",
      "==================================================\n",
      "Index: 130\n",
      "Sum: 19\n",
      "1111\n",
      "==================================================\n",
      "Index: 132\n",
      "Sum: 37\n",
      "1117\n",
      "==================================================\n",
      "Index: 133\n",
      "Sum: 48\n",
      "1123\n",
      "==================================================\n",
      "Index: 135\n",
      "Sum: 64\n",
      "1125\n",
      "==================================================\n",
      "Index: 136\n",
      "Sum: 46\n",
      "1126\n",
      "==================================================\n",
      "Index: 138\n",
      "Sum: 83\n",
      "1133\n",
      "==================================================\n",
      "Index: 139\n",
      "Sum: 14\n",
      "1136\n",
      "==================================================\n",
      "Index: 140\n",
      "Sum: 20\n",
      "1136\n",
      "==================================================\n",
      "Index: 145\n",
      "Sum: 25\n",
      "1136\n",
      "==================================================\n",
      "Index: 146\n",
      "Sum: 26\n",
      "1137\n",
      "==================================================\n",
      "Index: 148\n",
      "Sum: 64\n",
      "1144\n",
      "==================================================\n",
      "Index: 150\n",
      "Sum: 96\n",
      "1159\n",
      "==================================================\n",
      "Index: 155\n",
      "Sum: 40\n",
      "1166\n",
      "==================================================\n",
      "Index: 157\n",
      "Sum: 66\n",
      "1170\n",
      "==================================================\n",
      "Index: 158\n",
      "Sum: 89\n",
      "1178\n",
      "==================================================\n",
      "Index: 160\n",
      "Sum: 29\n",
      "1185\n",
      "==================================================\n",
      "Index: 162\n",
      "Sum: 11\n",
      "1185\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "st = set()\n",
    "for idx in less_idx:\n",
    "    print('Index:', idx)\n",
    "    print('Sum:', usr_following[idx].sum())\n",
    "#     print(usr_following[idx])\n",
    "    li = list(np.where(usr_following[idx] == 1)[0])\n",
    "#     print(li)\n",
    "    st = st | set(li)\n",
    "    print(len(st))\n",
    "    print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1185 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "test_idx = list(st)\n",
    "test_idx.sort()\n",
    "print(len(test_idx), test_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1185 76\n"
     ]
    }
   ],
   "source": [
    "usr_test_amount = len(test_idx)\n",
    "movie_test_amount = len(less_idx)\n",
    "print(usr_test_amount, movie_test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 165)\n"
     ]
    }
   ],
   "source": [
    "usr_following = usr_following.T\n",
    "print(usr_following.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat of user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1582, 76)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldarea = usr_following[:, less_idx]\n",
    "coldarea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followings: 0\n",
      "Max number of followings: 52\n",
      "Avg of followers: 2.4121365360303413\n"
     ]
    }
   ],
   "source": [
    "#The number of following movie for each user\n",
    "each_user = np.sum(coldarea, axis=1)\n",
    "# print(each_user)\n",
    "\n",
    "print('Min number of followings:', np.min(each_user))\n",
    "print('Max number of followings:', np.max(each_user))\n",
    "print('Avg of followers:', np.mean(each_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">= 1 : 1185\n",
      ">= 2 : 831\n",
      ">= 3 : 554\n",
      ">= 4 : 377\n",
      ">= 5 : 228\n",
      ">= 6 : 161\n",
      ">= 7 : 108\n",
      ">= 8 : 76\n",
      ">= 9 : 53\n",
      ">= 10 : 39\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    print('>=', i, ':', np.sum(each_user >= i))\n",
    "# print('>', i, ':', np.sum(each_user > 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [1036, 165, 670, 720, 1363, 494, 854, 367, 1329, 245]\n"
     ]
    }
   ],
   "source": [
    "test_idx = list(each_user.argsort()[::-1][:100])\n",
    "print(len(test_idx), test_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_test_idx = []\n",
    "# for i in test_idx:\n",
    "#     add = 0\n",
    "#     for j in less_idx:\n",
    "#         if usr_following[i][j] == 1:\n",
    "#             add += 1\n",
    "            \n",
    "#     if add >= 6:\n",
    "#         new_test_idx.append(i)\n",
    "# print(len(new_test_idx))\n",
    "# random.seed(42)\n",
    "# test_idx = random.sample(new_test_idx, 100)\n",
    "# test_idx.sort()\n",
    "# print(len(test_idx), test_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 32\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(test_idx)\n",
    "usr_test_amount = len(test_idx)\n",
    "movie_test_amount = 32 #math.floor(len(less_idx)*0.5)\n",
    "print(usr_test_amount, movie_test_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init\n",
    "random.seed(42)\n",
    "train_t = []\n",
    "train_f = []\n",
    "test_t = []\n",
    "test_f = []\n",
    "\n",
    "for i in test_idx:\n",
    "    # init\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    t_for_test = []\n",
    "    f_for_test = []\n",
    "    \n",
    "    temp_t = []\n",
    "    temp_f = []\n",
    "    for j in less_idx:\n",
    "        if usr_following[i][j] == 1:\n",
    "            temp_t.append(j)\n",
    "        else:\n",
    "            temp_f.append(j)\n",
    "            \n",
    "    t_for_test = random.sample(temp_t, math.ceil(0.5*len(temp_t)))\n",
    "    f_for_test = random.sample(temp_f, movie_test_amount-len(t_for_test))\n",
    "    \n",
    "    test_t.append(t_for_test)\n",
    "    test_f.append(f_for_test)\n",
    "    \n",
    "    t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "    f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "    train_t.append(t_for_train)\n",
    "    train_f.append(f_for_train)\n",
    "    \n",
    "    if not (len(t_for_train) + len(f_for_train) + len(t_for_test) + len(f_for_test)) == len(less_idx):\n",
    "        print('Error!!!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 100\n",
      "The length of train_f: 100\n",
      "The length of test_t: 100\n",
      "The length of test_f: 100\n"
     ]
    }
   ],
   "source": [
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_f))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 511 5.11\n",
      "Testing: 561 5.61\n"
     ]
    }
   ],
   "source": [
    "#average num of following for training user\n",
    "total_train = 0\n",
    "for t in train_t:\n",
    "    total_train += len(t)\n",
    "avg = total_train / usr_test_amount\n",
    "print('Training:', total_train, avg)\n",
    "\n",
    "#average num of following for testing user\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test / usr_test_amount\n",
    "print('Testing:', total_test, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_auxilary = [i for i in range(movie_nb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation model\n",
    "## Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(SAVE_NAME):\n",
    "    print('==================================================')\n",
    "    print(SAVE_NAME)\n",
    "    print('Start time:', time.ctime())\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    loss_acc_list = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_yes_id=[]\n",
    "\n",
    "    for q in range(6):\n",
    "        print('Epoch:',q)\n",
    "        train_auc = 0\n",
    "        total_loss = 0\n",
    "        xuij_auc = 0\n",
    "        length = 0\n",
    "\n",
    "        for z in range(usr_test_amount):\n",
    "            idx = test_idx[z]\n",
    "            writeProgress('Idx: {}\\tProgress:'.format(idx), z, usr_test_amount)\n",
    "            \"\"\"\n",
    "            yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "            yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "            r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "            \"\"\"\n",
    "            yes = []\n",
    "            yesr = []\n",
    "\n",
    "    #         #選全部的Positive\n",
    "    #         sample = random.sample(train_t[z],len(train_t[z]))\n",
    "            #選全部的電影\n",
    "            sample = all_auxilary\n",
    "\n",
    "            #change\n",
    "            r_3 = np.zeros(len(sample))\n",
    "\n",
    "            for b in range(len(sample)):\n",
    "                yes.append(all_npy[sample[b]])\n",
    "                yesr.append(movie_genre[sample[b]] * usr_genre_norm[idx])\n",
    "\n",
    "            for b in range(len(yesr)):\n",
    "                r_3[b]=max(yesr[b])\n",
    "            #print('r_3:',r_3)\n",
    "\n",
    "            yes = np.array(yes)\n",
    "\n",
    "            # positive sample\n",
    "            train_t_sample = train_t[z]\n",
    "            for ta in train_t_sample:\n",
    "                #print(ta,'--> positive feedback')\n",
    "\n",
    "                pos = sample.index(ta)\n",
    "\n",
    "                image_1 = np.expand_dims(all_npy[ta],0)\n",
    "                train_f_sample = train_f[z] #random.sample(train_f[z],10)\n",
    "\n",
    "                for b in train_f_sample:\n",
    "                    image_2 = np.expand_dims(all_npy[b],0)\n",
    "\n",
    "                    _last_be_relu, _norm_par, _a_list, r3, _auc, _loss, _ = sess.run(\n",
    "                        [last_be_relu, norm_par, a_list_smooth, a_list_soft, auc, loss, train_op], \n",
    "                        feed_dict={user: [z], i: [ta], j: [b], xf: yes, \n",
    "                                   l_id:sample, l_id_len:[len(sample)],\n",
    "                                   positive_id: train_t[z], positive_len:[len(train_t[z])],\n",
    "                                   r: r_3, image_i: image_1, image_j: image_2})\n",
    "\n",
    "                    '''Observe all params\n",
    "                    print('u,vi,vj',_norm_par[:3])\n",
    "                    print('w1,wu,wy,wa,wv',_norm_par[3:7])\n",
    "                    print('beta',_norm_par[7])\n",
    "                    print('Embedding',_norm_par[8])\n",
    "                    print('after softmax:', r3)\n",
    "                    print('before softmax:', _a_list)\n",
    "                    print('---------------------------------------------------')\n",
    "                    '''\n",
    "                    train_auc += _auc\n",
    "                    total_loss += _loss\n",
    "                    length += 1\n",
    "\n",
    "        print(\"{:<20}{}\".format('total_loss', total_loss/length))\n",
    "        print(\"{:<20}{}\".format('train_auc:', train_auc/length))\n",
    "\n",
    "        loss_acc_list.append([total_loss/length, train_auc/length])\n",
    "\n",
    "        print('\\tCurrent time:', time.ctime(), ' sec')\n",
    "        print('==================================================')\n",
    "\n",
    "    print('Total cost time:',time.time()-t0, ' sec')\n",
    "\n",
    "    print('End time:', time.ctime())\n",
    "    \n",
    "    U, Y, A, E, Au, Ay, Aa, Av, B = sess.run([user_latent, item_latent, aux_item, embedding, Wu, Wy, Wa, Wv, Beta])\n",
    "    np.savez('./weight/coldstart/' + SAVE_NAME + '.npz',\n",
    "             U=U, Y=Y, A=A, E=E, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av, B=B)\n",
    "    \n",
    "    return loss_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-25-8457192f1bab>:141: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "==================================================\n",
      "MRM_E240_movie\n",
      "Start time: Fri May  8 03:02:33 2020\n",
      "Epoch: 0\n",
      "total_loss          [[0.23444402]]\n",
      "train_auc:          0.9132364597093792\n",
      "\tCurrent time: Fri May  8 03:13:24 2020  sec\n",
      "==================================================\n",
      "Epoch: 1\n",
      "total_loss          [[0.05636716]]\n",
      "train_auc:          0.9874768824306472\n",
      "\tCurrent time: Fri May  8 03:24:08 2020  sec\n",
      "==================================================\n",
      "Epoch: 2\n",
      "total_loss          [[0.01686195]]\n",
      "train_auc:          0.9988375165125495\n",
      "\tCurrent time: Fri May  8 03:35:00 2020  sec\n",
      "==================================================\n",
      "Epoch: 3\n",
      "total_loss          [[0.0097248]]\n",
      "train_auc:          0.9998414795244386\n",
      "\tCurrent time: Fri May  8 03:45:56 2020  sec\n",
      "==================================================\n",
      "Epoch: 4\n",
      "total_loss          [[0.00662194]]\n",
      "train_auc:          1.0\n",
      "\tCurrent time: Fri May  8 03:56:50 2020  sec\n",
      "==================================================\n",
      "Epoch: 5\n",
      "total_loss          [[0.00562592]]\n",
      "train_auc:          0.9999471598414795\n",
      "\tCurrent time: Fri May  8 04:07:46 2020  sec\n",
      "==================================================\n",
      "Total cost time: 3911.7891085147858  sec\n",
      "End time: Fri May  8 04:07:46 2020\n",
      "Epoch: range(1, 7)\n",
      "Loss: [0.2344440221786499, 0.05636715516448021, 0.016861949115991592, 0.00972480047494173, 0.006621938198804855, 0.0056259166449308395]\n",
      "Acc: [0.9132364597093792, 0.9874768824306472, 0.9988375165125495, 0.9998414795244386, 1.0, 0.9999471598414795]\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3hU5bn38e9NEggiAkIoKAgoVA0eEEesm6p4xhNaxYqIIkLSvbe1B2vfTa1tLXb3RW3V2loLVfGEIsKrolapp2qtVQyIUEQEqdYoloCigAcI3O8fzwJjTMgkmZk1h9/nutbFzDrM3Au4fmvN86z1LHN3REQkf7WJuwAREUkvBb2ISJ5T0IuI5DkFvYhInlPQi4jkOQW9iEieU9BL3jOzIjPbYGZ7pHLdFtTxCzO7LdWfK9KU4rgLEKnPzDbUebsT8BmwJXr/LXef3pzPc/ctwM6pXlckVyjoJeu4+/agNbM3gQnu/kRj65tZsbvXZqI2kVykphvJOVETyL1mdo+ZrQfGmNlhZvaCma0zs1VmdoOZlUTrF5uZm1nf6P1d0fJHzWy9mf3dzPo1d91o+Ylm9rqZfWhmvzWzv5nZBUnuxzfMbElU81NmtnedZZeZ2btm9pGZvWZmw6L5XzOzBdH8f5vZNSn4K5U8p6CXXPUN4G6gE3AvUAt8F+gGDAWGA9/awfajgZ8AuwL/Aq5s7rpm1h2YCfww+t5/AkOSKd7M9gXuBC4GyoAngDlmVmJmA6PaB7v7LsCJ0fcC/Ba4JprfH5iVzPdJYVPQS656zt0fcvet7v6Ju7/k7i+6e627rwSmAkfuYPtZ7l7l7puB6cCgFqx7CrDQ3R+Mll0HrEmy/lHAHHd/Ktp2MuGgdSjhoFUKDIyapf4Z7RPAZmCAmXV19/Xu/mKS3ycFTEEvuertum/MbB8ze8TM3jOzj4BJhLPsxrxX5/XH7LgDtrF1d6tbh4cRAquTqH3btm/V2XZrtO3u7r4M+AFhH1ZHTVQ9olXHAeXAMjObZ2YnJfl9UsAU9JKr6g+7OgX4B9A/atb4KWBprmEV0GvbGzMzYPckt30X6FNn2zbRZ70D4O53uftQoB9QBPzfaP4ydx8FdAd+Dcw2s9LW74rkMwW95IuOwIfAxqj9e0ft86nyMDDYzE41s2JCH0FZktvOBEaY2bCo0/iHwHrgRTPb18yOMrN2wCfRtBXAzM4zs27RL4APCQe8randLck3CnrJFz8AxhLCcgqhgzat3P3fwNnAtcBaYC/gZcJ1/01tu4RQ701ADaHzeETUXt8OuJrQ3v8e0AX4cbTpScDS6GqjXwFnu/umFO6W5CHTg0dEUsPMighNMiPd/a9x1yOyjc7oRVrBzIabWeeomeUnhKti5sVclsgXKOhFWufrwEpC88sJwDfcvcmmG5FMUtONiEie0xm9iEiey7pBzbp16+Z9+/aNuwwRkZwyf/78Ne7e4OW9WRf0ffv2paqqKu4yRERyipm91dgyNd2IiOQ5Bb2ISJ5T0IuI5Lmsa6MXkey0efNmqqur+fTTT+MupaCVlpbSq1cvSkpKkt5GQS8iSamurqZjx4707duXMFCnZJq7s3btWqqrq+nXr1/TG0TUdCMiSfn000/p2rWrQj5GZkbXrl2b/atKQS8iSVPIx68l/wb5E/Tvvw9XXAH/+EfclYiIZJX8CXqAyZNhypS4qxCRNFi7di2DBg1i0KBB9OjRg9133337+02bkhuSf9y4cSxbtmyH69x4441Mnz49FSXz9a9/nYULF6bks1ojfzpjd90VzjwT7rwTrroKdtop7opEJIW6du26PTSvuOIKdt55Zy699NIvrOPuuDtt2jR8Djtt2rQmv+eiiy5qfbFZJr/O6Csr4cMPYdasuCsRkQxZsWIF5eXlnHvuuQwcOJBVq1ZRWVlJIpFg4MCBTJo0afu6286wa2tr6dy5MxMnTuTAAw/ksMMOY/Xq1QBcfvnlXH/99dvXnzhxIkOGDGHvvffm+eefB2Djxo2ceeaZlJeXM3LkSBKJRJNn7nfddRf7778/++23H5dddhkAtbW1nHfeedvn33DDDQBcd911lJeXc8ABBzBmzJhW/x3lzxk9wBFHwFe/Cn/8I5x/ftzViOSv730PUt0kMWgQRAHbXK+99hp33HEHiUQCgMmTJ7PrrrtSW1vLUUcdxciRIykvL//CNh9++CFHHnkkkydP5pJLLuHWW29l4sSJX/psd2fevHnMmTOHSZMm8dhjj/Hb3/6WHj16MHv2bF555RUGDx68w/qqq6u5/PLLqaqqolOnThx77LE8/PDDlJWVsWbNGhYvXgzAunXrALj66qt56623aNu27fZ5rZFfZ/RmMGECPPccvPpq3NWISIbstdde20Me4J577mHw4MEMHjyYpUuX8moDedC+fXtOPPFEAA4++GDefPPNBj/7jDPO+NI6zz33HKNGjQLgwAMPZODAgTus78UXX+Too4+mW7dulJSUMHr0aJ599ln69+/PsmXL+M53vsPcuXPp1KkTAAMHDmTMmDFMnz69WTdGNSa/zugBxo6FH/8Ybr4Zrr027mpE8lMLz7zTpUOHDttfL1++nN/85jfMmzePzp07M2bMmAavO2/btu3210VFRdTW1jb42e3atWtynZbq2rUrixYt4tFHH+XGG29k9uzZTJ06lblz5/LMM88wZ84cfvnLX7Jo0SKKiopa/D35dUYP0L07nH463HEH6FZtkYLz0Ucf0bFjR3bZZRdWrVrF3LlzU/4dQ4cOZebMmQAsXry4wV8MdR166KE8/fTTrF27ltraWmbMmMGRRx5JTU0N7s5ZZ53FpEmTWLBgAVu2bKG6upqjjz6aq6++mjVr1vDxxx+3qt78O6MHqKiA++6D+++Hc86JuxoRyaDBgwdTXl7OPvvsQ58+fRg6dGjKv+Piiy/m/PPPp7y8fPu0rdmlIb169eLKK69k2LBhuDunnnoqJ598MgsWLGD8+PG4O2bGVVddRW1tLaNHj2b9+vVs3bqVSy+9lI4dO7aq3qx7ZmwikfBWP3hk61bo3x/69oWnnkpJXSKFbunSpey7775xl5EVamtrqa2tpbS0lOXLl3P88cezfPlyioszc+7c0L+Fmc1390RD6+fnGX2bNqFT9sc/hhUrQuiLiKTIhg0bOOaYY6itrcXdmTJlSsZCviWyt7LWGjcOfvrT0Ck7eXLc1YhIHuncuTPz58+Pu4yk5V9n7DY9e8Ipp8C0aZDk7dEismPZ1tRbiFryb5C/QQ/hTtnVq+Ghh+KuRCTnlZaWsnbtWoV9jLaNR19aWtqs7fK36QbghBOgd+9wp+yZZ8ZdjUhO69WrF9XV1dTU1MRdSkHb9oSp5sjvoC8qggsvhEmT4M03w1U4ItIiJSUlzXqqkWSP/G66gRD0ALfcEm8dIiIxyf+g32MPOPFEuPVWSPHtyyIiuSD/gx7CnbLvvgt/+lPclYiIZFxhBP3JJ0OPHqFTVkSkwBRG0JeUhLb6P/0JqqvjrkZEJKMKI+gBxo8PY+Ak8SgxEZF8UjhBv+eecOyxYUiELVvirkZEJGMKJ+ghdMr+61/w+ONxVyIikjGFFfSnnw5lZeqUFZGCUlhB37ZteNTgnDnw3ntxVyMikhGFFfQQxqmvrYXbbou7EhGRjCi8oN97bzjyyNApu3Vr3NWIiKRdUkFvZsPNbJmZrTCziQ0sv8TMXjWzRWb2pJn1qbNsrJktj6axqSy+xSoq4I034Omn465ERCTtmgx6MysCbgROBMqBc8ysvN5qLwMJdz8AmAVcHW27K/Az4FBgCPAzM+uSuvJb6MwzoUsXdcqKSEFI5ox+CLDC3Ve6+yZgBnBa3RXc/Wl3/zh6+wKwbbDkE4DH3f19d/8AeBwYnprSW6G0FM4/H+6/H9asibsaEZG0SibodwfervO+OprXmPHAo83Z1swqzazKzKoy9lCDiorwiME77sjM94mIxCSlnbFmNgZIANc0Zzt3n+ruCXdPlJWVpbKkxg0cCIcdBlOngh6NJiJ5LJmgfwfoXed9r2jeF5jZscCPgRHu/llzto1NRQUsWwbPPRd3JSIiaZNM0L8EDDCzfmbWFhgFzKm7gpkdBEwhhPzqOovmAsebWZeoE/b4aF52+OY3YZdd1CkrInmtyaB391rg24SAXgrMdPclZjbJzEZEq10D7AzcZ2YLzWxOtO37wJWEg8VLwKRoXnbo0AHOPRfuuw8++CDuakRE0sI8y9qnE4mEV1VVZe4LX34ZBg+GG26Aiy/O3PeKiKSQmc1390RDywrvztj6DjoIEonQfJNlBz0RkVRQ0EPolF28GObNi7sSEZGUU9ADnHNOaK+fOjXuSkREUk5BD9CxI4waBTNmwEcfxV2NiEhKKei3qayEjz+Ge+6JuxIRkZRS0G9zyCFwwAFqvhGRvKOg38YsdMouWBAmEZE8oaCva8yYMLKl7pQVkTyioK+rc+cwLML06bBhQ9zViIikhIK+vooKWL8eZs6MuxIRkZRQ0Nc3dCjsu6+ab0Qkbyjo69vWKfvCC+FuWRGRHKegb8h550HbtjqrF5G8oKBvSLducMYZcOed8MkncVcjItIqCvrGVFbCunUwe3bclYiItIqCvjHDhkH//rpTVkRynoK+MWYwYQL89a/w2mtxVyMi0mIK+h254AIoLoabb467EhGRFlPQ78hXvgKnnQa33QaffRZ3NSIiLaKgb0pFBaxdCw88EHclIiItoqBvynHHQZ8+uqZeRHKWgr4pbdqETtknn4Q33oi7GhGRZlPQJ2PcuBD46pQVkRykoE/G7rvDySfDtGmweXPc1YiINIuCPlmVlfDvf8PDD8ddiYhIsyjokzV8eDiz152yIpJjFPTJKi6GCy+EuXPhrbfirkZEJGkK+uYYPz78eeut8dYhItIMCvrm6NMHTjghBH1tbdzViIgkRUHfXBUVUF0Njz0WdyUiIklR0DfXqaeGMXB0p6yI5AgFfXOVlIQbqB55BN55J+5qRESapKBviQkTYMuWcAOViEiWU9C3xF57wdFHwy23wNatcVcjIrJDSQW9mQ03s2VmtsLMJjaw/AgzW2BmtWY2st6yLWa2MJrmpKrw2FVWwptvwhNPxF2JiMgONRn0ZlYE3AicCJQD55hZeb3V/gVcANzdwEd84u6DomlEK+vNHqefDl276k5ZEcl6yZzRDwFWuPtKd98EzABOq7uCu7/p7ouAwmnHaNcOxo6FBx8MY+CIiGSpZIJ+d+DtOu+ro3nJKjWzKjN7wcxOb2gFM6uM1qmqqalpxkfHrKIi3Dh1++1xVyIi0qhMdMb2cfcEMBq43sz2qr+Cu09194S7J8rKyjJQUorssw8cfni4pt497mpERBqUTNC/A/Su875XNC8p7v5O9OdK4C/AQc2oL/tVVMCKFfCXv8RdiYhIg5IJ+peAAWbWz8zaAqOApK6eMbMuZtYuet0NGAq82tJis9LIkdC5s+6UFZGs1WTQu3st8G1gLrAUmOnuS8xskpmNADCzQ8ysGjgLmGJmS6LN9wWqzOwV4GlgsrvnV9C3bw/nnQezZ8PatXFXIyLyJeZZ1racSCS8qqoq7jKaZ/FiOOAAuPZa+P73465GRAqQmc2P+kO/RHfGpsL++8Ohh6pTVkSykoI+VSorYelSeP75uCsREfkCBX2qnH02dOyoO2VFJOso6FOlQwcYPRruuw/WrYu7GhGR7RT0qVRRAZ98AtOnx12JiMh2CvpUOvhgGDw4NN+oU1ZEsoSCPtUqKmDRInjppbgrEREBFPSpN3o07LST7pQVkayhoE+1XXaBUaPgnntg/fq4qxERUdCnRUUFbNwYwl5EJGYK+nQ49FDYbz8134hIVlDQp4NZuFO2qgpefjnuakSkwCno02XMGCgt1Vm9iMROQZ8uXbqEseqnTw/t9SIiMVHQp1NFBXz0URgWQUQkJgr6dDr8cNh7bzXfiEisFPTpZBbO6p9/HpYsaXp9EZE0UNCn2/nnQ0mJzupFJDYK+nQrK4MzzoA77oBPP427GhEpQAr6TKiogA8+CA8QFxHJMAV9Jhx1FOy5p5pvRCQWCvpMaNMGJkyAZ56B11+PuxoRKTAK+kwZNw6Ki+Hmm+OuREQKjII+U3r0gFNPhdtug02b4q5GRAqIgj6TKiqgpgYefDDuSkSkgCjoM+n442GPPdQpKyIZpaDPpKIiGD8eHn8cVq6MuxoRKRAK+ky78MJwFc4tt8RdiYgUCAV9pvXqBSedBNOmwebNcVcjIgVAQR+HigpYtQoeeSTuSkSkACjo43DSSbDbbuqUFZGMUNDHobg43ED12GPw9ttxVyMieU5BH5fx48Edbr017kpEJM8p6OPSrx8cd1y4+mbLlrirEZE8llTQm9lwM1tmZivMbGIDy48wswVmVmtmI+stG2tmy6NpbKoKzwsVFaHpZu7cuCsRkTzWZNCbWRFwI3AiUA6cY2bl9Vb7F3ABcHe9bXcFfgYcCgwBfmZmXVpfdp4YMQK6d1enrIikVTJn9EOAFe6+0t03ATOA0+qu4O5vuvsiYGu9bU8AHnf39939A+BxYHgK6s4PbdvCBRfAQw+Fyy1FRNIgmaDfHah7aUh1NC8ZSW1rZpVmVmVmVTU1NUl+dJ6YMCG00U+bFnclIpKnsqIz1t2nunvC3RNlZWVxl5NZAwbAsGFhnPqt9X8QiYi0XjJB/w7Qu877XtG8ZLRm28JRWQn//Cc8+WTclYhIHkom6F8CBphZPzNrC4wC5iT5+XOB482sS9QJe3w0T+r6xjdg113VKSsiadFk0Lt7LfBtQkAvBWa6+xIzm2RmIwDM7BAzqwbOAqaY2ZJo2/eBKwkHi5eASdE8qau0FM4/Hx54IDyYREQkhczd467hCxKJhFdVVcVdRua9+ioMHAjXXAOXXhp3NSKSY8xsvrsnGlqWFZ2xApSXw9Chofkmyw6+IpLbFPTZpKICXn8dnn027kpEJI8o6LPJWWdBp07qlBWRlFLQZ5OddoIxY2DWLHhffdYikhoK+mxTUQGffQZ33hl3JSKSJxT02ebAA+GQQ9QpKyIpo6DPRpWVsGQJvPBC3JWISB5Q0GejUaNg551h6tS4KxGRPKCgz0Y77wznnAP33gsffhh3NSKS4xT02aqyEj75BO6+u+l1RUR2QEGfrQ4+GAYNCs036pQVkVZQ0Gcrs3Cp5cKFMH9+3NWISA5T0Gezc8+F9u11p6yItIqCPpt16gRnnx3a6TdsiLsaEclRCvpsV1ERQn7GjLgrEZEcpaDPdocdFoYwVvONiLSQgj7bmYVLLefNg1deibsaEclBCvpccN550K6dzupFpEUU9Llg113hzDPhrrvg44/jrkZEcoyCPldUVobhEGbNirsSEckxCvpcccQR8NWvaqAzEWk2BX2uMIMJE+Bvf4NXX427GhHJIQr6XDJ2LJSUwM03x12JiOQQBX0u6d4dTj8dbr8dPv007mpEJEco6HNNRUV4cPj998ddiYjkCAV9rjnmGOjXT9fUi0jSFPS5pk2b0Cn79NOwfHnc1YhIDlDQ56Jx46CoSJ2yIpIUBX0u6tkTTjkFbrsNNm2KuxoRyXIK+lxVWQmrV8NDD8VdiYhkOQV9rjrhBOjdW3fKikiTFPS5qqgILrwQHn8cnnwy7mpEJIsp6HPZt74Fe+wBxx4LZ5yhq3BEpEEK+lzWsycsXQr/+7/hzL68HL7//XBDlYhIJKmgN7PhZrbMzFaY2cQGlrczs3uj5S+aWd9ofl8z+8TMFkbTH1JbvtC+PVx2WTibv/BCuOEG6N8frr9eV+SICJBE0JtZEXAjcCJQDpxjZuX1VhsPfODu/YHrgKvqLHvD3QdF03+mqG6pr0cPmDIlPG5wyJBwZj9wYBgqwT3u6kQkRsmc0Q8BVrj7SnffBMwATqu3zmnA7dHrWcAxZmapK1OStt9+8Nhj8Oij4fGDZ5wBw4ZBVVXclYlITJIJ+t2Bt+u8r47mNbiOu9cCHwJdo2X9zOxlM3vGzA5vZb2SrOHDYeFC+MMf4LXX4JBDwrNn33676W1FJK+kuzN2FbCHux8EXALcbWa71F/JzCrNrMrMqmpqatJcUgEpLg5X5ixfDj/6Edx3X3hK1U9+AuvXx12diGRIMkH/DtC7zvte0bwG1zGzYqATsNbdP3P3tQDuPh94A/hq/S9w96nunnD3RFlZWfP3QnZsl13gl7+EZctCU84vfgEDBoQRMLdsibs6EUmzZIL+JWCAmfUzs7bAKGBOvXXmAGOj1yOBp9zdzaws6szFzPYEBgArU1O6NFufPjB9Orz4Yrgyp7ISDjoI/vznuCsTkTRqMuijNvdvA3OBpcBMd19iZpPMbES02i1AVzNbQWii2XYJ5hHAIjNbSOik/U9310XecRsyBP76V5g1CzZuDMMpnHSSnkUrkqfMs+zSu0Qi4VW6QiRzPvsMfvc7uPJK2LAhPMHq5z8Pjy0UkZxhZvPdPdHQMt0ZW+jatYMf/ABWrID//u8wxn3//jB5sp5LK5InFPQSdOsW7qr9xz/gqKPCVTr77AP33KMbrkRynIJevmjvveHBB+Gpp6BLFxg9Gg47DJ5/Pu7KRKSFFPTSsKOOCnfTTpsWbrIaOhS++U1YqYumRHKNgl4aV1QEF1wAr78eOmgfeQT23Rd++ENYty7u6kQkSQp6aVqHDvDTn4Y7bMeMgV//OnTY/u53sHlz3NWJSBMU9JK83XaDW26BBQvgwAPh4oth//3Dc2vVYSuStRT00nyDBsETT3z+YPIRI+CYY+Dll+OtS0QapKCXljGDU06BxYtDE86iRXDwweHhJ+++G3d1IlKHgl5ap6QELroo3HB16aVhLJ0BA0Ln7caNcVcnIijoJVU6d4arrw5j359yClxxRRgS+bbbYOvWuKsTKWgKekmtfv3g3nvhb3+D3r1h3LjQpPPUU3FXJlKwFPSSHv/xH/D3v4chFD74IHTWjhgRxsQXkYxS0Ev6mMGoUaE5Z/Jk+MtfwjNtL74Y1qyJuzqRgqGgl/QrLYX/+Z/QYVtRATfdFG64+tWvwjDJIpJWCnrJnO7d4fe/D5diDh0ahlLYd9/wABTdcCWSNgp6ybzy8jBuzp//DDvvDGedBYcfHh5xKCIpp6CX+Bx3XLib9o9/DM06X/taGBb5rbfirkwkryjoJV5FRTBhQhgw7fLL4YEHwpj4P/oRfPRR3NWJ5AUFvWSHjh3Dc2uXLQvj3k+eHDps//AHqK2NuzqRnKagl+zSuzfccQe89FLoqP2v/wojZT76qDpsRVpIQS/ZKZEI193ffz9s2gQnnQTDh4dB1ESkWYrjLkCkUWZw+ukh5G+6KQyUNmgQnHtuGFZht90+n3r2DNfri8iXmGfZz+FEIuFVVVVxlyHZ6P33Qzv+lCnwySdfXt6lyxfDv6GpRw9o2zbztYukmZnNd/dEg8sU9JJz3EPov/tumFat+vx13WnVqoY7csvKvvhLoKEDwle+AsX6wSu5Y0dBr//JknvMoGvXMO2/f+Prbd0axtRp6CCw7UDwyivw3ntfHkrZLIT9jn4d9OwZDhpFRendX5FWUtBL/mrTJgy70L17aNtvzJYtsHp14weE6mqYNy+sU19RUWgOaqrJqGvXcPAQiYGCXqSoKJyd9+wZOnkbs3lzOPtvrLlo5Up47jlYu/bL27Zt+8VmosaajDp31gFBUk5BL5KskpJwnX/v3jte79NPPz8gNDQtXQpPPgnr1n1529LShg8A3buHcYE6dPj8z23TtvfqU5BG6H+GSKqVlkLfvmHakY8/brwj+d13YeHCMPhbss/ebdu28YNAa97vtFNoBpOcpaAXictOO8Fee4VpR9avD/0DGzeGacOGz1/Xf9/Qsn//+8vLN21qXq3t26fnIFJaqqaqDFDQi2S7jh3DlEq1tckdJJp6//77X16+ZUvydbRpEw54DR0I2rcPzVHFxaEfpf7rhuY1tbwl27TmM4uKsuJApqAXKUTFxdCpU5hSyT38WmjJQaP++5qacNDYsiUcmLb92djrLVtCh3m2adMm+YPHQQeF5yynmIJeRFLHDNq1C1PXrvHUsHVr4weCZOa1dnlrttlzz7T8lSjoRSS/tGkTppKSuCvJGkl1pZvZcDNbZmYrzGxiA8vbmdm90fIXzaxvnWU/iuYvM7MTUle6iIgko8mgN7Mi4EbgRKAcOMfMyuutNh74wN37A9cBV0XblgOjgIHAcOD30eeJiEiGJHNGPwRY4e4r3X0TMAM4rd46pwG3R69nAceYmUXzZ7j7Z+7+T2BF9HkiIpIhyQT97sDbdd5XR/MaXMfda4EPga5JbouZVZpZlZlV1dTUJF+9iIg0KStud3P3qe6ecPdEWVlZ3OWIiOSVZIL+HaDu4B69onkNrmNmxUAnYG2S24qISBolE/QvAQPMrJ+ZtSV0rs6pt84cYGz0eiTwlIcnmswBRkVX5fQDBgDzUlO6iIgko8nr6N291sy+DcwFioBb3X2JmU0Cqtx9DnALcKeZrQDeJxwMiNabCbwK1AIXuXsz7o8WEZHWyrpHCZpZDfBWKz6iG7AmReXkikLb50LbX9A+F4rW7HMfd2+wkzPrgr61zKyqsecm5qtC2+dC21/QPheKdO1zVlx1IyIi6aOgFxHJc/kY9FPjLiAGhbbPhba/oH0uFGnZ57xroxcRkS/KxzN6ERGpQ0EvIpLn8ibozexWM1ttZv+Iu5ZMMLPeZva0mb1qZkvM7Ltx15RuZlZqZvPM7JVon38ed02ZYmZFZvaymT0cdy2ZYGZvmtliM1toZlVx15MJZtbZzGaZ2WtmttTMDkvZZ+dLG72ZHQFsAO5w9/3irifdzKwn0NPdF5hZR2A+cLq7vxpzaWkTDX3dwd03mFkJ8BzwXXd/IebS0s7MLgESwC7ufkrc9aSbmb0JJNy9YG6YMrPbgb+6+83RcDM7ufu6VHx23pzRu/uzhOEXCoK7r3L3BdHr9cBSGhgCOp94sCF6WxJN+XGmsgNm1gs4Gbg57lokPcysE3AEYTgZ3H1TqkIe8ijoC1n06MaDgBfjrST9oiaMhcBq4HF3z/t9Bq4H/g+wNe5CMsiBP5vZfDOrjLuYDOgH1KLOVo0AAAFtSURBVADToia6m82sQ6o+XEGf48xsZ2A28D13/yjuetLN3be4+yDCkNdDzCyvm+nM7BRgtbvPj7uWDPu6uw8mPML0oqhpNp8VA4OBm9z9IGAj8KXnc7eUgj6HRe3Us4Hp7v7/4q4nk6KftU8TnkWcz4YCI6I26xnA0WZ2V7wlpZ+7vxP9uRq4n/x/BGk1UF3nF+osQvCnhII+R0Udk7cAS9392rjryQQzKzOzztHr9sBxwGvxVpVe7v4jd+/l7n0Jw38/5e5jYi4rrcysQ3SBAVHzxfFAXl9N5+7vAW+b2d7RrGMIw7unRJPj0ecKM7sHGAZ0M7Nq4Gfufku8VaXVUOA8YHHUZg1wmbv/Kcaa0q0ncLuZFRFOUma6e0FcblhgvgLcH85lKAbudvfH4i0pIy4GpkdX3KwExqXqg/Pm8koREWmYmm5ERPKcgl5EJM8p6EVE8pyCXkQkzynoRUTynIJeRCTPKehFRPLc/wcyudBI5u1fFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAVE_NAME = 'MRM_E{}_{}'.format(embedding_dims, \"movie\")\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "user = tf.placeholder(tf.int32,shape=(1,))\n",
    "i = tf.placeholder(tf.int32, shape=(1,))\n",
    "j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "#多少個auxliary \n",
    "xf = tf.placeholder(tf.float32, shape=(None, ft_dim))\n",
    "l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "r = tf.placeholder(tf.float32,shape=(None,))\n",
    "positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "\n",
    "image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "with tf.variable_scope(\"item_level\"):\n",
    "    user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=8))\n",
    "    item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=9)) \n",
    "    aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                               initializer=tf.random_normal_initializer(0,0.1,seed=10))\n",
    "\n",
    "#     W1 = tf.get_variable(\"W1\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wu = tf.get_variable(\"Wu\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wy = tf.get_variable(\"Wy\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wa = tf.get_variable(\"Wa\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wv = tf.get_variable(\"Wv\", [usr_nb, movie_nb, embedding_dims], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#     Wve = tf.get_variable(\"Wve\", [embedding_dims, ft_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "with tf.variable_scope('feature_level'):\n",
    "    embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                           initializer=tf.random_normal_initializer(0.01, 0.001, seed=10))\n",
    "\n",
    "#lookup the latent factors by user and id\n",
    "u = tf.nn.embedding_lookup(user_latent, user)\n",
    "vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "# w1 = tf.nn.embedding_lookup(W1, user)\n",
    "wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user))\n",
    "wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user))\n",
    "wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user))\n",
    "wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user))\n",
    "\n",
    "beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n",
    "\n",
    "a_list = tf.Variable([])\n",
    "q = tf.constant(0)\n",
    "\n",
    "def att_cond(q,a_list):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def att_body(q,a_list):\n",
    "    xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "\n",
    "    a_list = tf.concat([a_list,[(tf.nn.relu(tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                            tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                            tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                            tf.matmul(wvui, tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "    q += 1\n",
    "    return q, a_list\n",
    "\n",
    "_, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "\n",
    "norm_par = [wu,wy,wa,wv]\n",
    "\n",
    "wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "\n",
    "last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "\n",
    "aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "q = tf.constant(0)\n",
    "\n",
    "def sum_att_cond(q,aux_np):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def sum_att_body(q,aux_np):\n",
    "    aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "    q += 1\n",
    "    return q, aux_np\n",
    "\n",
    "_, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "#矩陣中對應函數各自相乘\n",
    "# ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "l2_norm = tf.add_n([\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "            0.00001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "\n",
    "            0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "            0.00001 * tf.reduce_sum(tf.multiply(embedding,embedding))\n",
    "          ])\n",
    "\n",
    "loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "\n",
    "loss_acc_list = training(SAVE_NAME)\n",
    "\n",
    "# training history\n",
    "epochs = range(1, len(loss_acc_list) + 1)\n",
    "print('Epoch:', epochs)\n",
    "loss = [ls[0].tolist()[0][0] for ls in loss_acc_list]\n",
    "print('Loss:', loss)\n",
    "acc = [ls[1] for ls in loss_acc_list]\n",
    "print('Acc:', acc)\n",
    "print('==================================================')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1\n",
    "\n",
    "def topN(RSls, n):\n",
    "    maxn = np.argsort(RSls)[::-1][:n]\n",
    "    return maxn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def allSortPrepare(testRS):\n",
    "    all_sort = []\n",
    "\n",
    "    for i in range(usr_test_amount):\n",
    "        all_sort.append(topN(list(testRS[i]),len(testRS[i])))\n",
    "\n",
    "    all_sort = np.asarray(all_sort)\n",
    "    print(all_sort.shape)\n",
    "    return all_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DCG(prec_list): #找出前n名的[1,1,1,0,...]\n",
    "    dcg = 0\n",
    "    for i in range(len(prec_list)):\n",
    "        dcg += (2**prec_list[i]-1)/math.log2(i+2)\n",
    "    return dcg\n",
    "\n",
    "def NDCG(target, testRS, num_ndcg, all_sort): #target是真正的喜好\n",
    "    total_ndcg = 0\n",
    "    \n",
    "    for m in range(usr_test_amount): # the number of testing users\n",
    "        idcg = DCG(target[m][:num_ndcg])\n",
    "        \n",
    "        pre_list = []\n",
    "        for s in all_sort[m][:num_ndcg]:\n",
    "            #print(m,s,target[m][s])\n",
    "            pre_list.append(target[m][s]) #把prec_list 的 score加進去\n",
    "        \n",
    "        dcg = DCG(pre_list)\n",
    "        ndcg = dcg/idcg\n",
    "        total_ndcg += ndcg\n",
    "        \n",
    "    avg_ndcg = total_ndcg/usr_test_amount\n",
    "    return avg_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(target,testRS):\n",
    "    total_prec = 0\n",
    "    for u in range(usr_test_amount):\n",
    "        y_true = target[u]\n",
    "        y_scores = testRS[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/usr_test_amount\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(testRS, target, sumtarget, all_sort):\n",
    "    print('\\n==============================\\n')\n",
    "    # Top N\n",
    "    N = [1, 5]\n",
    "    correct = 0\n",
    "\n",
    "    for n in N:\n",
    "        print('Top', n)\n",
    "        correct = 0\n",
    "\n",
    "        for i in range(len(testRS)):\n",
    "            topn = topN(testRS[i], n)\n",
    "            sum_target = int(np.sum(target[i]))\n",
    "\n",
    "            TP = 0\n",
    "            for i in topn:\n",
    "                if i < sum_target:\n",
    "                    TP += 1\n",
    "\n",
    "            correct += TP\n",
    "\n",
    "        prec = correct/(len(testRS)*n) #150*n\n",
    "        recall = correct/sumtarget\n",
    "\n",
    "        print('prec:', prec)\n",
    "        print('recall:', recall)\n",
    "        print('F1_score:', F1_score(prec, recall))\n",
    "        print('*****')\n",
    "\n",
    "    print('\\n==============================\\n')\n",
    "\n",
    "    # NDCG\n",
    "    num_ndcgs = [5, 10]\n",
    "    for num_ndcg in num_ndcgs:\n",
    "        print('NDCG@', num_ndcg)\n",
    "        print('NDCG score:', NDCG(target, testRS, num_ndcg, all_sort))\n",
    "        print('*****')\n",
    "\n",
    "    print('\\n==============================\\n')\n",
    "\n",
    "    # MAP\n",
    "    print('MAP:', MAP(target,testRS))\n",
    "    print('\\n==============================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def testing(U, Y, A, E, Au, Ay, Aa, Av, B):\n",
    "    #with Embedding\n",
    "    result = np.zeros((usr_test_amount, movie_nb))\n",
    "    RS = np.zeros((usr_test_amount, movie_nb))\n",
    "\n",
    "    #test_idx --> Test 的 index length = 150\n",
    "    sum_alpha = 0\n",
    "    test_yes_id = []\n",
    "\n",
    "    for s in range(usr_test_amount):\n",
    "#         print(s, test_idx[s])\n",
    "        \n",
    "        yes = []\n",
    "        sample = [i for i in range(movie_nb)]\n",
    "        alpha = np.zeros([len(sample)])\n",
    "        \n",
    "        for a in range(len(sample)):\n",
    "            r = np.max(movie_genre[sample[a]] * usr_genre_norm[test_idx[s]]) #sample a 的category vec *user_category vec\n",
    "\n",
    "    # #         ''' Observe each part in attention\n",
    "    #         WuUu = np.sum(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0).T))\n",
    "    #         WyYy = np.sum(np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T))\n",
    "    #         WaAa = np.sum(np.dot(Aa[test_idx[s]],np.expand_dims(A[sample[a]],0).T))\n",
    "    #         WvVy = np.sum(np.dot(np.dot(Av[test_idx[s]], E),np.expand_dims(all_npy[sample[a]],0).T))\n",
    "    #         print('The sum of each par -->',\n",
    "    #               '\\nw1:',testW1,\n",
    "    #               '\\nWuU:',WuUu,\n",
    "    #               '\\nwyY:',WyYy,\n",
    "    #               '\\nWaA:',WaAa,\n",
    "    #               '\\nWvV:',WvVy)\n",
    "    # #         '''\n",
    "\n",
    "            alpha_a = (np.dot(Au[test_idx[s]][sample[a]],np.expand_dims(U[test_idx[s]],0).T) + \n",
    "                       np.dot(Ay[test_idx[s]][sample[a]],np.expand_dims(Y[sample[a]],0).T) + \n",
    "                       np.dot(Aa[test_idx[s]][sample[a]],np.expand_dims(A[sample[a]],0).T) +\n",
    "                       np.dot(Av[test_idx[s]][sample[a]],np.dot(E,np.expand_dims(all_npy[sample[a]],0).T)))\n",
    "\n",
    "\n",
    "            # relu part\n",
    "            alpha[a]=np.sum((relu(alpha_a)))*r\n",
    "            # tanh part\n",
    "    #         alpha[a]=np.sum((np.tanh(alpha_a)))*r\n",
    "\n",
    "        mul = np.zeros((1,latent_dim))\n",
    "        added_alpha = np.add(alpha,0.0000000001)\n",
    "        norm_alpha = added_alpha/np.sum(added_alpha)\n",
    "        sum_alpha += np.sum(alpha)\n",
    "\n",
    "#         print(\"{:<15}{}\".format('sum_alpha:', sum_alpha))\n",
    "#         print('==================================================')\n",
    "\n",
    "        for i in range(len(sample)):\n",
    "            mul += norm_alpha[i] * A[sample[i]] # attention alpha*Ai part\n",
    "        new_mul = mul + U[test_idx[s]]  #(U+auxilary)\n",
    "\n",
    "        for k in range(movie_test_amount):\n",
    "            result[s][k] = np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "            RS[s][k] = np.dot(new_mul,Y[k].T) + np.dot(B[test_idx[s]], np.dot(E, all_npy[k].T))\n",
    "        \n",
    "    #取出test的資料\n",
    "    print(RS.shape)\n",
    "\n",
    "    testRS = np.zeros((usr_test_amount, movie_test_amount)) #shape 150 * 32\n",
    "    target = np.zeros((usr_test_amount, movie_test_amount)) #shape 150 * 32\n",
    "\n",
    "    for z in range(usr_test_amount):\n",
    "        user_id = test_idx[z]\n",
    "        # positive target YouTuber list\n",
    "        youtube_t = test_t[z] \n",
    "        # not target YouTuber list\n",
    "        youtube_f = test_f[z]\n",
    "\n",
    "#         print(user_id)\n",
    "#         print(youtube_t)\n",
    "#         print(youtube_f)\n",
    "\n",
    "        #前面放target的RS\n",
    "        for i in range(len(youtube_t)):\n",
    "            testRS[z][i] = RS[z][youtube_t[i]]\n",
    "            target[z][i] = 1\n",
    "\n",
    "        for i in range(len(youtube_f)):\n",
    "            testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]\n",
    "\n",
    "    #     print(testRS[z])\n",
    "    #     print(target[z])\n",
    "    #     print('==============================')\n",
    "\n",
    "    print(target.shape, testRS.shape)\n",
    "    sumtarget = np.sum(target)\n",
    "    print('num of positive data in testing:', sumtarget) # whole matrix: 4800\n",
    "\n",
    "    # for metrics\n",
    "    metrics(testRS, target, sumtarget, allSortPrepare(testRS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = 'MRM_E240_movie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FILE = './weight/coldstart/' + SAVE_NAME + '.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent factor and Each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRM_E240_movie\n",
      "User latent shape:  (100, 64)\n",
      "photo latent shape:  (165, 64)\n",
      "Auxilary latent shape:  (165, 64)\n",
      "Embedding shape: (240, 2372)\n",
      "Wu weight shape: (100, 165, 64)\n",
      "Wy weight shape: (100, 165, 64)\n",
      "Wa weight shape: (100, 165, 64)\n",
      "Wv weight shape: (100, 165, 240)\n",
      "Beta shape: (100, 240)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1036 is out of bounds for axis 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-664f09b8775d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Beta shape:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=================================================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-1d9e8c22d3e9>\u001b[0m in \u001b[0;36mtesting\u001b[0;34m(U, Y, A, E, Au, Ay, Aa, Av, B)\u001b[0m\n\u001b[1;32m     33\u001b[0m             alpha_a = (np.dot(Au[test_idx[s]][sample[a]],np.expand_dims(U[test_idx[s]],0).T) + \n\u001b[1;32m     34\u001b[0m                        \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                        \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                        np.dot(Av[test_idx[s]][sample[a]],np.dot(E,np.expand_dims(all_npy[sample[a]],0).T)))\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1036 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "print(SAVE_NAME)\n",
    "\n",
    "params = np.load(SAVE_FILE)\n",
    "\n",
    "U = params['U']\n",
    "Y = params['Y']\n",
    "A = params['A']\n",
    "E = params['E']\n",
    "Au = params['Wu']\n",
    "Ay = params['Wy']\n",
    "Aa = params['Wa']\n",
    "Av = params['Wv']\n",
    "B = params['B']\n",
    "\n",
    "print('User latent shape: ',U.shape)\n",
    "print('photo latent shape: ', Y.shape)\n",
    "print('Auxilary latent shape: ',A.shape)\n",
    "print('Embedding shape:', E.shape)\n",
    "print('Wu weight shape:', Au.shape)\n",
    "print('Wy weight shape:', Ay.shape)\n",
    "print('Wa weight shape:', Aa.shape)\n",
    "print('Wv weight shape:', Av.shape)\n",
    "print('Beta shape:',B.shape)\n",
    "\n",
    "testing(U, Y, A, E, Au, Ay, Aa, Av, B)\n",
    "print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
