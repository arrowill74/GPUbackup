{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "def writeProgress(msg, count, total):\n",
    "    sys.stdout.write(msg + \"{:.2%}\\r\".format(count/total))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: (165, 2372)\n",
      "Movie genre: (165, 20)\n",
      "User following: (1582, 165)\n",
      "User genre: (1582, 20)\n"
     ]
    }
   ],
   "source": [
    "all_npy = np.load('./npy/all_2372.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "\n",
    "print('All features:', all_npy.shape)\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582 165\n",
      "64 2372 240\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "print(usr_nb, movie_nb)\n",
    "\n",
    "# usr_test_amount = 150\n",
    "# movie_test_amount = 32\n",
    "# print(usr_test_amount, movie_test_amount)\n",
    "\n",
    "latent_dim = 64 # latent dims\n",
    "ft_dim = all_npy.shape[1] # feature dims\n",
    "embedding_dims = 240\n",
    "print(latent_dim, ft_dim, embedding_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize usr_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 20)\n"
     ]
    }
   ],
   "source": [
    "usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "for i in range(len(usr_genre)):\n",
    "    usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "print(usr_genre_norm.shape)\n",
    "# print('Before:', usr_genre)\n",
    "# print('After:', usr_genre_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & testing split\n",
    "## Prepare\n",
    "### Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followers: 1\n",
      "Max number of followers: 520\n",
      "Avg of followers: 142.0969696969697\n",
      "The num of followers over 5: 163\n"
     ]
    }
   ],
   "source": [
    "#The number of followers for each movie\n",
    "moive_followers = np.sum(usr_following, axis=0)\n",
    "# print(moive_followers)\n",
    "\n",
    "print('Min number of followers:', np.min(moive_followers))\n",
    "print('Max number of followers:', np.max(moive_followers))\n",
    "print('Avg of followers:', np.mean(moive_followers))\n",
    "\n",
    "asc = np.sort(moive_followers)\n",
    "# print(asc)\n",
    "desc = np.flip(asc)\n",
    "# print(desc)\n",
    "\n",
    "over5 = 0\n",
    "for num in moive_followers:\n",
    "    if num >= 5:\n",
    "        over5 += 1\n",
    "print('The num of followers over 5:', over5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<= 100: 76\n",
      "(76,) [  6   7   8  11  13  14  15  16  17  19  20  23  26  27  29  31  32  33\n",
      "  35  36  38  39  41  43  45  46  47  48  51  54  56  59  61  63  65  67\n",
      "  69  70  71  73  76  82  83  88  90  92  94  95  97  98 105 107 109 110\n",
      " 113 115 116 117 124 130 132 133 135 136 138 139 140 145 146 148 150 155\n",
      " 157 158 160 162]\n"
     ]
    }
   ],
   "source": [
    "# print('<= 10:', np.sum(moive_followers <= 10))\n",
    "# print('<= 20:', np.sum(moive_followers <= 20))\n",
    "# print('<= 30:', np.sum(moive_followers <= 30))\n",
    "# print('<= 40:', np.sum(moive_followers <= 40))\n",
    "# print('<= 50:', np.sum(moive_followers <= 50))\n",
    "print('<= 100:', np.sum(moive_followers <= 100))\n",
    "less_idx = np.nonzero(moive_followers <= 100)[0]\n",
    "print(less_idx.shape, less_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 165)\n",
      "(165, 1582)\n"
     ]
    }
   ],
   "source": [
    "print(usr_following.shape)\n",
    "usr_following = usr_following.T\n",
    "print(usr_following.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 6\n",
      "Sum: 37\n",
      "37\n",
      "==================================================\n",
      "Index: 7\n",
      "Sum: 1\n",
      "38\n",
      "==================================================\n",
      "Index: 8\n",
      "Sum: 37\n",
      "69\n",
      "==================================================\n",
      "Index: 11\n",
      "Sum: 75\n",
      "141\n",
      "==================================================\n",
      "Index: 13\n",
      "Sum: 97\n",
      "221\n",
      "==================================================\n",
      "Index: 14\n",
      "Sum: 23\n",
      "235\n",
      "==================================================\n",
      "Index: 15\n",
      "Sum: 18\n",
      "248\n",
      "==================================================\n",
      "Index: 16\n",
      "Sum: 31\n",
      "269\n",
      "==================================================\n",
      "Index: 17\n",
      "Sum: 61\n",
      "314\n",
      "==================================================\n",
      "Index: 19\n",
      "Sum: 78\n",
      "357\n",
      "==================================================\n",
      "Index: 20\n",
      "Sum: 61\n",
      "394\n",
      "==================================================\n",
      "Index: 23\n",
      "Sum: 72\n",
      "433\n",
      "==================================================\n",
      "Index: 26\n",
      "Sum: 90\n",
      "484\n",
      "==================================================\n",
      "Index: 27\n",
      "Sum: 23\n",
      "497\n",
      "==================================================\n",
      "Index: 29\n",
      "Sum: 32\n",
      "510\n",
      "==================================================\n",
      "Index: 31\n",
      "Sum: 58\n",
      "532\n",
      "==================================================\n",
      "Index: 32\n",
      "Sum: 61\n",
      "572\n",
      "==================================================\n",
      "Index: 33\n",
      "Sum: 80\n",
      "624\n",
      "==================================================\n",
      "Index: 35\n",
      "Sum: 11\n",
      "628\n",
      "==================================================\n",
      "Index: 36\n",
      "Sum: 78\n",
      "652\n",
      "==================================================\n",
      "Index: 38\n",
      "Sum: 28\n",
      "659\n",
      "==================================================\n",
      "Index: 39\n",
      "Sum: 49\n",
      "677\n",
      "==================================================\n",
      "Index: 41\n",
      "Sum: 82\n",
      "717\n",
      "==================================================\n",
      "Index: 43\n",
      "Sum: 70\n",
      "743\n",
      "==================================================\n",
      "Index: 45\n",
      "Sum: 81\n",
      "778\n",
      "==================================================\n",
      "Index: 46\n",
      "Sum: 77\n",
      "810\n",
      "==================================================\n",
      "Index: 47\n",
      "Sum: 89\n",
      "838\n",
      "==================================================\n",
      "Index: 48\n",
      "Sum: 49\n",
      "849\n",
      "==================================================\n",
      "Index: 51\n",
      "Sum: 19\n",
      "851\n",
      "==================================================\n",
      "Index: 54\n",
      "Sum: 18\n",
      "854\n",
      "==================================================\n",
      "Index: 56\n",
      "Sum: 22\n",
      "861\n",
      "==================================================\n",
      "Index: 59\n",
      "Sum: 24\n",
      "864\n",
      "==================================================\n",
      "Index: 61\n",
      "Sum: 41\n",
      "879\n",
      "==================================================\n",
      "Index: 63\n",
      "Sum: 58\n",
      "893\n",
      "==================================================\n",
      "Index: 65\n",
      "Sum: 4\n",
      "894\n",
      "==================================================\n",
      "Index: 67\n",
      "Sum: 76\n",
      "903\n",
      "==================================================\n",
      "Index: 69\n",
      "Sum: 40\n",
      "909\n",
      "==================================================\n",
      "Index: 70\n",
      "Sum: 41\n",
      "922\n",
      "==================================================\n",
      "Index: 71\n",
      "Sum: 20\n",
      "926\n",
      "==================================================\n",
      "Index: 73\n",
      "Sum: 43\n",
      "931\n",
      "==================================================\n",
      "Index: 76\n",
      "Sum: 93\n",
      "956\n",
      "==================================================\n",
      "Index: 82\n",
      "Sum: 78\n",
      "987\n",
      "==================================================\n",
      "Index: 83\n",
      "Sum: 82\n",
      "1003\n",
      "==================================================\n",
      "Index: 88\n",
      "Sum: 44\n",
      "1007\n",
      "==================================================\n",
      "Index: 90\n",
      "Sum: 68\n",
      "1015\n",
      "==================================================\n",
      "Index: 92\n",
      "Sum: 73\n",
      "1029\n",
      "==================================================\n",
      "Index: 94\n",
      "Sum: 73\n",
      "1036\n",
      "==================================================\n",
      "Index: 95\n",
      "Sum: 31\n",
      "1039\n",
      "==================================================\n",
      "Index: 97\n",
      "Sum: 9\n",
      "1042\n",
      "==================================================\n",
      "Index: 98\n",
      "Sum: 72\n",
      "1051\n",
      "==================================================\n",
      "Index: 105\n",
      "Sum: 71\n",
      "1063\n",
      "==================================================\n",
      "Index: 107\n",
      "Sum: 97\n",
      "1079\n",
      "==================================================\n",
      "Index: 109\n",
      "Sum: 59\n",
      "1083\n",
      "==================================================\n",
      "Index: 110\n",
      "Sum: 33\n",
      "1086\n",
      "==================================================\n",
      "Index: 113\n",
      "Sum: 12\n",
      "1087\n",
      "==================================================\n",
      "Index: 115\n",
      "Sum: 35\n",
      "1093\n",
      "==================================================\n",
      "Index: 116\n",
      "Sum: 39\n",
      "1098\n",
      "==================================================\n",
      "Index: 117\n",
      "Sum: 63\n",
      "1104\n",
      "==================================================\n",
      "Index: 124\n",
      "Sum: 52\n",
      "1109\n",
      "==================================================\n",
      "Index: 130\n",
      "Sum: 19\n",
      "1111\n",
      "==================================================\n",
      "Index: 132\n",
      "Sum: 37\n",
      "1117\n",
      "==================================================\n",
      "Index: 133\n",
      "Sum: 48\n",
      "1123\n",
      "==================================================\n",
      "Index: 135\n",
      "Sum: 64\n",
      "1125\n",
      "==================================================\n",
      "Index: 136\n",
      "Sum: 46\n",
      "1126\n",
      "==================================================\n",
      "Index: 138\n",
      "Sum: 83\n",
      "1133\n",
      "==================================================\n",
      "Index: 139\n",
      "Sum: 14\n",
      "1136\n",
      "==================================================\n",
      "Index: 140\n",
      "Sum: 20\n",
      "1136\n",
      "==================================================\n",
      "Index: 145\n",
      "Sum: 25\n",
      "1136\n",
      "==================================================\n",
      "Index: 146\n",
      "Sum: 26\n",
      "1137\n",
      "==================================================\n",
      "Index: 148\n",
      "Sum: 64\n",
      "1144\n",
      "==================================================\n",
      "Index: 150\n",
      "Sum: 96\n",
      "1159\n",
      "==================================================\n",
      "Index: 155\n",
      "Sum: 40\n",
      "1166\n",
      "==================================================\n",
      "Index: 157\n",
      "Sum: 66\n",
      "1170\n",
      "==================================================\n",
      "Index: 158\n",
      "Sum: 89\n",
      "1178\n",
      "==================================================\n",
      "Index: 160\n",
      "Sum: 29\n",
      "1185\n",
      "==================================================\n",
      "Index: 162\n",
      "Sum: 11\n",
      "1185\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "st = set()\n",
    "for idx in less_idx:\n",
    "    print('Index:', idx)\n",
    "    print('Sum:', usr_following[idx].sum())\n",
    "#     print(usr_following[idx])\n",
    "    li = list(np.where(usr_following[idx] == 1)[0])\n",
    "#     print(li)\n",
    "    st = st | set(li)\n",
    "    print(len(st))\n",
    "    print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1185 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "test_idx = list(st)\n",
    "test_idx.sort()\n",
    "print(len(test_idx), test_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1185 76\n"
     ]
    }
   ],
   "source": [
    "usr_test_amount = len(test_idx)\n",
    "movie_test_amount = len(less_idx)\n",
    "print(usr_test_amount, movie_test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 165)\n"
     ]
    }
   ],
   "source": [
    "usr_following = usr_following.T\n",
    "print(usr_following.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat of user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1582, 76)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldarea = usr_following[:, less_idx]\n",
    "coldarea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of followings: 0\n",
      "Max number of followings: 52\n",
      "Avg of followers: 2.4121365360303413\n"
     ]
    }
   ],
   "source": [
    "#The number of following movie for each user\n",
    "each_user = np.sum(coldarea, axis=1)\n",
    "# print(each_user)\n",
    "\n",
    "print('Min number of followings:', np.min(each_user))\n",
    "print('Max number of followings:', np.max(each_user))\n",
    "print('Avg of followers:', np.mean(each_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">= 1 : 1185\n",
      ">= 2 : 831\n",
      ">= 3 : 554\n",
      ">= 4 : 377\n",
      ">= 5 : 228\n",
      ">= 6 : 161\n",
      ">= 7 : 108\n",
      ">= 8 : 76\n",
      ">= 9 : 53\n",
      ">= 10 : 39\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    print('>=', i, ':', np.sum(each_user >= i))\n",
    "# print('>', i, ':', np.sum(each_user > 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [1036, 165, 670, 720, 1363, 494, 854, 367, 1329, 245]\n"
     ]
    }
   ],
   "source": [
    "test_idx = list(each_user.argsort()[::-1][:100])\n",
    "print(len(test_idx), test_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_test_idx = []\n",
    "# for i in test_idx:\n",
    "#     add = 0\n",
    "#     for j in less_idx:\n",
    "#         if usr_following[i][j] == 1:\n",
    "#             add += 1\n",
    "            \n",
    "#     if add >= 6:\n",
    "#         new_test_idx.append(i)\n",
    "# print(len(new_test_idx))\n",
    "# random.seed(42)\n",
    "# test_idx = random.sample(new_test_idx, 100)\n",
    "# test_idx.sort()\n",
    "# print(len(test_idx), test_idx[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 32\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(test_idx)\n",
    "usr_test_amount = len(test_idx)\n",
    "movie_test_amount = 32 #math.floor(len(less_idx)*0.5)\n",
    "print(usr_test_amount, movie_test_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init\n",
    "random.seed(42)\n",
    "train_t = []\n",
    "train_f = []\n",
    "test_t = []\n",
    "test_f = []\n",
    "\n",
    "for i in test_idx:\n",
    "    # init\n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    t_for_test = []\n",
    "    f_for_test = []\n",
    "    \n",
    "    temp_t = []\n",
    "    temp_f = []\n",
    "    for j in less_idx:\n",
    "        if usr_following[i][j] == 1:\n",
    "            temp_t.append(j)\n",
    "        else:\n",
    "            temp_f.append(j)\n",
    "            \n",
    "    t_for_test = random.sample(temp_t, math.ceil(0.5*len(temp_t)))\n",
    "    f_for_test = random.sample(temp_f, movie_test_amount-len(t_for_test))\n",
    "    \n",
    "    test_t.append(t_for_test)\n",
    "    test_f.append(f_for_test)\n",
    "    \n",
    "    t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "    f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "    train_t.append(t_for_train)\n",
    "    train_f.append(f_for_train)\n",
    "    \n",
    "    if not (len(t_for_train) + len(f_for_train) + len(t_for_test) + len(f_for_test)) == len(less_idx):\n",
    "        print('Error!!!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 100\n",
      "The length of train_f: 100\n",
      "The length of test_t: 100\n",
      "The length of test_f: 100\n"
     ]
    }
   ],
   "source": [
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_f))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 511 5.11\n",
      "Testing: 561 5.61\n"
     ]
    }
   ],
   "source": [
    "#average num of following for training user\n",
    "total_train = 0\n",
    "for t in train_t:\n",
    "    total_train += len(t)\n",
    "avg = total_train / usr_test_amount\n",
    "print('Training:', total_train, avg)\n",
    "\n",
    "#average num of following for testing user\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test / usr_test_amount\n",
    "print('Testing:', total_test, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_auxilary = [i for i in range(movie_nb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation model\n",
    "## Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(SAVE_NAME):\n",
    "    print('==================================================')\n",
    "    print(SAVE_NAME)\n",
    "    print('Start time:', time.ctime())\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    loss_acc_list = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_yes_id=[]\n",
    "\n",
    "    for q in range(6):\n",
    "        print('Epoch:',q)\n",
    "        train_auc = 0\n",
    "        total_loss = 0\n",
    "        xuij_auc = 0\n",
    "        length = 0\n",
    "\n",
    "        for z in range(usr_test_amount):\n",
    "            idx = test_idx[z]\n",
    "            writeProgress('Idx: {}\\tProgress:'.format(idx), z, usr_test_amount)\n",
    "            \"\"\"\n",
    "            yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "            yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "            r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "            \"\"\"\n",
    "            yes = []\n",
    "            yesr = []\n",
    "\n",
    "    #         #選全部的Positive\n",
    "    #         sample = random.sample(train_t[z],len(train_t[z]))\n",
    "            #選全部的電影\n",
    "            sample = all_auxilary\n",
    "\n",
    "            #change\n",
    "            r_3 = np.zeros(len(sample))\n",
    "\n",
    "            for b in range(len(sample)):\n",
    "                yes.append(all_npy[sample[b]])\n",
    "                yesr.append(movie_genre[sample[b]] * usr_genre_norm[idx])\n",
    "\n",
    "            for b in range(len(yesr)):\n",
    "                r_3[b]=max(yesr[b])\n",
    "            #print('r_3:',r_3)\n",
    "\n",
    "            yes = np.array(yes)\n",
    "\n",
    "            # positive sample\n",
    "            train_t_sample = train_t[z]\n",
    "            for ta in train_t_sample:\n",
    "                #print(ta,'--> positive feedback')\n",
    "\n",
    "                pos = sample.index(ta)\n",
    "\n",
    "                image_1 = np.expand_dims(all_npy[ta],0)\n",
    "                train_f_sample = train_f[z] #random.sample(train_f[z],10)\n",
    "\n",
    "                for b in train_f_sample:\n",
    "                    image_2 = np.expand_dims(all_npy[b],0)\n",
    "\n",
    "                    _last_be_relu, _norm_par, _a_list, r3, _auc, _loss, _ = sess.run(\n",
    "                        [last_be_relu, norm_par, a_list_smooth, a_list_soft, auc, loss, train_op], \n",
    "                        feed_dict={user: [z], i: [ta], j: [b], xf: yes, \n",
    "                                   l_id:sample, l_id_len:[len(sample)],\n",
    "                                   positive_id: train_t[z], positive_len:[len(train_t[z])],\n",
    "                                   r: r_3, image_i: image_1, image_j: image_2})\n",
    "\n",
    "                    '''Observe all params\n",
    "                    print('u,vi,vj',_norm_par[:3])\n",
    "                    print('w1,wu,wy,wa,wv',_norm_par[3:7])\n",
    "                    print('beta',_norm_par[7])\n",
    "                    print('Embedding',_norm_par[8])\n",
    "                    print('after softmax:', r3)\n",
    "                    print('before softmax:', _a_list)\n",
    "                    print('---------------------------------------------------')\n",
    "                    '''\n",
    "                    train_auc += _auc\n",
    "                    total_loss += _loss\n",
    "                    length += 1\n",
    "\n",
    "        print(\"{:<20}{}\".format('total_loss', total_loss/length))\n",
    "        print(\"{:<20}{}\".format('train_auc:', train_auc/length))\n",
    "\n",
    "        loss_acc_list.append([total_loss/length, train_auc/length])\n",
    "\n",
    "        print('\\tCurrent time:', time.ctime(), ' sec')\n",
    "        print('==================================================')\n",
    "\n",
    "    print('Total cost time:',time.time()-t0, ' sec')\n",
    "\n",
    "    print('End time:', time.ctime())\n",
    "    \n",
    "    U, Y, A, E, Au, Ay, Aa, Av, B = sess.run([user_latent, item_latent, aux_item, embedding, Wu, Wy, Wa, Wv, Beta])\n",
    "    np.savez('./weight/coldstart/' + SAVE_NAME + '.npz',\n",
    "             U=U, Y=Y, A=A, E=E, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av, B=B)\n",
    "    \n",
    "    return loss_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-25-8457192f1bab>:141: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "==================================================\n",
      "MRM_E240_movie\n",
      "Start time: Fri May 15 11:00:28 2020\n",
      "Epoch: 0\n",
      "total_loss          [[0.23310116]]\n",
      "train_auc:          0.9133421400264201\n",
      "\tCurrent time: Fri May 15 11:11:16 2020  sec\n",
      "==================================================\n",
      "Epoch: 1\n",
      "total_loss          [[0.05805049]]\n",
      "train_auc:          0.9871070013210039\n",
      "\tCurrent time: Fri May 15 11:22:03 2020  sec\n",
      "==================================================\n",
      "Epoch: 2\n",
      "total_loss          [[0.0168768]]\n",
      "train_auc:          0.9990488771466315\n",
      "\tCurrent time: Fri May 15 11:32:50 2020  sec\n",
      "==================================================\n",
      "Epoch: 3\n",
      "total_loss          [[0.00930355]]\n",
      "train_auc:          0.9998414795244386\n",
      "\tCurrent time: Fri May 15 11:43:37 2020  sec\n",
      "==================================================\n",
      "Epoch: 4\n",
      "total_loss          [[0.00648063]]\n",
      "train_auc:          1.0\n",
      "\tCurrent time: Fri May 15 11:54:24 2020  sec\n",
      "==================================================\n",
      "Epoch: 5\n",
      "total_loss          [[0.00527268]]\n",
      "train_auc:          1.0\n",
      "\tCurrent time: Fri May 15 12:05:11 2020  sec\n",
      "==================================================\n",
      "Total cost time: 3881.5478599071503  sec\n",
      "End time: Fri May 15 12:05:11 2020\n",
      "Epoch: range(1, 7)\n",
      "Loss: [0.23310115933418274, 0.058050487190485, 0.01687680371105671, 0.009303554892539978, 0.006480630021542311, 0.005272675771266222]\n",
      "Acc: [0.9133421400264201, 0.9871070013210039, 0.9990488771466315, 0.9998414795244386, 1.0, 1.0]\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAVE_NAME = 'MRM_E{}_{}'.format(embedding_dims, \"movie\")\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "user = tf.placeholder(tf.int32,shape=(1,))\n",
    "i = tf.placeholder(tf.int32, shape=(1,))\n",
    "j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "#多少個auxliary \n",
    "xf = tf.placeholder(tf.float32, shape=(None, ft_dim))\n",
    "l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "r = tf.placeholder(tf.float32,shape=(None,))\n",
    "positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "\n",
    "image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "with tf.variable_scope(\"item_level\"):\n",
    "    user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=8))\n",
    "    item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=9)) \n",
    "    aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                               initializer=tf.random_normal_initializer(0,0.1,seed=10))\n",
    "\n",
    "#     W1 = tf.get_variable(\"W1\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wu = tf.get_variable(\"Wu\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wy = tf.get_variable(\"Wy\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wa = tf.get_variable(\"Wa\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wv = tf.get_variable(\"Wv\", [usr_nb, movie_nb, embedding_dims], initializer=tf.contrib.layers.xavier_initializer())\n",
    "#     Wve = tf.get_variable(\"Wve\", [embedding_dims, ft_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "with tf.variable_scope('feature_level'):\n",
    "    embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                           initializer=tf.random_normal_initializer(0.01, 0.001, seed=10))\n",
    "\n",
    "#lookup the latent factors by user and id\n",
    "u = tf.nn.embedding_lookup(user_latent, user)\n",
    "vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "# w1 = tf.nn.embedding_lookup(W1, user)\n",
    "wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user))\n",
    "wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user))\n",
    "wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user))\n",
    "wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user))\n",
    "\n",
    "beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n",
    "\n",
    "a_list = tf.Variable([])\n",
    "q = tf.constant(0)\n",
    "\n",
    "def att_cond(q,a_list):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def att_body(q,a_list):\n",
    "    xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "\n",
    "    a_list = tf.concat([a_list,[(tf.nn.relu(tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                            tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                            tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                            tf.matmul(wvui, tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "    q += 1\n",
    "    return q, a_list\n",
    "\n",
    "_, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "\n",
    "norm_par = [wu,wy,wa,wv]\n",
    "\n",
    "wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "\n",
    "last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "\n",
    "aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "q = tf.constant(0)\n",
    "\n",
    "def sum_att_cond(q,aux_np):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def sum_att_body(q,aux_np):\n",
    "    aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "    q += 1\n",
    "    return q, aux_np\n",
    "\n",
    "_, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "#矩陣中對應函數各自相乘\n",
    "# ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "l2_norm = tf.add_n([\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "            0.01 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "            0.00001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "\n",
    "            0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "            0.00001 * tf.reduce_sum(tf.multiply(embedding,embedding))\n",
    "          ])\n",
    "\n",
    "loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "\n",
    "loss_acc_list = training(SAVE_NAME)\n",
    "\n",
    "# training history\n",
    "epochs = range(1, len(loss_acc_list) + 1)\n",
    "print('Epoch:', epochs)\n",
    "loss = [ls[0].tolist()[0][0] for ls in loss_acc_list]\n",
    "print('Loss:', loss)\n",
    "acc = [ls[1] for ls in loss_acc_list]\n",
    "print('Acc:', acc)\n",
    "print('==================================================')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1\n",
    "\n",
    "def topN(RSls, n):\n",
    "    maxn = np.argsort(RSls)[::-1][:n]\n",
    "    return maxn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def allSortPrepare(testRS):\n",
    "    all_sort = []\n",
    "\n",
    "    for i in range(usr_test_amount):\n",
    "        all_sort.append(topN(list(testRS[i]),len(testRS[i])))\n",
    "\n",
    "    all_sort = np.asarray(all_sort)\n",
    "    print(all_sort.shape)\n",
    "    return all_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DCG(prec_list): #找出前n名的[1,1,1,0,...]\n",
    "    dcg = 0\n",
    "    for i in range(len(prec_list)):\n",
    "        dcg += (2**prec_list[i]-1)/math.log2(i+2)\n",
    "    return dcg\n",
    "\n",
    "def NDCG(target, testRS, num_ndcg, all_sort): #target是真正的喜好\n",
    "    total_ndcg = 0\n",
    "    \n",
    "    for m in range(usr_test_amount): # the number of testing users\n",
    "        idcg = DCG(target[m][:num_ndcg])\n",
    "        \n",
    "        pre_list = []\n",
    "        for s in all_sort[m][:num_ndcg]:\n",
    "            #print(m,s,target[m][s])\n",
    "            pre_list.append(target[m][s]) #把prec_list 的 score加進去\n",
    "        \n",
    "        dcg = DCG(pre_list)\n",
    "        ndcg = dcg/idcg\n",
    "        total_ndcg += ndcg\n",
    "        \n",
    "    avg_ndcg = total_ndcg/usr_test_amount\n",
    "    return avg_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(target,testRS):\n",
    "    total_prec = 0\n",
    "    for u in range(usr_test_amount):\n",
    "        y_true = target[u]\n",
    "        y_scores = testRS[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/usr_test_amount\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(testRS, target, sumtarget, all_sort):\n",
    "    print('\\n==============================\\n')\n",
    "    # Top N\n",
    "    N = [1, 5]\n",
    "    correct = 0\n",
    "\n",
    "    for n in N:\n",
    "        print('Top', n)\n",
    "        correct = 0\n",
    "\n",
    "        for i in range(len(testRS)):\n",
    "            topn = topN(testRS[i], n)\n",
    "            sum_target = int(np.sum(target[i]))\n",
    "\n",
    "            TP = 0\n",
    "            for i in topn:\n",
    "                if i < sum_target:\n",
    "                    TP += 1\n",
    "\n",
    "            correct += TP\n",
    "\n",
    "        prec = correct/(len(testRS)*n) #150*n\n",
    "        recall = correct/sumtarget\n",
    "\n",
    "        print('prec:', prec)\n",
    "        print('recall:', recall)\n",
    "        print('F1_score:', F1_score(prec, recall))\n",
    "        print('*****')\n",
    "\n",
    "    print('\\n==============================\\n')\n",
    "\n",
    "    # NDCG\n",
    "    num_ndcgs = [5, 10]\n",
    "    for num_ndcg in num_ndcgs:\n",
    "        print('NDCG@', num_ndcg)\n",
    "        print('NDCG score:', NDCG(target, testRS, num_ndcg, all_sort))\n",
    "        print('*****')\n",
    "\n",
    "    print('\\n==============================\\n')\n",
    "\n",
    "    # MAP\n",
    "    print('MAP:', MAP(target,testRS))\n",
    "    print('\\n==============================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def testing(U, Y, A, E, Au, Ay, Aa, Av, B):\n",
    "    #with Embedding\n",
    "    result = np.zeros((usr_test_amount, movie_nb))\n",
    "    RS = np.zeros((usr_test_amount, movie_nb))\n",
    "\n",
    "    #test_idx --> Test 的 index length = 150\n",
    "    sum_alpha = 0\n",
    "    test_yes_id = []\n",
    "\n",
    "    for s in range(usr_test_amount):\n",
    "#         print(s, test_idx[s])\n",
    "        \n",
    "        yes = []\n",
    "        sample = [i for i in range(movie_nb)]\n",
    "        alpha = np.zeros([len(sample)])\n",
    "        \n",
    "        for a in range(len(sample)):\n",
    "            r = np.max(movie_genre[sample[a]] * usr_genre_norm[test_idx[s]]) #sample a 的category vec *user_category vec\n",
    "\n",
    "    # #         ''' Observe each part in attention\n",
    "    #         WuUu = np.sum(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0).T))\n",
    "    #         WyYy = np.sum(np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T))\n",
    "    #         WaAa = np.sum(np.dot(Aa[test_idx[s]],np.expand_dims(A[sample[a]],0).T))\n",
    "    #         WvVy = np.sum(np.dot(np.dot(Av[test_idx[s]], E),np.expand_dims(all_npy[sample[a]],0).T))\n",
    "    #         print('The sum of each par -->',\n",
    "    #               '\\nw1:',testW1,\n",
    "    #               '\\nWuU:',WuUu,\n",
    "    #               '\\nwyY:',WyYy,\n",
    "    #               '\\nWaA:',WaAa,\n",
    "    #               '\\nWvV:',WvVy)\n",
    "    # #         '''\n",
    "\n",
    "            alpha_a = (np.dot(Au[s][sample[a]],np.expand_dims(U[s],0).T) + \n",
    "                       np.dot(Ay[s][sample[a]],np.expand_dims(Y[sample[a]],0).T) + \n",
    "                       np.dot(Aa[s][sample[a]],np.expand_dims(A[sample[a]],0).T) +\n",
    "                       np.dot(Av[s][sample[a]],np.dot(E,np.expand_dims(all_npy[sample[a]],0).T)))\n",
    "\n",
    "\n",
    "            # relu part\n",
    "            alpha[a]=np.sum((relu(alpha_a)))*r\n",
    "            # tanh part\n",
    "    #         alpha[a]=np.sum((np.tanh(alpha_a)))*r\n",
    "\n",
    "        mul = np.zeros((1,latent_dim))\n",
    "        added_alpha = np.add(alpha,0.0000000001)\n",
    "        norm_alpha = added_alpha/np.sum(added_alpha)\n",
    "        sum_alpha += np.sum(alpha)\n",
    "\n",
    "#         print(\"{:<15}{}\".format('sum_alpha:', sum_alpha))\n",
    "#         print('==================================================')\n",
    "\n",
    "        for i in range(len(sample)):\n",
    "            mul += norm_alpha[i] * A[sample[i]] # attention alpha*Ai part\n",
    "        new_mul = mul + U[s]  #(U+auxilary)\n",
    "\n",
    "        for k in range(movie_test_amount):\n",
    "            result[s][k] = np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "            RS[s][k] = np.dot(new_mul,Y[k].T) + np.dot(B[s], np.dot(E, all_npy[k].T))\n",
    "        \n",
    "    #取出test的資料\n",
    "    print(RS.shape)\n",
    "\n",
    "    testRS = np.zeros((usr_test_amount, movie_test_amount)) #shape 150 * 32\n",
    "    target = np.zeros((usr_test_amount, movie_test_amount)) #shape 150 * 32\n",
    "\n",
    "    for z in range(usr_test_amount):\n",
    "        user_id = test_idx[z]\n",
    "        # positive target YouTuber list\n",
    "        youtube_t = test_t[z] \n",
    "        # not target YouTuber list\n",
    "        youtube_f = test_f[z]\n",
    "\n",
    "#         print(user_id)\n",
    "#         print(youtube_t)\n",
    "#         print(youtube_f)\n",
    "\n",
    "        #前面放target的RS\n",
    "        for i in range(len(youtube_t)):\n",
    "            testRS[z][i] = RS[z][youtube_t[i]]\n",
    "            target[z][i] = 1\n",
    "\n",
    "        for i in range(len(youtube_f)):\n",
    "            testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]\n",
    "\n",
    "    #     print(testRS[z])\n",
    "    #     print(target[z])\n",
    "    #     print('==============================')\n",
    "\n",
    "    print(target.shape, testRS.shape)\n",
    "    sumtarget = np.sum(target)\n",
    "    print('num of positive data in testing:', sumtarget) # whole matrix: 4800\n",
    "\n",
    "    # for metrics\n",
    "    metrics(testRS, target, sumtarget, allSortPrepare(testRS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE_NAME = 'MRM_E240_movie_100_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FILE = './weight/coldstart/' + SAVE_NAME + '.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent factor and Each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRM_E240_movie\n",
      "User latent shape:  (100, 64)\n",
      "photo latent shape:  (165, 64)\n",
      "Auxilary latent shape:  (165, 64)\n",
      "Embedding shape: (240, 2372)\n",
      "Wu weight shape: (100, 165, 64)\n",
      "Wy weight shape: (100, 165, 64)\n",
      "Wa weight shape: (100, 165, 64)\n",
      "Wv weight shape: (100, 165, 240)\n",
      "Beta shape: (100, 240)\n",
      "(100, 165)\n",
      "(100, 32) (100, 32)\n",
      "num of positive data in testing: 561.0\n",
      "(100, 32)\n",
      "\n",
      "==============================\n",
      "\n",
      "Top 1\n",
      "prec: 0.12\n",
      "recall: 0.0213903743315508\n",
      "F1_score: 0.036308623298033284\n",
      "*****\n",
      "Top 5\n",
      "prec: 0.396\n",
      "recall: 0.35294117647058826\n",
      "F1_score: 0.3732327992459944\n",
      "*****\n",
      "\n",
      "==============================\n",
      "\n",
      "NDCG@ 5\n",
      "NDCG score: 0.3365915507219186\n",
      "*****\n",
      "NDCG@ 10\n",
      "NDCG score: 0.4340258567194812\n",
      "*****\n",
      "\n",
      "==============================\n",
      "\n",
      "MAP: 0.20303628650314753\n",
      "\n",
      "==============================\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(SAVE_NAME)\n",
    "\n",
    "params = np.load(SAVE_FILE)\n",
    "\n",
    "U = params['U']\n",
    "Y = params['Y']\n",
    "A = params['A']\n",
    "E = params['E']\n",
    "Au = params['Wu']\n",
    "Ay = params['Wy']\n",
    "Aa = params['Wa']\n",
    "Av = params['Wv']\n",
    "B = params['B']\n",
    "\n",
    "print('User latent shape: ',U.shape)\n",
    "print('photo latent shape: ', Y.shape)\n",
    "print('Auxilary latent shape: ',A.shape)\n",
    "print('Embedding shape:', E.shape)\n",
    "print('Wu weight shape:', Au.shape)\n",
    "print('Wy weight shape:', Ay.shape)\n",
    "print('Wa weight shape:', Aa.shape)\n",
    "print('Wv weight shape:', Av.shape)\n",
    "print('Beta shape:',B.shape)\n",
    "\n",
    "testing(U, Y, A, E, Au, Ay, Aa, Av, B)\n",
    "print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
