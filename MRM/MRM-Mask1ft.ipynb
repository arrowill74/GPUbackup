{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "def writeProgress(msg, count, total):\n",
    "    sys.stdout.write(msg + \"{:.2%}\\r\".format(count/total))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_ls = os.listdir('./npy/mask1ft/')\n",
    "ft_ls = ['mask_image.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFt(PATH):\n",
    "    return np.load(PATH)\n",
    "\n",
    "# Normalize usr_genre\n",
    "def ugNorm(usr_genre):\n",
    "    usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "    for i in range(len(usr_genre)):\n",
    "        usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "    print(usr_genre_norm.shape)\n",
    "    return usr_genre_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(usr_following):\n",
    "    #The number of following movie for each user\n",
    "    each_user = np.sum(usr_following, axis=1)\n",
    "    # print(each_user)\n",
    "\n",
    "    print('Min number of followings:', np.min(each_user))\n",
    "    print('Max number of followings:', np.max(each_user))\n",
    "    print('Avg of followers:', np.mean(each_user))\n",
    "\n",
    "    asc = np.sort(each_user)\n",
    "    # print(each_user)\n",
    "    # print(asc)\n",
    "    desc = np.flip(asc)\n",
    "    # print(desc)\n",
    "    \n",
    "    print('Over 10:', np.sum(each_user >= 10))\n",
    "    print('Over 12:', np.sum(each_user >= 12))\n",
    "    print('Over 14:', np.sum(each_user >= 14))\n",
    "    print('Over 16:', np.sum(each_user >= 16))\n",
    "    print('Over 18:', np.sum(each_user >= 18))\n",
    "    print('Over 20:', np.sum(each_user >= 20))\n",
    "    \n",
    "    usr_idx = [i for i in range(len(usr_following))]\n",
    "    print(len(usr_idx))\n",
    "\n",
    "    random.seed(42)\n",
    "    test_idx = sorted(random.sample(usr_idx, usr_test_amount))\n",
    "    print(len(test_idx), test_idx[:10]) # 150 [13, 51, 54, 61, 65, 88, 93, 96, 114, 130]\n",
    "\n",
    "    # init\n",
    "    train_t = []\n",
    "    train_f = []\n",
    "    test_t = []\n",
    "    test_f = []\n",
    "\n",
    "    for i in range(usr_nb):\n",
    "        # init\n",
    "        t_for_train = []\n",
    "        f_for_train = []\n",
    "        t_for_test = []\n",
    "        f_for_test = []\n",
    "\n",
    "        if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "            for j in range(movie_nb):\n",
    "                if usr_following[i][j] == 1:\n",
    "                    t_for_train.append(j)\n",
    "                else:\n",
    "                    f_for_train.append(j)\n",
    "\n",
    "            train_t.append(t_for_train)\n",
    "            train_f.append(f_for_train)\n",
    "    #         print(len(t_for_train) + len(f_for_train))\n",
    "\n",
    "        else: #if in test id, choose half of true and other \n",
    "            temp_t = []\n",
    "            temp_f = []\n",
    "\n",
    "            for j in range(movie_nb):\n",
    "                if usr_following[i][j] == 1:\n",
    "                    temp_t.append(j)\n",
    "                else:\n",
    "                    temp_f.append(j)\n",
    "\n",
    "            # random choose half true and half false for test \n",
    "            t_for_test = random.sample(temp_t, math.ceil(0.5*len(temp_t)))\n",
    "            f_for_test  = random.sample(temp_f, movie_test_amount-len(t_for_test))\n",
    "\n",
    "            test_t.append(t_for_test)\n",
    "            test_f.append(f_for_test)\n",
    "\n",
    "            #the others for training\n",
    "            t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "            f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "            train_t.append(t_for_train)\n",
    "            train_f.append(f_for_train)\n",
    "\n",
    "        if not (len(t_for_train) + len(f_for_train) + len(t_for_test) + len(f_for_test)) == movie_nb:\n",
    "            print('Error!!!')\n",
    "            break\n",
    "    \n",
    "    return train_t, train_f, test_t, test_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie genre: (165, 20)\n",
      "User following: (1582, 165)\n",
      "User genre: (1582, 20)\n",
      "1582 165\n",
      "150 32\n",
      "(1582, 20)\n",
      "Min number of followings: 10\n",
      "Max number of followings: 133\n",
      "Avg of followers: 14.820480404551201\n",
      "Over 10: 1582\n",
      "Over 12: 937\n",
      "Over 14: 613\n",
      "Over 16: 440\n",
      "Over 18: 315\n",
      "Over 20: 229\n",
      "1582\n",
      "150 [13, 51, 54, 61, 65, 88, 93, 96, 114, 130]\n",
      "Training: 14.139064475347661\n",
      "Testing: 7.1866666666666665\n"
     ]
    }
   ],
   "source": [
    "# Basic setup\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)\n",
    "\n",
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "print(usr_nb, movie_nb)\n",
    "\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 32\n",
    "print(usr_test_amount, movie_test_amount)\n",
    "\n",
    "usr_genre_norm = ugNorm(usr_genre)\n",
    "train_t, train_f, test_t, test_f = train_test_split(usr_following)\n",
    "\n",
    "# Stat\n",
    "#average num of following for training user\n",
    "total_train = 0\n",
    "for t in train_t:\n",
    "    total_train += len(t)\n",
    "avg = total_train / usr_nb\n",
    "print('Training:', avg)\n",
    "\n",
    "#average num of following for testing user\n",
    "total_test = 0\n",
    "for t in test_t:\n",
    "    total_test += len(t)\n",
    "avg = total_test / usr_test_amount\n",
    "print('Testing:', avg)\n",
    "\n",
    "all_auxilary = [i for i in range(movie_nb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(SAVE_NAME):\n",
    "    print('==================================================')\n",
    "    print(SAVE_NAME)\n",
    "    print('Start time:', time.ctime())\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    loss_acc_list = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_yes_id=[]\n",
    "\n",
    "    for q in range(6):\n",
    "        print('Epoch:',q)\n",
    "        train_auc = 0\n",
    "        total_loss = 0\n",
    "        xuij_auc = 0\n",
    "        length = 0\n",
    "\n",
    "        for z in range(usr_nb):\n",
    "            writeProgress('Progress:', z, usr_nb)\n",
    "            \"\"\"\n",
    "            yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "            yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "            r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "            \"\"\"\n",
    "            yes = []\n",
    "            yesr = []\n",
    "\n",
    "    #         #選全部的Positive\n",
    "    #         sample = random.sample(train_t[z],len(train_t[z]))\n",
    "            #選全部的電影\n",
    "            sample = all_auxilary\n",
    "\n",
    "            #change\n",
    "            r_3 = np.zeros(len(sample))\n",
    "\n",
    "            for b in range(len(sample)):\n",
    "                yes.append(all_npy[sample[b]])\n",
    "                yesr.append(movie_genre[sample[b]] * usr_genre_norm[z])\n",
    "\n",
    "            for b in range(len(yesr)):\n",
    "                r_3[b]=max(yesr[b])\n",
    "            #print('r_3:',r_3)\n",
    "\n",
    "            yes = np.array(yes)\n",
    "\n",
    "            # positive sample\n",
    "            train_t_sample = train_t[z]\n",
    "            for ta in train_t_sample:\n",
    "                #print(ta,'--> positive feedback')\n",
    "\n",
    "                pos = sample.index(ta)\n",
    "\n",
    "                image_1=np.expand_dims(all_npy[ta],0)\n",
    "                train_f_sample = random.sample(train_f[z],10)\n",
    "\n",
    "                for b in train_f_sample:\n",
    "                    image_2 = np.expand_dims(all_npy[b],0)\n",
    "\n",
    "                    _last_be_relu, _norm_par, _a_list, r3, _auc, _loss, _ = sess.run(\n",
    "                        [last_be_relu, norm_par, a_list_smooth, a_list_soft, auc, loss, train_op], \n",
    "                        feed_dict={user: [z], i: [ta], j: [b], xf: yes, \n",
    "                                   l_id:sample, l_id_len:[len(sample)],\n",
    "                                   positive_id: train_t[z], positive_len:[len(train_t[z])],\n",
    "                                   r: r_3, image_i: image_1, image_j: image_2})\n",
    "\n",
    "                    '''Observe all params\n",
    "                    print('u,vi,vj',_norm_par[:3])\n",
    "                    print('w1,wu,wy,wa,wv',_norm_par[3:7])\n",
    "                    print('beta',_norm_par[7])\n",
    "                    print('Embedding',_norm_par[8])\n",
    "                    print('after softmax:', r3)\n",
    "                    print('before softmax:', _a_list)\n",
    "                    print('---------------------------------------------------')\n",
    "                    '''\n",
    "                    train_auc += _auc\n",
    "                    total_loss += _loss\n",
    "                    length += 1\n",
    "\n",
    "        print(\"{:<20}{}\".format('total_loss', total_loss/length))\n",
    "        print(\"{:<20}{}\".format('train_auc:', train_auc/length))\n",
    "\n",
    "        loss_acc_list.append([total_loss/length, train_auc/length])\n",
    "\n",
    "        print('\\tCurrent time:', time.ctime(), ' sec')\n",
    "        print('==================================================')\n",
    "\n",
    "    print('Total cost time:',time.time()-t0, ' sec')\n",
    "\n",
    "    print('End time:', time.ctime())\n",
    "    \n",
    "    U, Y, A, E, Au, Ay, Aa, Av, B = sess.run([user_latent, item_latent, aux_item, embedding, Wu, Wy, Wa, Wv, Beta])\n",
    "    np.savez('./weight/mask1ft/' + SAVE_NAME + '.npz',\n",
    "             U=U, Y=Y, A=A, E=E, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av, B=B)\n",
    "    \n",
    "    return loss_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_image.npy\n",
      "All features: (165, 324)\n",
      "64 324 240\n",
      "SAVE_NAME: mask_image\n",
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-9-b342a57302bf>:153: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "==================================================\n",
      "mask_image\n",
      "Start time: Wed Apr 22 11:11:24 2020\n",
      "Epoch: 0\n",
      "total_loss          [[0.62195778]]\n",
      "train_auc:          0.6961283977110158\n",
      "\tCurrent time: Wed Apr 22 14:34:53 2020  sec\n",
      "==================================================\n",
      "Epoch: 1\n",
      "total_loss          [[0.55399318]]\n",
      "train_auc:          0.7380588340486409\n",
      "\tCurrent time: Wed Apr 22 17:58:00 2020  sec\n",
      "==================================================\n",
      "Epoch: 2\n",
      "total_loss          [[0.52576864]]\n",
      "train_auc:          0.7611722103004291\n",
      "\tCurrent time: Wed Apr 22 21:21:22 2020  sec\n",
      "==================================================\n",
      "Epoch: 3\n",
      "total_loss          [[0.50280276]]\n",
      "train_auc:          0.7791711373390557\n",
      "\tCurrent time: Thu Apr 23 00:45:45 2020  sec\n",
      "==================================================\n",
      "Epoch: 4\n",
      "total_loss          [[0.48357154]]\n",
      "train_auc:          0.7924043276108726\n",
      "\tCurrent time: Thu Apr 23 04:09:46 2020  sec\n",
      "==================================================\n",
      "Epoch: 5\n",
      "total_loss          [[0.47013926]]\n",
      "train_auc:          0.8032725321888412\n",
      "\tCurrent time: Thu Apr 23 07:34:13 2020  sec\n",
      "==================================================\n",
      "Total cost time: 73366.91588139534  sec\n",
      "End time: Thu Apr 23 07:34:13 2020\n",
      "Epoch: range(1, 7)\n",
      "Loss: [0.6219577772934549, 0.5539931836216917, 0.5257686413067776, 0.5028027623167024, 0.4835715363465665, 0.4701392614449213]\n",
      "Acc: [0.6961283977110158, 0.7380588340486409, 0.7611722103004291, 0.7791711373390557, 0.7924043276108726, 0.8032725321888412]\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZhU1bX+8e9iElAQRIwGFHDERgShQLl440+NCjcSJxIBJzQK3ghRIwoKccAhDlcNGmJAwQERRHDAJIIITigKDYLIKEGFVqLMigza9Pr9sQsp26a7aKr71PB+nqef9KlzqmpVG97evc86+5i7IyIi2atK1AWIiEjFUtCLiGQ5Bb2ISJZT0IuIZDkFvYhIllPQi4hkOQW9ZAQzq2pmm8zskFQeK5ILTH30UhHMbFPCZm1gG7A9vt3b3UdXflUiuUlBLxXOzD4FLnf310o5ppq7F1ZeVZlJPycpD03dSCTM7A4ze9bMxpjZN8CFZtbBzN4zsw1mtsrMHjKz6vHjq5mZm1nT+PbT8f2vmNk3ZjbDzJrt7rHx/Z3NbKmZbTSzh83sHTPruYu6d1ljfH9LM3vNzNaZ2X/M7IaEmv5kZv82s6/NLN/Mfm5mh5uZF3uP6Tve38wuN7O34u+zDhhkZkeY2evx91hjZqPMbN+E5zcxsxfNbHV8/xAzqxmv+eiE4w4ys81m1qD8/yUlEyjoJUrnAM8A+wLPAoXA1cD+QEegE9C7lOf3AP4E7AesAG7f3WPN7ABgHHB9/H0/AdqX8jq7rDEetq8BLwMHAUcCb8Sfdz3QNX58PeByYGsp75Pov4BFQEPgHsCAO4ADgTzg0Phnw8yqAf8ElgFNgYOBce6+Nf45Lyz2M5ns7muTrEMylIJeojTd3V929yJ33+Lus9z9fXcvdPflwHDgpFKeP97d8939e2A00Locx54JzHX3l+L7HgTW7OpFyqjx18AKdx/i7tvc/Wt3nxnfdzlwk7t/HP+8c919Xek/nh+scPdH3H17/Oe01N2nuvt37v5VvOYdNXQg/BLq7+7fxo9/J77vSaCHmVl8+yJgVJI1SAarFnUBktNWJm6YWXPgfqAt4QRuNeD9Up7/n4TvNwP7lOPYnyfW4e5uZgW7epEyajwY+PcunlravrIU/zkdCDxE+IuiDmHAtjrhfT519+0U4+7vmFkhcKKZrQcOIYz+JctpRC9RKt4JMAz4CDjc3esCNxOmKSrSKqDxjo34aLdRKceXVuNK4LBdPG9X+76Nv2/thMcOLHZM8Z/TPYQuppbxGnoWq6GJmVXdRR1PEaZvLiJM6WzbxXGSRRT0kk7qABuBb+MnDUubn0+VfwBtzKxLfH77asJceHlqnAgcYmZ9zGwvM6trZjvm+x8D7jCzwyxobWb7Ef7S+A/hZHRVM+sFNCmj5jqEXxAbzexgoF/CvhnAWuAuM6ttZrXMrGPC/lGEcwU9CKEvOUBBL+nkOuAS4BvCyPnZin5Dd/8SOB94gBCQhwEfEEbMu1Wju28ETgPOA74ElrJz7vw+4EVgKvA1YW6/pof+5iuAmwjnBg6n9OkqgFsIJ4w3En65TEiooZBw3uFowuh+BSHYd+z/FJgPbHP3d8t4H8kS6qMXSRCf8vgC6Orub0ddT0Uws6eA5e5+a9S1SOXQyVjJeWbWCXgP2ALcCHwPzCz1SRnKzA4FzgJaRl2LVB5N3YjAicByQufKGcA52XiS0sz+DMwD7nL3FVHXI5VHUzciIllOI3oRkSyXdnP0+++/vzdt2jTqMkREMsrs2bPXuHuJrcFpF/RNmzYlPz8/6jJERDKKmX22q32auhERyXIKehGRLKegFxHJcmk3R1+S77//noKCArZuTXb5bkm1mjVr0rhxY6pXr172wSKSVjIi6AsKCqhTpw5NmzZl51LaUlncnbVr11JQUECzZs3KfoKIpJWMmLrZunUrDRo0UMhHxMxo0KCB/qISyVAZEfSAQj5i+vmLZK6MmLoREclm69fDSy/Bd99Br16pf/2MGdFHae3atbRu3ZrWrVtz4IEH0qhRox+2v/vuu6Re49JLL2XJkiWlHjN06FBGjx6dipJFJM2tXQsjRkDnznDAAXDppfD44xXzXhrRJ6FBgwbMnTsXgFtvvZV99tmHfv36/egYd8fdqVKl5N+djyfxX/Cqq67a82JFJG2tXg0vvADjx8O0abB9OzRrBtdeC7/5DcRiFfO+GtHvgWXLlpGXl8cFF1xAixYtWLVqFb169SIWi9GiRQsGDx78w7Ennngic+fOpbCwkHr16jFgwABatWpFhw4d+OqrrwAYNGgQf/nLX344fsCAAbRv356jjjqKd98NNwP69ttvOe+888jLy6Nr167EYrEffgkluuWWW2jXrh3HHHMMV155JTtWKV26dCmnnHIKrVq1ok2bNnz66acA3HXXXbRs2ZJWrVoxcODAivyxieSUL7+ERx6BU0+FAw+E3r3hk0/g+uth9mz497/h3nuhXTuoqFNhSY3o4zdmGAJUBR5z97uL7T8EeBKoFz9mgLv/K77vRuB3wHbgD+4+eU8KvuYaKCHX9kjr1hDP1922ePFinnrqKWLxX8V33303++23H4WFhZx88sl07dqVvLy8Hz1n48aNnHTSSdx999388Y9/ZOTIkQwYMOAnr+3uzJw5k4kTJzJ48GAmTZrEww8/zIEHHsiECROYN28ebdq0KbGuq6++mttuuw13p0ePHkyaNInOnTvTvXt3br31Vrp06cLWrVspKiri5Zdf5pVXXmHmzJnUqlWLdevWle+HISIAfPEFPP98GLm/9Ra4w1FHwU03QdeucOyxFRfqJSkz6OO3VhtKuBdmATDLzCa6+8KEwwYR7ij/iJnlAf8Cmsa/7wa0AH4OvGZmR7r79lR/kKgcdthhP4Q8wJgxYxgxYgSFhYV88cUXLFy48CdBX6tWLTp37gxA27Ztefvtku9Yd+655/5wzI6R9/Tp0+nfvz8ArVq1okWLFiU+d+rUqdx3331s3bqVNWvW0LZtW0444QTWrFlDly5dgHARFMBrr73GZZddRq1atQDYb7/9yvOjEMlpBQUwYUII93feCeGelwc33xzCvUWLyg33RMmM6NsDy9x9OYCZjSXciiwx6B2oG/9+X8I9N4kfNzZ+t55PzGxZ/PVmlLfg8o68K8ree+/9w/cff/wxQ4YMYebMmdSrV48LL7ywxN7zGjVq/PB91apVKSwsLPG199prrzKPKcnmzZvp06cPc+bMoVGjRgwaNEg98CIV4LPPdob7jHiqtWwJt94awr3YGC8yyczRNyLcTX6HgvhjiW4FLjSzAsJovu9uPBcz62Vm+WaWv3r16iRLTz9ff/01derUoW7duqxatYrJk/dolqpEHTt2ZNy4cQDMnz+fhQsX/uSYLVu2UKVKFfbff3+++eYbJkyYAED9+vVp2LAhL7/8MhAuRNu8eTOnnXYaI0eOZMuWLQCauhEpxSefwH33wfHHQ9OmcN11sGUL3HEHLF4MH34YRvHpEvKQuq6b7sAT7n6/mXUARpnZMck+2d2HA8MBYrFYxt7bsE2bNuTl5dG8eXOaNGlCx44dU/4effv25eKLLyYvL++Hr3333fdHxzRo0IBLLrmEvLw8DjroII4//vgf9o0ePZrevXszcOBAatSowYQJEzjzzDOZN28esViM6tWr06VLF26//faU1y6SqZYtC6P28ePDCVSAtm3h7rvhvPPg8MOjra8sZd4zNh7ct7r7GfHtGwHc/c8JxywAOrn7yvj2cuAEwknYH441s8nx19rl1E0sFvPiNx5ZtGgRRx999G5/uGxUWFhIYWEhNWvW5OOPP+b000/n448/plq1iu+U1X8HySVLluwM9x0NIO3bhzbI884LbZHpxMxmu3uJDZrJpMMs4AgzawZ8Tji52qPYMSuAU4EnzOxooCawGpgIPGNmDxBOxh4BzCzXpxAANm3axKmnnkphYSHuzrBhwyol5EVywcKFO8N9/vzwWIcO8MADcO650KRJtPWVV5kJ4e6FZtYHmExonRzp7gvMbDCQ7+4TgeuAR83sWsKJ2Z4e/lRYYGbjCCduC4GrsqnjJgr16tVj9o6/HUVkj7jDRx+FYH/uOVi0KHTGdOwIQ4aEcG/cOOoq91xSQ8F4T/y/ij12c8L3C4ESJ6Td/U7gzj2occfraGGtCJU1xSeSKdxh3rydI/clS6BKFfjFL+Cqq+Ccc+DnP4+6ytTKiL/5a9asydq1a7VUcUR2rEe/o+9eJNO4w5w5O8N92bIQ7iefHC7CPOcc+NnPoq6y4mRE0Ddu3JiCggIyufUy0+24w5RIpnCHWbN2hvsnn0DVqmEpghtugLPPhoYNo66ycmRE0FevXl13NhKRMhUVwfvv7wz3FSugWjX45S9h0CA46yxo0CDqKitfRgS9iMiuFBXBu++GYJ8wISxFUL06nH46DB4Mv/411K8fdZXRUtCLSMbZvh2mT98Z7qtWwV57QadO8Oc/Q5cuUOw6wpymoBeRjFBYGFaCHD8+rAz55ZdQsyb8z/+EdWV+9SuoW7fs18lFCnoRSVvffw9vvBHC/YUXwo07atcOod61awj5ffaJusr0p6AXkbTiDm++CU8/DS++GG65t/feYTqma9cwPZOwaKwkQUEvImlhzRp48kkYPhyWLoU6dcKJ1K5d4YwzIH67BCkHBb2IRMY9zLsPGxZOqn73XVh+YODAsHiYwj01FPQiUunWrt05el+yJHTI9O4NvXrBMUkvcC7JUtCLSKVwh7ffDqP38ePD6L1DB3jiiTB6r1076gqzl4JeRCrUunU7R++LF4fRe69e4atly6iryw0KehFJOfdwQdPw4WH5323b4IQTYORIOP98jd4rm4JeRFJm3ToYNSoE/MKF4QKmyy+HK66AVq2iri53KehFZI+4h7Vmhg0Lo/etW8ONs0eMCKN39bxHT0EvIuWyfv3O0fuCBaHv/dJLw9x769ZRVyeJFPQikjR3mDEjjN7HjQuj93bt4LHHoFs3jd7TlYJeRMq0YcPO0ftHH4XRe8+eYfR+3HFRVydlUdCLSInc4b33Qrg/+yxs2QKxGDz6aBi9azGxzKGgF5Ef2bgxLCg2bBjMnx8C/eKLw+i9TZuoq5PyUNCLCO4wc2YI97Fjw+i9TZuw3b17mKqRzKWgF8lhGzfC6NEh0D/8MJxMvfDCsO5M27ZRVyepoqAXyTHuMGvWztH75s3hhOrf/w49emj0no0U9CI54uuvw+h9+HCYOzeM3nv02Dl6N4u6QqkoCnqRLOYO+fkh3MeMgW+/DRczPfJICHndYzU3KOhFstA338Azz4TpmQ8+CIuIde8eOmfatdPoPdco6EWyyOzZIdyfeSaM3o89FoYOhQsuCMsDS25KKujNrBMwBKgKPObudxfb/yBwcnyzNnCAu9eL77sX+BVQBZgCXO3unpryReSbb8K0zLBhMGdOuP1et25h7r19e43eJYmgN7OqwFDgNKAAmGVmE9194Y5j3P3ahOP7AsfFv/8voCNwbHz3dOAk4I0U1S+Ss+bM2Tl637Qp3MTjr38N7ZEavUuiZEb07YFl7r4cwMzGAmcBC3dxfHfglvj3DtQEagAGVAe+3JOCRXLZpk1h9D58eDjJWqtWWAq4d++wNLBG71KSZIK+EbAyYbsAOL6kA82sCdAMmAbg7jPM7HVgFSHo/+rui0p4Xi+gF8AhhxyyO/WL5IQPPgjhPnp0mKo55hh4+OEweq9XL+rqJN2l+mRsN2C8u28HMLPDgaOBxvH9U8zsv9397cQnuftwYDhALBbT/L1I3Lx50L8/TJ4MNWvuHL2fcIJG75K8Kkkc8zlwcMJ24/hjJekGjEnYPgd4z903ufsm4BWgQ3kKFcklK1bAJZeEK1ZnzoR774UvvoAnnoAOHRTysnuSCfpZwBFm1szMahDCfGLxg8ysOVAfmJHw8ArgJDOrZmbVCSdifzJ1IyLB+vVwww1w5JFhaeAbboDly+H666F+/airk0xV5tSNuxeaWR9gMqG9cqS7LzCzwUC+u+8I/W7A2GKtk+OBU4D5hBOzk9z95ZR+ApEssHVr6He/885wk4+LL4bBg0GnrCQVLN1a2mOxmOfn50ddhkilKCoKXTQDB8Jnn0GnTnDPPeFCJ5HdYWaz3T1W0r5kpm5EpAK89lq4Y9OFF8J++8GUKfDKKwp5ST0FvUglmzcvjNxPOy3MyY8eHXrif/nLqCuTbKWgF6kkxTtpHngAFi8Oq0hW0b9EqUBa1Eykgq1fD3/+Mzz0UNi+/noYMEBdNFJ5FPQiFWTbttBJc8cd6qSRaOkPRpEUKyoK8+5HHQXXXRfWoPngg3Cxk0JeoqCgF0mhXXXStGoVdWWSyxT0IimQ2Emzbp06aSS9KOhF9kDxTpr774clS9RJI+lFJ2NFymH9erj7bhgyJGyrk0bSmYJeZDeok0Yykf64FEnCjk6a5s1DJ0379uqkkcyhoBcpw9SpOztp6tcPnTSTJqmTRjKHgl5kF3Z00vzyl6GT5umn1UkjmUlBL1JMSZ00ixfDBReok0Yyk07GisRt2BDWpFEnjWQbBb3kvOKdNBddBLffrpOskj30h6jkrF110jz5pEJesouCXnKSOmkklyjoJad8+CF07qxOGsktCnrJCStWQM+e0Lo1vP++Omkkt+hkrGS14p00/frBjTeqk0Zyi4JestKOTpo77wwLkKmTRnKZ/miVrFJUBM88s7OTpl07ddKIKOgla0ydGoL9ggugXj149VV10oiAgl6yQGInzdq1oZNm9uxwtycRUdBLBlu58sedNP/3f+qkESmJTsZKxlEnjcjuSWrcY2adzGyJmS0zswEl7H/QzObGv5aa2YaEfYeY2atmtsjMFppZ09SVL7nEHUaNgsMOg/vug/PPh6VL4d57FfIipSlzRG9mVYGhwGlAATDLzCa6+8Idx7j7tQnH9wWOS3iJp4A73X2Kme0DFKWqeMkd69bBlVfCc89Bx47w17+GKRsRKVsyI/r2wDJ3X+7u3wFjgbNKOb47MAbAzPKAau4+BcDdN7n75j2sWXLMa69By5bw4othyubNNxXyIrsjmaBvBKxM2C6IP/YTZtYEaAZMiz90JLDBzJ43sw/M7L74XwjFn9fLzPLNLH/16tW79wkka23ZAtdcE7pn9t0X3nsvrA9f9Sf/DxKR0qS6N6EbMN7dt8e3qwH/DfQD2gGHAj2LP8ndh7t7zN1jDRs2THFJkonmzg2rSw4ZAn37hnbJNm2irkokMyUT9J8DBydsN44/VpJuxKdt4gqAufFpn0LgRUD/XGWXtm8PJ1fbtw9LF0yaBA89BLVqRV2ZSOZKJuhnAUeYWTMzq0EI84nFDzKz5kB9YEax59Yzsx3D9FOAhcWfKwLw2WdwyinQvz906QLz58MZZ0RdlUjmKzPo4yPxPsBkYBEwzt0XmNlgM/t1wqHdgLHu7gnP3U6YtplqZvMBAx5N5QeQzOcermY99tiwLs3jj8P48dCgQdSViWQHS8jltBCLxTw/Pz/qMqSSrFsH//u/MG5caJscNQqaNYu6KpHMY2az3T1W0j5dKC6Ree21MIp//vmwnPCbbyrkRSqCgl4q3dat8Mc/hrbJOnVC2+RNN6ltUqSiaK0bqVTz5oUbcn/0EVx1VeiwqV076qpEsptG9FIpiorC6pLt28OaNfDKK2EZA4W8SMXTiF4q3IoVcMkl8MYbcM45MHw47L9/1FWJ5A6N6KVCPfNMOOGanw8jR8KECQp5kcqmoJcKsX49dO8ebgLSokWYm7/0UjCLujKR3KOgl5SbNi2M4sePhzvuCG2Thx4adVUiuUtBLymzdStcdx2ceirsvTfMmAEDB0I1nQkSiZT+CUpKfPhhaJucPx9+//twByh11IikB43oZY8UFcH990O7dvDVV/DPf8LQoQp5kXSiEb2U28qVoW3y9dfh7LND26RuJyCSfjSil3IZMybc3m/WLBgxIqxXo5AXSU8Ketkt69dDjx7hKy8v3AnqssvUNimSzhT0krTXXw9tk+PGwe23w1tvwWGHRV2ViJRFQS9l2rYN+vULbZO1a4e2yUGD1DYpkin0T1VKNX9+uLp1/vxwg5D77gs98iKSOTSilxIVFcEDD0AsBl9+Cf/4B/ztbwp5kUykEb38xMqV0LNnWMrgrLPg0UfVUSOSyTSilx8ZOzaccH3/fXjsMXjhBYW8SKZT0AsAGzaEufju3aF589A2+bvfqW1SJBso6IU33gij+Gefhdtug7ffhsMPj7oqEUkVBX0O27YNrr8eTjkFataEd9+Fm29W26RIttE/6Rz10UdhqubDD6F377AwmTpqRLKTRvQ5pqgIHnwwtE3+5z/w8svw978r5EWymUb0OaSgILRNTp0KXbqErpoDDoi6KhGpaBrR54hx48JqkzNmhOWEX3pJIS+SKxT0WW7jRrjoIjj/fDjqqNA2ecUVapsUySVJBb2ZdTKzJWa2zMwGlLD/QTObG/9aamYbiu2va2YFZvbXVBUuZXvzzdA2OWYM3HorTJ8ORxwRdVUiUtnKnKM3s6rAUOA0oACYZWYT3X3hjmPc/dqE4/sCxxV7mduBt1JSsZRp27bQJnnffWEZ4XfegeOPj7oqEYlKMiP69sAyd1/u7t8BY4GzSjm+OzBmx4aZtQV+Bry6J4VKchYsCKF+771hiuaDDxTyIrkumaBvBKxM2C6IP/YTZtYEaAZMi29XAe4H+pX2BmbWy8zyzSx/9erVydQtxRQVwZAh0LYtfPEFTJwIw4bBPvtEXZmIRC3VJ2O7AePdfXt8+/fAv9y9oLQnuftwd4+5e6yhVtDabZ9/DmecAddcA6edFtaO79Il6qpEJF0k00f/OXBwwnbj+GMl6QZclbDdAfhvM/s9sA9Qw8w2uftPTuhK+Tz3XLiyddu2MIJXR42IFJdM0M8CjjCzZoSA7wb0KH6QmTUH6gMzdjzm7hck7O8JxBTyqfPkk+ECqPbtYdQoOPLIqCsSkXRUZtC7e6GZ9QEmA1WBke6+wMwGA/nuPjF+aDdgrLt7xZUrO8yZA1deCSefDJMnQ/XqUVckIunK0i2XY7GY5+fnR11GWlu7Npx03b4dZs/WFa4iAmY2291jJe3TWjcZZvt26NEDVq0K68Yr5EWkLAr6DHPLLfDqq2G9mvbto65GRDKB1rrJIC+9BHfeCZdfHrprRESSoaDPEEuWhMXJYjF4+OGoqxGRTKKgzwCbNsG558Jee8GECeG2fyIiydIcfZpzh8sug8WLYcoUOOSQqCsSkUyjoE9z998frn69995wE28Rkd2lqZs0Nm0a9O8PXbtCv1KXhRMR2TUFfZpauXLnXaFGjtT6NSJSfgr6NLRtWxjFb9sGzz8PdepEXZGIZDLN0aehP/wBZs4MId+8edTViEim04g+zYwYEa56vfFGOOecqKsRkWygoE8js2bBVVeFm4fcfnvU1YhItlDQp4nVq+G88+DAA+GZZ6Bq1agrEpFsoTn6NFBYCN27w1dfwbvvwv77R12RiGQTBX0aGDgQpk6Fxx+HNm2irkZEso2mbiI2YUK46vXKK8NtAUVEUk1BH6FFi0K4n3AC/OUvUVcjItlKQR+Rr78O7ZO1a8P48WFlShGRiqA5+gi4h5H8smVhbr5Ro6grEpFspqCPwD33wAsvwAMPwEknRV2NiGQ7Td1UsilTQpfN+efDNddEXY2I5AIFfSX67LPQL5+XF5Y60IqUIlIZFPSVZMuWcDvA778Pi5XtvXfUFYlIrtAcfSVwD2vYzJkDEyfCEUdEXZGI5BKN6CvB8OHhqtc//Qm6dIm6GhHJNQr6Cvbee9C3L3TuDLfcEnU1IpKLFPQV6Msvw52iGjeGp5/WipQiEo2kgt7MOpnZEjNbZmYDStj/oJnNjX8tNbMN8cdbm9kMM1tgZh+a2fmp/gDpqrAwtFCuWxd65vfbL+qKRCRXlXky1syqAkOB04ACYJaZTXT3hTuOcfdrE47vCxwX39wMXOzuH5vZz4HZZjbZ3Tek8kOko/794c03YdQoaNUq6mpEJJclM6JvDyxz9+Xu/h0wFjirlOO7A2MA3H2pu38c//4L4Cug4Z6VnP7Gjg1XvfbpAxdeGHU1IpLrkgn6RsDKhO2C+GM/YWZNgGbAtBL2tQdqAP8uYV8vM8s3s/zVq1cnU3fa+ugj+N3voGNHuP/+qKsREUn9ydhuwHh33574oJkdBIwCLnX3ouJPcvfh7h5z91jDhpk74N+wIVwUVbcuPPcc1KgRdUUiIsldMPU5cHDCduP4YyXpBlyV+ICZ1QX+CQx09/fKU2QmKCqCiy+GTz6B11+Hgw6KuiIRkSCZEf0s4Agza2ZmNQhhPrH4QWbWHKgPzEh4rAbwAvCUu49PTcnp6a674OWXw9z8iSdGXY2IyE5lBr27FwJ9gMnAImCcuy8ws8Fm9uuEQ7sBY93dEx77LfALoGdC+2XrFNafFl55BW6+OZx47dMn6mpERH7MfpzL0YvFYp6fnx91GUlbvhxiMTjkEHj33XDHKBGRymZms909VtI+XRm7BzZvDidf3cOKlAp5EUlHWr2ynNzhyivhww/hn/+EQw+NuiIRkZIp6Mtp6NBw1ettt4UFy0RE0pWmbsrhnXfg2mvhzDNh0KCoqxERKZ2CfjetWgW/+Q00bRpG9FX0ExSRNKepm93w/ffw29/Cxo0weTLUqxd1RSIiZVPQ74Z+/WD6dBgzBlq2jLoaEZHkaOIhSU8/DQ89FObmu3WLuhoRkeQp6JMwbx706gW/+AXcc0/U1YiI7B4FfRnWrw8XRdWvD+PGQfXqUVckIrJ7NEdfiqIiuOACWLkS3noLfvazqCsSEdl9CvpS3HZbWLDskUfghBOirkZEpHw0dbML//gHDB4MPXtC795RVyMiUn4K+hIsWxaWHG7TBv72NzCLuiIRkfJT0Bfz7bdwzjlQtSpMmAC1akVdkYjIntEcfQJ3uOIKWLAAJk0KyxyIiGQ6BX2CIUPCVa933QWnnx51NSIiqaGpm7g33wxLHJx9NgwYEHU1IiKpo6AHPv88LFZ22GHw5JM6+Soi2SXnp262bYOuXcNJ2Ndfh7p1o65IRBaFtLQAAAXuSURBVCS1cj7or70W3nsPnnsO8vKirkZEJPVyeurmiSfCVa/XXx9G9SIi2Shng37OnHBz71NOCV02IiLZKieDfu3asCLlAQfA2LFQLecnsEQkm+VcxG3fDt27h3u/Tp8ODRtGXZGISMXKuaC/+WaYMgUefRTatYu6GhGRipdTUzcvvhjm4y+/PHyJiOSCnAn6JUvg4ovDKP7hh6OuRkSk8iQV9GbWycyWmNkyM/vJAgFm9qCZzY1/LTWzDQn7LjGzj+Nfl6Sy+GR98004+brXXmFFypo1o6hCRCQaZc7Rm1lVYChwGlAAzDKzie6+cMcx7n5twvF9gePi3+8H3ALEAAdmx5+7PqWfohTucNllsHhxmJs/+ODKemcRkfSQzIi+PbDM3Ze7+3fAWOCsUo7vDoyJf38GMMXd18XDfQrQaU8K3l333w/jx8Pdd4eeeRGRXJNM0DcCViZsF8Qf+wkzawI0A6btznPNrJeZ5ZtZ/urVq5OpOynTpkH//uGq1379UvayIiIZJdUnY7sB4919++48yd2Hu3vM3WMNU9TYvnIlnH8+HHUUjBypFSlFJHclE/SfA4kz243jj5WkGzunbXb3uSmzdSucd15YmfKFF6BOnYp+RxGR9JVM0M8CjjCzZmZWgxDmE4sfZGbNgfrAjISHJwOnm1l9M6sPnB5/rEL94Q8waxY89VQY0YuI5LIyu27cvdDM+hACuiow0t0XmNlgIN/dd4R+N2Csu3vCc9eZ2e2EXxYAg919XWo/wo899li46vXGG8PdokREcp0l5HJaiMVinp+fX67nzpoFJ54IJ50Er7wCVaumuDgRkTRlZrPdPVbSvqy5Mnb16jAvf9BB4QbfCnkRkSBrgr5KFWjdGp5/Hho0iLoaEZH0kTWrVzZoABN/copYRESyZkQvIiIlU9CLiGQ5Bb2ISJZT0IuIZDkFvYhIllPQi4hkOQW9iEiWU9CLiGS5tFvrxsxWA5/twUvsD6xJUTmZItc+c659XtBnzhV78pmbuHuJN/RIu6DfU2aWv6uFfbJVrn3mXPu8oM+cKyrqM2vqRkQkyynoRUSyXDYG/fCoC4hArn3mXPu8oM+cKyrkM2fdHL2IiPxYNo7oRUQkgYJeRCTLZU3Qm9lIM/vKzD6KupbKYGYHm9nrZrbQzBaY2dVR11TRzKymmc00s3nxz3xb1DVVFjOramYfmNk/oq6lMpjZp2Y238zmmln5biKdYcysnpmNN7PFZrbIzDqk7LWzZY7ezH4BbAKecvdjoq6nopnZQcBB7j7HzOoAs4Gz3X1hxKVVGDMzYG9332Rm1YHpwNXu/l7EpVU4M/sjEAPquvuZUddT0czsUyDm7jlzwZSZPQm87e6PmVkNoLa7b0jFa2fNiN7d3wLWRV1HZXH3Ve4+J/79N8AioFG0VVUsDzbFN6vHv7JjpFIKM2sM/Ap4LOpapGKY2b7AL4ARAO7+XapCHrIo6HOZmTUFjgPej7aSihefwpgLfAVMcfes/8zAX4AbgKKoC6lEDrxqZrPNrFfUxVSCZsBq4PH4FN1jZrZ3ql5cQZ/hzGwfYAJwjbt/HXU9Fc3dt7t7a6Ax0N7MsnqazszOBL5y99lR11LJTnT3NkBn4Kr41Gw2qwa0AR5x9+OAb4EBqXpxBX0Gi89TTwBGu/vzUddTmeJ/1r4OdIq6lgrWEfh1fM56LHCKmT0dbUkVz90/j//vV8ALQPtoK6pwBUBBwl+o4wnBnxIK+gwVPzE5Aljk7g9EXU9lMLOGZlYv/n0t4DRgcbRVVSx3v9HdG7t7U6AbMM3dL4y4rAplZnvHGwyIT1+cDmR1N527/wdYaWZHxR86FUhZY0W1VL1Q1MxsDPD/gP3NrAC4xd1HRFtVheoIXATMj89ZA9zk7v+KsKaKdhDwpJlVJQxSxrl7TrQb5pifAS+EsQzVgGfcfVK0JVWKvsDoeMfNcuDSVL1w1rRXiohIyTR1IyKS5RT0IiJZTkEvIpLlFPQiIllOQS8ikuUU9CIiWU5BLyKS5f4/lwBU8n3xrg4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ft in ft_ls:\n",
    "    print(ft)\n",
    "    PATH = './npy/mask1ft/' + ft\n",
    "    all_npy = loadFt(PATH)\n",
    "    print('All features:', all_npy.shape)\n",
    "    \n",
    "    latent_dim = 64 # latent dims\n",
    "    ft_dim = all_npy.shape[1] # feature dims\n",
    "    embedding_dims = 240\n",
    "    print(latent_dim, ft_dim, embedding_dims)\n",
    "    \n",
    "    SAVE_NAME = ft.split('.')[0]\n",
    "    print('SAVE_NAME:', SAVE_NAME)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    user = tf.placeholder(tf.int32,shape=(1,))\n",
    "    i = tf.placeholder(tf.int32, shape=(1,))\n",
    "    j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "    #多少個auxliary \n",
    "    xf = tf.placeholder(tf.float32, shape=(None, ft_dim))\n",
    "    l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "    r = tf.placeholder(tf.float32,shape=(None,))\n",
    "    positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "\n",
    "    image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "    image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "    with tf.variable_scope(\"item_level\"):\n",
    "        user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "        item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=3)) \n",
    "        aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                                   initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "\n",
    "    #     W1 = tf.get_variable(\"W1\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wu = tf.get_variable(\"Wu\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wy = tf.get_variable(\"Wy\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wa = tf.get_variable(\"Wa\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wv = tf.get_variable(\"Wv\", [usr_nb, movie_nb, embedding_dims], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    #     Wve = tf.get_variable(\"Wve\", [embedding_dims, ft_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    with tf.variable_scope('feature_level'):\n",
    "        embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                               initializer=tf.random_normal_initializer(0.01, 0.001, seed=10))\n",
    "\n",
    "    #lookup the latent factors by user and id\n",
    "    u = tf.nn.embedding_lookup(user_latent, user)\n",
    "    vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "    vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "    # w1 = tf.nn.embedding_lookup(W1, user)\n",
    "    wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user))\n",
    "    wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user))\n",
    "    wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user))\n",
    "    wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user))\n",
    "\n",
    "    beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n",
    "    \n",
    "    a_list = tf.Variable([])\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def att_cond(q,a_list):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def att_body(q,a_list):\n",
    "        xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "        wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "\n",
    "        a_list = tf.concat([a_list,[(tf.nn.relu(tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                                tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(wvui, tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "        q += 1\n",
    "        return q, a_list\n",
    "\n",
    "    _, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "    a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "    a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "\n",
    "    norm_par = [wu,wy,wa,wv]\n",
    "\n",
    "    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "    wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "    wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "    wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "    wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "\n",
    "    last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "\n",
    "    aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def sum_att_cond(q,aux_np):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def sum_att_body(q,aux_np):\n",
    "        aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "        q += 1\n",
    "        return q, aux_np\n",
    "\n",
    "    _, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "    aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "    aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "    latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "    feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "    feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "    only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "    #矩陣中對應函數各自相乘\n",
    "    # ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "    xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "    xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "    l2_norm = tf.add_n([\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "                0.001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "\n",
    "                0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "                0.001 * tf.reduce_sum(tf.multiply(embedding,embedding))\n",
    "              ])\n",
    "\n",
    "    loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "    auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "    \n",
    "    loss_acc_list = training(SAVE_NAME)\n",
    "    \n",
    "    # training history\n",
    "    epochs = range(1, len(loss_acc_list) + 1)\n",
    "    print('Epoch:', epochs)\n",
    "    loss = [ls[0].tolist()[0][0] for ls in loss_acc_list]\n",
    "    print('Loss:', loss)\n",
    "    acc = [ls[1] for ls in loss_acc_list]\n",
    "    print('Acc:', acc)\n",
    "    print('==================================================')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.title('Training accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.title('Training loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#     print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_image.npy\n",
      "All features: (165, 324)\n",
      "64 324 240\n",
      "SAVE_NAME: mask_image\n",
      "==================================================\n",
      "mask_image\n",
      "Start time: Thu Apr 23 07:34:15 2020\n",
      "Epoch: 0\n",
      "total_loss          [[0.62396092]]\n",
      "train_auc:          0.69631169527897\n",
      "\tCurrent time: Thu Apr 23 10:58:51 2020  sec\n",
      "==================================================\n",
      "Epoch: 1\n",
      "total_loss          [[0.55038294]]\n",
      "train_auc:          0.7407546494992847\n",
      "\tCurrent time: Thu Apr 23 14:23:40 2020  sec\n",
      "==================================================\n",
      "Epoch: 2\n",
      "total_loss          [[0.5203637]]\n",
      "train_auc:          0.7653522889842632\n",
      "\tCurrent time: Thu Apr 23 17:48:09 2020  sec\n",
      "==================================================\n",
      "Epoch: 3\n",
      "Progress:36.03%\r"
     ]
    }
   ],
   "source": [
    "for ft in ft_ls:\n",
    "    print(ft)\n",
    "    PATH = './npy/mask1ft/' + ft\n",
    "    all_npy = loadFt(PATH)\n",
    "    print('All features:', all_npy.shape)\n",
    "    \n",
    "    latent_dim = 64 # latent dims\n",
    "    ft_dim = all_npy.shape[1] # feature dims\n",
    "    embedding_dims = 240\n",
    "    print(latent_dim, ft_dim, embedding_dims)\n",
    "    \n",
    "    SAVE_NAME = ft.split('.')[0]\n",
    "    print('SAVE_NAME:', SAVE_NAME)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    user = tf.placeholder(tf.int32,shape=(1,))\n",
    "    i = tf.placeholder(tf.int32, shape=(1,))\n",
    "    j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "    #多少個auxliary \n",
    "    xf = tf.placeholder(tf.float32, shape=(None, ft_dim))\n",
    "    l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "    r = tf.placeholder(tf.float32,shape=(None,))\n",
    "    positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "\n",
    "    image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "    image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "    with tf.variable_scope(\"item_level\"):\n",
    "        user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=42))\n",
    "        item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=43)) \n",
    "        aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                                   initializer=tf.random_normal_initializer(0,0.1,seed=44))\n",
    "\n",
    "    #     W1 = tf.get_variable(\"W1\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wu = tf.get_variable(\"Wu\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wy = tf.get_variable(\"Wy\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wa = tf.get_variable(\"Wa\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wv = tf.get_variable(\"Wv\", [usr_nb, movie_nb, embedding_dims], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    #     Wve = tf.get_variable(\"Wve\", [embedding_dims, ft_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    with tf.variable_scope('feature_level'):\n",
    "        embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                               initializer=tf.random_normal_initializer(0.01, 0.001, seed=10))\n",
    "\n",
    "    #lookup the latent factors by user and id\n",
    "    u = tf.nn.embedding_lookup(user_latent, user)\n",
    "    vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "    vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "    # w1 = tf.nn.embedding_lookup(W1, user)\n",
    "    wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user))\n",
    "    wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user))\n",
    "    wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user))\n",
    "    wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user))\n",
    "\n",
    "    beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n",
    "    \n",
    "    a_list = tf.Variable([])\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def att_cond(q,a_list):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def att_body(q,a_list):\n",
    "        xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "        wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "\n",
    "        a_list = tf.concat([a_list,[(tf.nn.relu(tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                                tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(wvui, tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "        q += 1\n",
    "        return q, a_list\n",
    "\n",
    "    _, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "    a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "    a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "\n",
    "    norm_par = [wu,wy,wa,wv]\n",
    "\n",
    "    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "    wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "    wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "    wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "    wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "\n",
    "    last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "\n",
    "    aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def sum_att_cond(q,aux_np):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def sum_att_body(q,aux_np):\n",
    "        aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "        q += 1\n",
    "        return q, aux_np\n",
    "\n",
    "    _, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "    aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "    aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "    latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "    feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "    feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "    only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "    #矩陣中對應函數各自相乘\n",
    "    # ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "    xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "    xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "    l2_norm = tf.add_n([\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "                0.001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "\n",
    "                0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "                0.001 * tf.reduce_sum(tf.multiply(embedding,embedding))\n",
    "              ])\n",
    "\n",
    "    loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "    auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "    \n",
    "    loss_acc_list = training(SAVE_NAME)\n",
    "    \n",
    "    # training history\n",
    "    epochs = range(1, len(loss_acc_list) + 1)\n",
    "    print('Epoch:', epochs)\n",
    "    loss = [ls[0].tolist()[0][0] for ls in loss_acc_list]\n",
    "    print('Loss:', loss)\n",
    "    acc = [ls[1] for ls in loss_acc_list]\n",
    "    print('Acc:', acc)\n",
    "    print('==================================================')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.title('Training accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.title('Training loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#     print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ft in ft_ls:\n",
    "    print(ft)\n",
    "    PATH = './npy/mask1ft/' + ft\n",
    "    all_npy = loadFt(PATH)\n",
    "    print('All features:', all_npy.shape)\n",
    "    \n",
    "    latent_dim = 64 # latent dims\n",
    "    ft_dim = all_npy.shape[1] # feature dims\n",
    "    embedding_dims = 240\n",
    "    print(latent_dim, ft_dim, embedding_dims)\n",
    "    \n",
    "    SAVE_NAME = ft.split('.')[0]\n",
    "    print('SAVE_NAME:', SAVE_NAME)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    user = tf.placeholder(tf.int32,shape=(1,))\n",
    "    i = tf.placeholder(tf.int32, shape=(1,))\n",
    "    j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "    #多少個auxliary \n",
    "    xf = tf.placeholder(tf.float32, shape=(None, ft_dim))\n",
    "    l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "    r = tf.placeholder(tf.float32,shape=(None,))\n",
    "    positive_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "    positive_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "\n",
    "    image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "    image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "    with tf.variable_scope(\"item_level\"):\n",
    "        user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=8))\n",
    "        item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                      initializer=tf.random_normal_initializer(0,0.1,seed=9)) \n",
    "        aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                                   initializer=tf.random_normal_initializer(0,0.1,seed=10))\n",
    "\n",
    "    #     W1 = tf.get_variable(\"W1\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wu = tf.get_variable(\"Wu\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wy = tf.get_variable(\"Wy\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wa = tf.get_variable(\"Wa\", [usr_nb, movie_nb, latent_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Wv = tf.get_variable(\"Wv\", [usr_nb, movie_nb, embedding_dims], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    #     Wve = tf.get_variable(\"Wve\", [embedding_dims, ft_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    with tf.variable_scope('feature_level'):\n",
    "        embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "        Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                               initializer=tf.random_normal_initializer(0.01, 0.001, seed=10))\n",
    "\n",
    "    #lookup the latent factors by user and id\n",
    "    u = tf.nn.embedding_lookup(user_latent, user)\n",
    "    vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "    vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "    # w1 = tf.nn.embedding_lookup(W1, user)\n",
    "    wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user))\n",
    "    wy = tf.squeeze(tf.nn.embedding_lookup(Wy, user))\n",
    "    wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user))\n",
    "    wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user))\n",
    "\n",
    "    beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor\n",
    "    \n",
    "    a_list = tf.Variable([])\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def att_cond(q,a_list):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def att_body(q,a_list):\n",
    "        xfi = tf.expand_dims(xf[q],0) #(1,l)\n",
    "        wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "        wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[q]),0) #取該YOUTUBER那欄(1,K)\n",
    "\n",
    "        a_list = tf.concat([a_list,[(tf.nn.relu(tf.matmul(wuui, u, transpose_b=True) +\n",
    "                                                tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "                                                tf.matmul(wvui, tf.matmul(embedding,xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "        q += 1\n",
    "        return q, a_list\n",
    "\n",
    "    _, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "    a_list_smooth = tf.add(a_list,0.0000000001)\n",
    "    a_list_soft = tf.divide(a_list_smooth,tf.reduce_sum(a_list_smooth, 0)) #without softmax\n",
    "\n",
    "    norm_par = [wu,wy,wa,wv]\n",
    "\n",
    "    wuui = tf.expand_dims(tf.nn.embedding_lookup(wu,l_id[-1]),0)\n",
    "    wyui = tf.expand_dims(tf.nn.embedding_lookup(wy,l_id[-1]),0)\n",
    "    waui = tf.expand_dims(tf.nn.embedding_lookup(wa,l_id[-1]),0)\n",
    "    wvui = tf.expand_dims(tf.nn.embedding_lookup(wv,l_id[-1]),0)\n",
    "    wu_be_relu = tf.matmul(wuui, u, transpose_b=True)\n",
    "    wy_be_relu = tf.matmul(wyui, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[-1]),0), transpose_b=True)\n",
    "    wa_be_relu = tf.matmul(waui, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[-1]),0), transpose_b=True)\n",
    "    wv_be_relu = tf.matmul(wvui, tf.matmul(embedding,tf.expand_dims(xf[-1],0), transpose_b=True))\n",
    "\n",
    "    last_be_relu = [wu_be_relu,wy_be_relu,wa_be_relu,wv_be_relu]\n",
    "\n",
    "    aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "    q = tf.constant(0)\n",
    "\n",
    "    def sum_att_cond(q,aux_np):\n",
    "        return tf.less(q,l_id_len[0])\n",
    "\n",
    "    def sum_att_body(q,aux_np):\n",
    "        aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "        q += 1\n",
    "        return q, aux_np\n",
    "\n",
    "    _, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "    aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "    aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "    latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "    feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "    feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "    only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "    only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "    #矩陣中對應函數各自相乘\n",
    "    # ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "    xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "    xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "    xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "    l2_norm = tf.add_n([\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "                0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "                0.01 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "                0.00001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "\n",
    "                0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "                0.00001 * tf.reduce_sum(tf.multiply(embedding,embedding))\n",
    "              ])\n",
    "\n",
    "    loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "    auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "    \n",
    "    loss_acc_list = training(SAVE_NAME)\n",
    "    \n",
    "    # training history\n",
    "    epochs = range(1, len(loss_acc_list) + 1)\n",
    "    print('Epoch:', epochs)\n",
    "    loss = [ls[0].tolist()[0][0] for ls in loss_acc_list]\n",
    "    print('Loss:', loss)\n",
    "    acc = [ls[1] for ls in loss_acc_list]\n",
    "    print('Acc:', acc)\n",
    "    print('==================================================')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.title('Training accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.title('Training loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#     print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
