{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)  \n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x / np.sum(exp_x)\n",
    "    return softmax_x \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: (165, 4876)\n",
      "Movie genre: (165, 20)\n",
      "User following: (1582, 165)\n",
      "User genre: (1582, 20)\n"
     ]
    }
   ],
   "source": [
    "all_npy = np.load('./npy/all_4876.npy')\n",
    "movie_genre = np.load('./npy/movie_genre.npy')\n",
    "usr_following = np.load('./npy/user_followings.npy')\n",
    "usr_genre = np.load('./npy/user_genre.npy')\n",
    "\n",
    "print('All features:', all_npy.shape)\n",
    "print('Movie genre:', movie_genre.shape)\n",
    "print('User following:', usr_following.shape)\n",
    "print('User genre:', usr_genre.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize usr_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 20)\n"
     ]
    }
   ],
   "source": [
    "usr_genre_norm = np.zeros(usr_genre.shape)\n",
    "for i in range(len(usr_genre)):\n",
    "    usr_genre_norm[i] = usr_genre[i]/np.max(usr_genre[i])\n",
    "print(usr_genre_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [[2 1 0 ... 1 0 0]\n",
      " [4 8 4 ... 0 0 0]\n",
      " [2 2 2 ... 1 0 0]\n",
      " ...\n",
      " [5 3 0 ... 1 1 0]\n",
      " [2 2 0 ... 0 1 0]\n",
      " [3 2 0 ... 1 1 0]]\n",
      "After: [[0.22222222 0.11111111 0.         ... 0.11111111 0.         0.        ]\n",
      " [0.44444444 0.88888889 0.44444444 ... 0.         0.         0.        ]\n",
      " [0.4        0.4        0.4        ... 0.2        0.         0.        ]\n",
      " ...\n",
      " [0.26315789 0.15789474 0.         ... 0.05263158 0.05263158 0.        ]\n",
      " [0.28571429 0.28571429 0.         ... 0.         0.14285714 0.        ]\n",
      " [0.33333333 0.22222222 0.         ... 0.11111111 0.11111111 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('Before:', usr_genre)\n",
    "print('After:', usr_genre_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & testing split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582 165\n"
     ]
    }
   ],
   "source": [
    "usr_nb = len(usr_following) # the number of users\n",
    "movie_nb = len(movie_genre)  # the number of movies\n",
    "\n",
    "print(usr_nb, movie_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 16\n"
     ]
    }
   ],
   "source": [
    "usr_test_amount = 150\n",
    "movie_test_amount = 16\n",
    "\n",
    "print(usr_test_amount, movie_test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "usr_idx = [i for i in range(len(usr_following))]\n",
    "print(len(usr_idx))\n",
    "\n",
    "test_idx = random.sample(usr_idx, usr_test_amount)\n",
    "print(len(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "train_t = [0] * usr_nb\n",
    "train_f = [0] * usr_nb\n",
    "# Testing\n",
    "test_t = [0] * usr_test_amount\n",
    "test_f = [0] * usr_test_amount\n",
    "test_pos = -1\n",
    "\n",
    "for i in range(len(usr_following)):\n",
    "    \n",
    "    t_for_train = []\n",
    "    f_for_train = []\n",
    "    if i not in test_idx: #if not in test id, just append it to true or false list\n",
    "        for j in range(movie_nb):\n",
    "            if usr_following[i][j] == 1:\n",
    "                t_for_train.append(j)\n",
    "            else:\n",
    "                f_for_train.append(j)\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train\n",
    "        \n",
    "    else: #if in test id, choose 2 true and other \n",
    "        test_pos += 1\n",
    "        temp_t = []\n",
    "        temp_f = []\n",
    "        \n",
    "        for j in range(movie_nb):\n",
    "            \n",
    "            if usr_following[i][j] == 1:\n",
    "                temp_t.append(j)\n",
    "            else:\n",
    "                temp_f.append(j)\n",
    "        \n",
    "        # random choose 2 true and 8 false for test \n",
    "        t_for_test = random.sample(temp_t, 2)\n",
    "        f_for_test  = random.sample(temp_f, 8)\n",
    "        test_t[test_pos] = t_for_test\n",
    "        test_f[test_pos] = f_for_test\n",
    "        \n",
    "        #other for training\n",
    "        t_for_train = [item for item in temp_t if not item in t_for_test]\n",
    "        f_for_train = [item for item in temp_f if not item in f_for_test]\n",
    "        train_t[i] = t_for_train\n",
    "        train_f[i] = f_for_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_t: 1582\n",
      "The length of train_f: 1582\n",
      "The length of test_t: 150\n",
      "The length of test_f: 150\n"
     ]
    }
   ],
   "source": [
    "# train_t[i] 代表的是user i positive feedback\n",
    "print('The length of train_t:',len(train_t))\n",
    "print('The length of train_f:',len(train_f))\n",
    "print('The length of test_t:',len(test_t))\n",
    "print('The length of test_f:',len(test_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = 'MRM_ALL_Embedding250'\n",
    "LATENT_FOLDER = './latent_factor/MRM_ALL/Embedding250/'\n",
    "newPath(LATENT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 4876 250\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128 # latent dims\n",
    "ft_dim = all_npy.shape[1] # feature dims\n",
    "embedding_dims = 250\n",
    "\n",
    "print(latent_dim, ft_dim, embedding_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "user = tf.placeholder(tf.int32,shape=(1,))\n",
    "i = tf.placeholder(tf.int32, shape=(1,))\n",
    "j = tf.placeholder(tf.int32, shape=(1,))\n",
    "\n",
    "#多少個auxliary \n",
    "xf = tf.placeholder(tf.float32, shape=(None,ft_dim))\n",
    "l_id = tf.placeholder(tf.int32, shape=(None,))\n",
    "l_id_len = tf.placeholder(tf.int32,shape=(1,))\n",
    "r = tf.placeholder(tf.float32,shape=(None,))\n",
    "\n",
    "image_i = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "image_j = tf.placeholder(tf.float32, [1, ft_dim])\n",
    "\n",
    "with tf.variable_scope(\"item_level\"):\n",
    "    user_latent = tf.get_variable(\"user_latent\", [usr_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    item_latent = tf.get_variable(\"item_latent\", [movie_nb, latent_dim],\n",
    "                                  initializer=tf.random_normal_initializer(0,0.1,seed=3)) \n",
    "    aux_item = tf.get_variable(\"aux_item\", [movie_nb, latent_dim],\n",
    "                               initializer=tf.random_normal_initializer(0,0.1,seed=3))\n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\", [usr_nb, latent_dim],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wu = tf.get_variable(\"Wu\", [latent_dim,latent_dim], \n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wy = tf.get_variable(\"Wy\", [movie_nb, latent_dim, latent_dim],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wa = tf.get_variable(\"Wa\", [latent_dim, latent_dim],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Wv = tf.get_variable(\"Wv\", [latent_dim, ft_dim],\n",
    "                         initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    aux_new = tf.get_variable(\"aux_new\", [1, latent_dim], initializer=tf.constant_initializer(0.0))\n",
    "    ########## Error part, how to get auxisize dynamically\n",
    "    ####aux_size= tf.get_variable(name='aux_size', initializer=l_id.get_shape().as_list()[-1])\n",
    "    \n",
    "with tf.variable_scope('feature_level'):\n",
    "    embedding = tf.get_variable(\"embedding\", [embedding_dims,ft_dim],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "    Beta = tf.get_variable(\"beta\", [usr_nb, embedding_dims],\n",
    "                           initializer=tf.random_normal_initializer(0.00001,0.000001,seed=10))\n",
    "    \n",
    "#lookup the latent factors by user and id\n",
    "u = tf.nn.embedding_lookup(user_latent, user)\n",
    "vi = tf.nn.embedding_lookup(item_latent, i)\n",
    "vj = tf.nn.embedding_lookup(item_latent, j)\n",
    "\n",
    "w1 = tf.nn.embedding_lookup(W1, user) #(1*k)\n",
    "wu = Wu\n",
    "#wu = tf.squeeze(tf.nn.embedding_lookup(Wu, user)) #(k*k)\n",
    "wy = tf.squeeze(tf.nn.embedding_lookup(Wy, i)) #(k*k)\n",
    "wa = Wa\n",
    "#wa = tf.squeeze(tf.nn.embedding_lookup(Wa, user)) #(k*k)\n",
    "wv = Wv\n",
    "#wv = tf.squeeze(tf.nn.embedding_lookup(Wv, user)) #(k,l)\n",
    "\n",
    "beta = tf.nn.embedding_lookup(Beta, user) #user feature latent factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-15-e975e9415cb9>:76: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "a_list = tf.Variable([])\n",
    "q = tf.constant(0)\n",
    "\n",
    "def att_cond(q,a_list):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def att_body(q,a_list):\n",
    "    xfi = tf.expand_dims(xf[q],0) #(1,ft_dim)\n",
    "    \n",
    "    a_list = tf.concat([a_list,[(tf.matmul( w1, tf.nn.relu( tf.matmul(wu, u, transpose_b=True) +\n",
    "        tf.matmul(wy, tf.expand_dims(tf.nn.embedding_lookup(item_latent,l_id[q]),0), transpose_b=True) +\n",
    "        tf.matmul(wa, tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0), transpose_b=True) +\n",
    "        tf.matmul(wv, xfi, transpose_b=True)))[0][0])*r[q]]],0)\n",
    "    q += 1\n",
    "    return q,  a_list\n",
    "\n",
    "_, a_list = tf.while_loop(att_cond,att_body,[q,a_list],shape_invariants=[q.get_shape(),tf.TensorShape([None])])\n",
    "\n",
    "a_list_soft = tf.nn.softmax(a_list)\n",
    "\n",
    "\n",
    "aux_np = tf.expand_dims(tf.zeros(latent_dim),0)\n",
    "q = tf.constant(0)\n",
    "\n",
    "def sum_att_cond(q,aux_np):\n",
    "    return tf.less(q,l_id_len[0])\n",
    "\n",
    "def sum_att_body(q,aux_np):\n",
    "    #aux_np+=a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)\n",
    "    aux_np = tf.math.add_n([aux_np,a_list_soft[q]*tf.expand_dims(tf.nn.embedding_lookup(aux_item, l_id[q]),0)]) \n",
    "    q += 1\n",
    "    return q, aux_np\n",
    "\n",
    "_, aux_np = tf.while_loop(sum_att_cond, sum_att_body, [q,aux_np])\n",
    "\n",
    "aux_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "#tf.print('aux attention:',aux_np)\n",
    "aux_np += u #user_latent factor + sum (alpha*auxilary)\n",
    "aux_new = tf.assign(aux_new,aux_np) #把aux_new 的 值變成aux_np\n",
    "\n",
    "\n",
    "latent_i_part = tf.matmul(aux_new, vi, transpose_b=True)\n",
    "feature_i_part = tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "latent_j_part = tf.matmul(aux_new, vj, transpose_b=True)\n",
    "feature_j_part = tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "only_aux_i_part = tf.matmul(aux_np, vi, transpose_b=True)\n",
    "only_aux_j_part = tf.matmul(aux_np, vj, transpose_b=True)\n",
    "\n",
    "#矩陣中對應函數各自相乘\n",
    "# ex: tf.matmul(thetav,(tf.matmul(embedding, image_i, transpose_b=True)))\n",
    "xui = tf.matmul(aux_new, vi, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_i, transpose_b=True)))\n",
    "xuj = tf.matmul(aux_new, vj, transpose_b=True)+ tf.matmul(beta,(tf.matmul(embedding,image_j, transpose_b=True)))\n",
    "\n",
    "xuij = tf.subtract(xui,xuj)\n",
    "\n",
    "norm_par = [tf.reduce_sum(tf.multiply(u, u)),tf.reduce_sum(tf.multiply(vi, vi)),tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "           tf.reduce_sum(tf.multiply(w1, w1)),tf.reduce_sum(tf.multiply(wu, wu)),tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "           tf.reduce_sum(tf.multiply(wa, wa)),tf.reduce_sum(tf.multiply(wv,wv)),tf.reduce_sum(tf.multiply(beta,beta))]\n",
    "l2_norm = tf.add_n([\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(u, u)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vi, vi)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(vj, vj)),\n",
    "  \n",
    "            0.0001 * tf.reduce_sum(tf.multiply(w1, w1)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(wu, wu)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(wy, wy)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(wa, wa)),\n",
    "            0.0001 * tf.reduce_sum(tf.multiply(wv,wv)),\n",
    "            \n",
    "            0.001 * tf.reduce_sum(tf.multiply(beta,beta)),\n",
    "            \n",
    "          ])\n",
    "\n",
    "loss = l2_norm - tf.log(tf.sigmoid(xuij)) # objective funtion\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss) #parameter optimize \n",
    "auc = tf.reduce_mean(tf.to_float(xuij > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: Fri Mar  6 12:47:54 2020\n",
      "Iteration: 0\n",
      "total_loss          [[0.08078891]]\n",
      "train_auc:          0.9733971312537804\n",
      "\tCurrent time: Fri Mar  6 13:31:35 2020\n",
      "==================================================\n",
      "Iteration: 1\n",
      "total_loss          [[0.02767426]]\n",
      "train_auc:          0.991102134278061\n",
      "\tCurrent time: Fri Mar  6 14:15:24 2020\n",
      "==================================================\n",
      "Iteration: 2\n",
      "total_loss          [[0.0114475]]\n",
      "train_auc:          0.9963730234165731\n",
      "\tCurrent time: Fri Mar  6 14:59:14 2020\n",
      "==================================================\n",
      "Iteration: 3\n",
      "total_loss          [[0.00743184]]\n",
      "train_auc:          0.9978354791324635\n",
      "\tCurrent time: Fri Mar  6 15:43:06 2020\n",
      "==================================================\n",
      "Iteration: 4\n",
      "total_loss          [[0.00376023]]\n",
      "train_auc:          0.9989285405685647\n",
      "\tCurrent time: Fri Mar  6 16:26:55 2020\n",
      "==================================================\n",
      "Total cost time: 13140.847634792328\n",
      "End time: Fri Mar  6 16:26:55 2020\n"
     ]
    }
   ],
   "source": [
    "print('Start time:', time.ctime())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "loss_acc_list = []\n",
    "t0 = time.time()\n",
    "\n",
    "#use_true=init_list_of_objects(136)\n",
    "#use_test=init_list_of_objects(136)\n",
    "\n",
    "#train_pair_t=[] #positive feedback\n",
    "#train_pair_f=[] #negative feedback\n",
    "train_yes_id=[]\n",
    "\n",
    "for q in range(5):\n",
    "    print('Iteration:',q)\n",
    "    train_auc = 0\n",
    "    total_loss = 0\n",
    "    xuij_auc = 0\n",
    "    length = 0\n",
    "    \n",
    "    for z in range(usr_nb):\n",
    "        \"\"\"\n",
    "        yes 用來存放選擇到的YouTuber feature (for auxilary)\n",
    "        yesr 用來存放user對該YouTuber的喜好程度(user_category 跟 YouTuber_category的相似性)\n",
    "        r_3 用來存放user 對該YouTuber種類的偏好(取max)\n",
    "        \"\"\"\n",
    "        yes = []\n",
    "        yesr = []\n",
    "        \n",
    "        sample = random.sample(train_t[z],len(train_t[z])) #隨機選3個sample true's YouTuber\n",
    "        train_yes_id.append(sample) #sample全部丟進去\n",
    "        \n",
    "        #sample=random.sample(train_t[z]+train_f[z],len(train_t[z])+len(train_f[z]))\n",
    "        \n",
    "        #change\n",
    "        r_3 = np.zeros(len(sample)) \n",
    "        alpha_history = []\n",
    "        a_list_history = []\n",
    "        U_history = []\n",
    "        Y_history = []\n",
    "        \n",
    "        #print(len(sample))\n",
    "        #check if all YouTuber are in train_t or train_f\n",
    "        #if len(train_t[z])+len(train_f[z]) != 88:\n",
    "            #print(z,len(train_t[z])+len(train_f[z]))\n",
    "         \n",
    "        for b in range(len(sample)):\n",
    "            yes.append(all_npy[sample[b]])\n",
    "            yesr.append(movie_genre[sample[b]] * usr_genre_norm[z])\n",
    "            #print('YouTuber_category ', YouTuber_category[sample[k]])\n",
    "            #print('User_category ',user_category_norm[z])\n",
    "        #print(len(yes))\n",
    "        \n",
    "        for b in range(len(yesr)):\n",
    "            r_3[b]=max(yesr[b])\n",
    "        #print('r_3:',r_3)\n",
    "        \n",
    "        yes = np.array(yes)\n",
    "        #print('user shape should be ',np.array([z]).shape)\n",
    "        #print('xf shape should be ',yes.shape)\n",
    "        #print('r shape should be ',np.array(r_3).shape)\n",
    "        #print('l_id shape should be ',np.array(sample).shape)\n",
    "        \n",
    "        #not_used_list = list(set(train_t[z]).difference(set(sample)))\n",
    "        \n",
    "        # positive \n",
    "        train_t_sample = random.sample(train_t[z],len(train_t[z]))\n",
    "        #print('number of positive feedback', len(train_t[z]))\n",
    "        # negative\n",
    "        train_f_sample = random.sample(train_f[z],20)\n",
    "        \n",
    "        for ta in train_t_sample:\n",
    "            #print(ta,'--> positive feedback')\n",
    "            \n",
    "            pos = sample.index(ta)\n",
    "            #new_sample = np.delete(sample,[pos])\n",
    "            #new_yes = np.delete(yes,[pos],axis=0)\n",
    "            #new_r_3 = np.delete(r_3,[pos])\n",
    "            new_sample = sample\n",
    "            new_yes = yes\n",
    "            new_r_3 = r_3\n",
    "            #print(len(yes),len(new_yes))\n",
    "            #print(yes)\n",
    "            #print(new_yes)\n",
    "            \n",
    "            #ta=random.choice(train_t[z]) #ta is true positve photo\n",
    "            #train_pair_t.append(ta)\n",
    "            image_1=np.expand_dims(all_npy[ta],0) #(1,2048)\n",
    "            #print('Image_1 shape ',image_1.shape)\n",
    "            #train_f_sample = random.sample(train_f[z],20)\n",
    "            #print('True:',train_t_sample,'Now:',ta)\n",
    "            #print('False:',train_f_sample)\n",
    "            \n",
    "            for b in train_f_sample:\n",
    "                #print('likes:',ta,';Not likes:',b)\n",
    "                #b=random.choice(train_f[z])  #b is no feedback photo\n",
    "                #train_pair_f.append(b)\n",
    "                image_2=np.expand_dims(all_npy[b],0) #(1,2048)\n",
    "                #print('Image_2 shape',image_2.shape)\n",
    "            \n",
    "                #use_test[z].append(b)\n",
    "                _embedding,_a_list,r3,_auc, _loss,_=sess.run([embedding,a_list,a_list_soft,auc,loss,train_op], feed_dict={user: [z],\n",
    "                                        i: [ta], j: [b], xf: new_yes , l_id:new_sample, l_id_len:[len(new_sample)],r:new_r_3,\n",
    "                                        image_i:image_1,image_j:image_2})\n",
    "                \n",
    "                #print(XUIJ)\n",
    "                #print('loss=',_loss)\n",
    "                #print('auc=',_auc)\n",
    "                \n",
    "                #print('after softmax:',r3)\n",
    "                #print('before softmax:',_a_list)\n",
    "                #print('embedding:',_embedding)\n",
    "                #print('---------------------------------------------------')\n",
    "                a_list_history.append(_a_list)\n",
    "                alpha_history.append(r3)\n",
    "                train_auc += _auc\n",
    "                total_loss += _loss\n",
    "                length += 1\n",
    "            #now1+=1\n",
    "        \n",
    "        np.save(LATENT_FOLDER + str(q) + '_' + str(z),_embedding)\n",
    "    \n",
    "    #print('mine:',xuij_auc/136)   \n",
    "    #print('a_list_soft:',r3)\n",
    "    print(\"{:<20}{}\".format('total_loss', total_loss/length))\n",
    "    print(\"{:<20}{}\".format('train_auc:', train_auc/length))\n",
    "    \n",
    "    loss_acc_list.append([total_loss/length, train_auc/length, time.time()-t0])\n",
    "    \n",
    "    print('\\tCurrent time:', time.ctime())\n",
    "    print('==================================================')\n",
    "    \n",
    "print('Total cost time:',time.time()-t0)\n",
    "\n",
    "print('End time:', time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "loss= [[0.08078891]]\n",
      "acc= 0.9733971312537804\n",
      "==================================================\n",
      "Iteration: 1\n",
      "loss= [[0.02767426]]\n",
      "acc= 0.991102134278061\n",
      "==================================================\n",
      "Iteration: 2\n",
      "loss= [[0.0114475]]\n",
      "acc= 0.9963730234165731\n",
      "==================================================\n",
      "Iteration: 3\n",
      "loss= [[0.00743184]]\n",
      "acc= 0.9978354791324635\n",
      "==================================================\n",
      "Iteration: 4\n",
      "loss= [[0.00376023]]\n",
      "acc= 0.9989285405685647\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(loss_acc_list)):\n",
    "    print('Iteration:',i)\n",
    "    print('loss=',loss_acc_list[i][0])\n",
    "    print('acc=',loss_acc_list[i][1])\n",
    "#     print('time=',loss_acc_list[i][2])\n",
    "    print('==================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent factor and Each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "U, Y, A, A1, Au, Ay, Aa, Av, E, B = sess.run([user_latent, item_latent, aux_item, \n",
    "                                              W1, Wu, Wy, Wa, Wv, embedding, Beta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User latent shape:  (1582, 128)\n",
      "photo latent shape:  (165, 128)\n",
      "Auxilary latent shape:  (165, 128)\n",
      "W1 weight shape:  (1582, 128)\n",
      "Wu weight shape: (128, 128)\n",
      "Wy weight shape: (165, 128, 128)\n",
      "Wa weight shape: (128, 128)\n",
      "Wv weight shape: (128, 4876)\n",
      "Embedding shape: (250, 4876)\n",
      "Beta shape: (1582, 250)\n"
     ]
    }
   ],
   "source": [
    "print('User latent shape: ',U.shape)\n",
    "print('photo latent shape: ', Y.shape)\n",
    "print('Auxilary latent shape: ',A.shape)\n",
    "print('W1 weight shape: ',A1.shape)\n",
    "print('Wu weight shape:',Au.shape)\n",
    "print('Wy weight shape:', Ay.shape)\n",
    "print('Wa weight shape:', Aa.shape)\n",
    "print('Wv weight shape:', Av.shape)\n",
    "print('Embedding shape:', E.shape)\n",
    "print('Beta shape:',B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./weight/' + SAVE_NAME + '.npz', \n",
    "         U=U, Y=Y, A=A, A1=A1, Wu=Au, Wy=Ay, Wa=Aa, Wv=Av, E=E, B=B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1273\n",
      "alpha:         [-2.30421689e-48 -1.75178244e-24  1.13868815e-48 -8.83453920e-26\n",
      " -1.10507568e-24 -7.69014298e-24 -2.47631883e-24 -5.81664294e-24\n",
      " -3.31764132e-24 -5.29741763e-31]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "1 988\n",
      "alpha:         [ 2.00544921e-20 -4.39479051e-20  2.85005261e-21  2.93937860e-20\n",
      "  2.54160367e-20 -4.61905369e-21  2.83937757e-20  7.14964849e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "2 868\n",
      "alpha:         [-1.31503866e-20 -3.28282147e-20 -3.62162727e-20 -2.51541604e-21\n",
      " -4.60119950e-20 -5.70621289e-20 -1.05128761e-20 -3.30565488e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "3 582\n",
      "alpha:         [-2.17881334e-20 -3.74829773e-20 -3.24941373e-20 -8.11086012e-21\n",
      " -9.96976579e-20 -3.59875162e-20 -2.84597986e-25 -6.40283354e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "4 1078\n",
      "alpha:         [-2.47139129e-31  1.00836842e-32 -1.96824436e-28 -5.18390364e-35\n",
      " -4.63282062e-29 -4.90796863e-29 -1.09129675e-31 -7.85431330e-29\n",
      " -3.68745897e-29 -1.07448070e-29 -4.03498350e-29 -6.52951882e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "5 1122\n",
      "alpha:         [-2.30228940e-24 -8.42091490e-24 -1.88996724e-24 -7.34233415e-24\n",
      " -4.37564487e-24 -1.16126637e-24 -1.33528887e-25  8.05968376e-28\n",
      " -2.01773146e-24  9.90153902e-49]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "6 1041\n",
      "alpha:         [ 6.25359967e-20  1.68288431e-20  2.74840181e-21 -1.88422103e-20\n",
      "  1.17443250e-19  1.86265797e-20  1.26231689e-20 -9.08672937e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "7 180\n",
      "alpha:         [6.85412474e-22 5.60506333e-23 3.15022169e-22 3.67752189e-22\n",
      " 2.23951803e-21 1.71321823e-22 1.32548500e-22 2.05473694e-21\n",
      " 5.17548988e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "8 438\n",
      "alpha:         [-9.12437654e-46  3.15663916e-23  8.71479694e-22  4.54679409e-22\n",
      "  3.79009779e-23  1.91557527e-21  1.98716427e-22  7.44770498e-28\n",
      " -6.99276020e-46]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "9 740\n",
      "alpha:         [-8.79857436e-22 -1.94687526e-22 -9.51001009e-26  6.38265305e-22\n",
      "  4.70708675e-22  7.89195475e-22 -3.33972330e-22 -3.06445150e-22\n",
      "  3.98746460e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "10 1451\n",
      "alpha:         [-5.56508947e-30 -6.63210644e-29 -1.39364461e-29 -1.11254991e-29\n",
      " -1.44646508e-29 -3.40808535e-31 -2.14436421e-29 -5.53686876e-29\n",
      "  5.26626245e-30 -9.83591617e-31  3.97529347e-30 -6.71522661e-30]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "11 1197\n",
      "alpha:         [ 1.11195776e-20  7.29356697e-20 -1.70525831e-45  7.31892705e-20\n",
      "  6.21806783e-20  1.40342671e-20 -2.24010406e-20  9.50699413e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "12 169\n",
      "alpha:         [ 1.44584101e-59 -6.81258946e-35 -2.04011269e-34 -1.39225617e-36\n",
      " -9.31010807e-36  1.26043074e-37  4.89044572e-60 -2.47300765e-35\n",
      "  6.02478330e-36 -3.52436473e-37  1.39369786e-35 -4.45651532e-37\n",
      "  5.84545932e-36  1.86283018e-40 -6.84787131e-35 -4.74058212e-38\n",
      " -4.97619453e-35  2.78035506e-35  4.54395162e-36]\n",
      "softmax alpha: [0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158]\n",
      "==================================================\n",
      "13 852\n",
      "alpha:         [ 4.05175724e-27 -1.55323197e-27  1.83124914e-26  8.68958989e-28\n",
      " -2.17139816e-27  2.43836819e-27  1.04146988e-26  1.14199261e-27\n",
      "  5.62947551e-27  2.79164911e-32  1.78532494e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "14 971\n",
      "alpha:         [-6.05373070e-22 -3.48485857e-22  1.97098207e-22  1.47519032e-23\n",
      " -6.70882897e-22 -6.89242277e-47 -6.44052665e-22 -3.55913849e-46\n",
      "  2.93487841e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "15 945\n",
      "alpha:         [ 6.44854312e-21 -5.04555458e-20 -7.19724202e-20 -1.56902274e-19\n",
      " -4.79286508e-20 -9.59610969e-20 -4.09765450e-44  1.39739375e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "16 625\n",
      "alpha:         [-1.44250730e-23  3.61460668e-22  1.37989475e-21  7.89164083e-46\n",
      "  2.47188754e-21 -5.02009176e-22 -2.41926283e-22  6.25928555e-23\n",
      "  1.37968153e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "17 622\n",
      "alpha:         [ 6.99294421e-35  5.27191568e-35  1.55009357e-35  8.67125771e-36\n",
      " -1.01777381e-35  5.73432026e-35  9.49965371e-42  1.91968324e-35\n",
      "  1.26079715e-35  1.08325838e-37  1.00459393e-34  1.02737273e-34\n",
      "  3.40998406e-38 -5.48382594e-36  1.97665191e-35  7.57323570e-36\n",
      " -3.38457946e-35  1.99297332e-35]\n",
      "softmax alpha: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "==================================================\n",
      "18 470\n",
      "alpha:         [-1.44524418e-20 -3.68147810e-20  1.47918042e-20 -4.54582930e-20\n",
      "  1.37275065e-20 -6.53664671e-20 -1.34362085e-21  7.16395416e-23]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "19 623\n",
      "alpha:         [-5.09820718e-31  4.94193390e-29 -6.46103594e-29 -1.85938331e-29\n",
      " -1.28269471e-29 -2.66063013e-30  3.42412754e-30  3.66050914e-30\n",
      " -6.39843289e-29 -4.47324952e-29 -6.99660229e-29 -6.53312763e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "20 1486\n",
      "alpha:         [ 1.62072903e-34  2.09995046e-34 -8.53480144e-35  4.51274406e-34\n",
      "  4.10233982e-34 -2.13760624e-34 -5.17841050e-33 -1.44985059e-34\n",
      " -1.64421717e-34 -9.20304408e-34  4.52073140e-35  1.99295237e-57\n",
      " -2.05756870e-33]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "21 911\n",
      "alpha:         [-2.17179860e-25  1.71250016e-24 -6.98130459e-30 -6.14152777e-27\n",
      " -8.43960563e-30 -9.32274143e-24 -8.38267934e-24 -5.08684964e-25\n",
      "  3.27973192e-48 -1.60727082e-23]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "22 1551\n",
      "alpha:         [ 4.86296509e-30 -8.59709785e-30 -1.92331854e-30 -3.08999059e-30\n",
      "  2.91023264e-29  1.80401459e-29 -4.13860851e-29  1.79160615e-29\n",
      " -3.31813311e-53 -2.13831870e-29  2.04693599e-29  9.45396084e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "23 22\n",
      "alpha:         [ 4.79848942e-22 -6.56498754e-22  3.33041906e-22  2.71842993e-22\n",
      "  1.52635788e-23 -1.03951722e-22  3.51684620e-23  1.59839767e-23\n",
      " -2.11477536e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "24 526\n",
      "alpha:         [ 1.00657438e-22  1.43446017e-20  4.20224586e-20  5.53647285e-20\n",
      "  8.24244284e-21  7.44307523e-20 -4.35644057e-20 -2.67882616e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "25 1262\n",
      "alpha:         [-1.41881843e-25 -1.15298843e-24  5.90034341e-25  4.26106148e-27\n",
      "  9.91281723e-24 -2.07891763e-25  2.46421711e-24 -6.58918944e-25\n",
      "  6.12802582e-25  6.77375741e-29]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "26 453\n",
      "alpha:         [-4.65756189e-30 -2.52674098e-36 -8.91328610e-31  3.99481976e-29\n",
      " -1.19808983e-29 -6.48265049e-30 -2.32233917e-29 -5.84739681e-30\n",
      " -5.49871274e-30 -3.32025820e-29  1.39589002e-30  9.69361181e-31]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "27 668\n",
      "alpha:         [ 5.43557711e-53 -1.90399402e-29  4.38383243e-30  6.17399108e-29\n",
      "  1.96783804e-29 -1.13307052e-29  6.78573368e-29  3.30670635e-30\n",
      "  2.66239030e-53 -3.52307752e-29 -8.88053308e-30  2.21737140e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "28 700\n",
      "alpha:         [ 2.17001283e-24  3.55100769e-24  1.46924866e-24  1.36584693e-24\n",
      "  4.93594437e-25  3.90001907e-24  1.50325923e-24  4.46014133e-24\n",
      "  3.54034506e-24 -1.65276355e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "29 1543\n",
      "alpha:         [ 4.15513516e-35  1.73977749e-35  1.25455014e-34 -8.86400105e-36\n",
      "  2.08558024e-35  2.58913722e-35  1.17753754e-37  6.34650999e-35\n",
      " -1.91379391e-35  1.11545553e-34  1.61335969e-34  4.80262445e-35\n",
      "  1.91322699e-35  4.50664959e-35  2.71103857e-35  5.84852792e-35\n",
      " -1.57168826e-36]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "30 444\n",
      "alpha:         [-4.72269372e-29 -1.81530510e-29  1.88231993e-29 -6.31712759e-30\n",
      "  2.96715030e-53  9.15536445e-31 -2.54404302e-30 -1.45502954e-28\n",
      "  8.11310120e-30  2.58760200e-53  6.09764983e-30 -1.60616043e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "31 1518\n",
      "alpha:         [3.56207024e-48 1.20406213e-23 1.03853001e-24 4.06664043e-24\n",
      " 2.70896621e-24 2.32278705e-24 1.04756003e-29 5.80171124e-24\n",
      " 1.13670715e-48 1.37587284e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "32 139\n",
      "alpha:         [-2.54461303e-34 -1.67087154e-33 -8.81099893e-34 -4.62448339e-34\n",
      " -1.07410849e-33 -3.15501162e-34 -1.15163799e-33 -1.82592046e-34\n",
      "  3.31168960e-39  4.80271269e-35  4.30209079e-35 -7.81572413e-36\n",
      "  7.50511745e-36]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "33 1270\n",
      "alpha:         [1.17995328e-34 1.18479901e-35 4.07693142e-35 3.72871604e-37\n",
      " 2.02023942e-36 1.37453520e-34 9.17900013e-37 1.01481018e-35\n",
      " 8.70180498e-59 1.64713598e-35 3.03174115e-59 1.35633783e-36\n",
      " 1.67611851e-35 4.06043834e-35 7.65349747e-35 6.99443367e-36\n",
      " 2.67245495e-36]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "34 1042\n",
      "alpha:         [-1.05882233e-28  2.41318755e-26 -3.44630539e-27  2.96807755e-50\n",
      " -1.32386800e-26  5.18679161e-26  3.54366145e-27  6.87119794e-26\n",
      "  1.68855076e-27  1.16432762e-26 -2.36787885e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "35 1187\n",
      "alpha:         [-1.58924645e-19 -1.27044174e-21  6.50523977e-21 -5.46879470e-20\n",
      " -3.48498934e-20 -4.25234523e-20 -2.57077126e-20 -7.03644604e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "36 609\n",
      "alpha:         [ 3.80444501e-21 -1.98410623e-20  3.27768605e-20  2.15187938e-20\n",
      " -3.56692552e-20 -5.72437517e-21 -1.32918820e-21 -5.11789543e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "37 848\n",
      "alpha:         [ 3.22320560e-33 -1.77343666e-34 -9.79284281e-35  1.72336462e-33\n",
      " -8.68923462e-35 -2.70754376e-35  2.37536861e-33  2.90829927e-33\n",
      "  6.21293929e-34 -2.03229513e-34  4.05560995e-34 -1.83880464e-34\n",
      "  2.99412636e-35]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "38 362\n",
      "alpha:         [-7.69558480e-61 -4.57881542e-35  8.06886227e-36 -3.60800050e-35\n",
      "  2.59192568e-38 -2.83311911e-36 -6.89628687e-35 -3.29831747e-35\n",
      "  6.26862450e-36  5.14124801e-35  4.10782139e-35  2.95491199e-59\n",
      " -1.59978704e-35  2.41527245e-35  1.02349515e-34 -1.94407949e-35\n",
      "  5.24379321e-38  1.13558196e-34  4.66591063e-35  1.63426237e-35\n",
      " -2.06785801e-35 -1.28388979e-35]\n",
      "softmax alpha: [0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455]\n",
      "==================================================\n",
      "39 769\n",
      "alpha:         [-2.59564625e-22 -1.01327838e-22  6.11816638e-24 -1.18187616e-22\n",
      " -4.48781424e-23 -4.36876291e-23 -1.48214060e-22  7.78922749e-46\n",
      " -3.43303705e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "40 815\n",
      "alpha:         [ 1.52437153e-30  1.72658549e-29 -6.64229745e-29  4.53602510e-29\n",
      " -2.08424054e-32  2.86409120e-29  6.05913673e-29 -2.89959987e-36\n",
      "  2.20486741e-29 -8.73557128e-30  9.54617046e-30 -4.33909314e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "41 214\n",
      "alpha:         [ 4.51829869e-35  2.54563421e-37  4.53421749e-34  4.41350751e-59\n",
      "  2.51861469e-36 -2.69151888e-36  4.10678437e-35  7.97229599e-36\n",
      "  1.80111674e-35  6.51322844e-35  1.39505214e-37  7.84402044e-35\n",
      "  6.61128871e-35  1.62442472e-36  1.27270550e-35  2.05292832e-59\n",
      " -5.72702919e-35  5.21811601e-35]\n",
      "softmax alpha: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "==================================================\n",
      "42 315\n",
      "alpha:         [-3.68626907e-35 -1.16226505e-35  4.88013670e-35  2.37104227e-35\n",
      "  2.66275077e-35  4.60115510e-35  2.06803696e-35 -4.04148986e-36\n",
      "  4.87820997e-35  7.82040689e-35  2.52334551e-36 -7.03549775e-37\n",
      " -3.95959565e-36  1.90350646e-37  2.90191878e-36  1.18352421e-34\n",
      " -8.09604585e-36  1.87578470e-34  2.42646828e-35  2.29194415e-35\n",
      "  1.07062726e-34]\n",
      "softmax alpha: [0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905]\n",
      "==================================================\n",
      "43 507\n",
      "alpha:         [-7.53581626e-36  2.25025073e-35  7.55257865e-35  2.20903773e-35\n",
      "  1.29706022e-34 -8.61567052e-35  2.46647888e-35  1.18929754e-35\n",
      "  2.35357382e-35 -3.20825105e-35  1.30860939e-35  7.48087001e-35\n",
      " -1.00696599e-35  3.33773536e-59  1.12130185e-35  8.03138480e-37\n",
      "  3.22407726e-38  4.46725216e-35  3.95396114e-35  5.57627966e-35\n",
      "  3.08471106e-40  5.80988100e-60  6.58460509e-35]\n",
      "softmax alpha: [0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n",
      " 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n",
      " 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826\n",
      " 0.04347826 0.04347826 0.04347826 0.04347826 0.04347826]\n",
      "==================================================\n",
      "44 531\n",
      "alpha:         [-2.81408369e-21 -1.16460140e-19  1.07439765e-20  1.21795252e-19\n",
      "  1.98132411e-19  2.16909165e-21  5.43907056e-20  5.46216346e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "45 927\n",
      "alpha:         [ 1.70429606e-34 -6.63661708e-36  1.88008054e-34 -7.10411456e-34\n",
      " -1.49173496e-34 -2.34569920e-34  8.65798726e-34  1.64852309e-34\n",
      "  1.35106646e-34 -1.22180498e-34  5.75784034e-34  3.20950508e-34\n",
      " -4.34231450e-34]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "46 771\n",
      "alpha:         [-8.02337990e-58 -3.61165287e-33 -1.36816072e-33 -1.00320768e-33\n",
      "  5.06220211e-35  1.34366721e-33 -2.30399781e-33  2.07354492e-33\n",
      "  3.21192377e-33 -2.37821020e-33 -7.86602744e-33 -8.23588273e-34\n",
      " -2.67968795e-58 -4.38962649e-34]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "47 220\n",
      "alpha:         [-2.32919959e-35  1.65644584e-35 -9.28455004e-36 -1.16053640e-35\n",
      "  1.04393499e-35  3.36183585e-35  1.30659942e-35  1.69040972e-34\n",
      "  3.35901021e-35  2.95681336e-35  1.56450409e-35 -6.13117057e-36\n",
      " -2.29868534e-36  1.18712961e-35  7.26707019e-38 -4.05811023e-36\n",
      " -1.23000429e-36]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "48 498\n",
      "alpha:         [ 7.96954879e-36 -4.77713622e-35  1.36514554e-35  1.25594511e-34\n",
      " -8.66197684e-35  3.52649932e-35 -8.13239838e-37  4.47374645e-35\n",
      "  4.04240192e-35  9.23266720e-35  2.84149752e-36  6.80555072e-36\n",
      "  4.58511598e-35 -4.14538451e-35  3.68880312e-35  6.68568520e-36\n",
      "  1.51229257e-41  1.86305368e-35  1.18532477e-59]\n",
      "softmax alpha: [0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158]\n",
      "==================================================\n",
      "49 318\n",
      "alpha:         [-6.91682633e-35 -1.18257716e-35 -3.95304235e-36 -1.93684688e-35\n",
      "  2.73787437e-36  5.80511332e-60  2.06133451e-36 -1.19421560e-35\n",
      " -1.91304828e-35 -1.15567495e-35  2.15100785e-36  1.42215728e-35\n",
      "  1.21687674e-37 -7.87968692e-35 -4.45182693e-35 -3.01047550e-35\n",
      " -5.28411667e-35  2.99463091e-35 -5.13647949e-37 -5.92413073e-35\n",
      "  1.51661221e-35  9.15092237e-36]\n",
      "softmax alpha: [0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455]\n",
      "==================================================\n",
      "50 1409\n",
      "alpha:         [ 6.39211043e-25 -3.67919093e-24  8.78922460e-24  1.05315218e-48\n",
      "  3.61519247e-24 -8.24553627e-24  2.65767813e-27 -7.62500233e-24\n",
      "  5.71335079e-25  2.36742346e-25]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "51 1470\n",
      "alpha:         [ 4.67607663e-20  1.20991904e-19 -1.36163983e-21 -7.09636817e-20\n",
      "  2.83734330e-21 -3.03794816e-23 -1.27559940e-19  7.03459364e-23]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "52 395\n",
      "alpha:         [-1.25250447e-35  5.47397167e-35 -5.84891705e-36 -1.43541340e-35\n",
      "  7.59425147e-35  3.57382689e-60  2.62244505e-35 -1.55731799e-35\n",
      " -2.87928178e-35 -5.04935555e-36 -9.92491355e-36  3.26226807e-35\n",
      " -2.16265605e-35 -1.38816883e-35 -2.08589724e-34 -2.59039395e-36\n",
      "  3.59333613e-36 -1.52072122e-36 -9.12887395e-36  1.64539789e-35\n",
      " -3.16742875e-35 -6.74235094e-36  1.05077891e-35 -1.03518840e-36\n",
      "  1.90542834e-35 -4.02145286e-36 -9.46602194e-36 -3.68629434e-37\n",
      " -1.53871850e-36 -1.86877435e-35  7.71635178e-36  1.43330328e-35\n",
      "  6.67359678e-35  7.80559277e-37]\n",
      "softmax alpha: [0.02941176 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176\n",
      " 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176\n",
      " 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176\n",
      " 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176\n",
      " 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176\n",
      " 0.02941176 0.02941176 0.02941176 0.02941176]\n",
      "==================================================\n",
      "53 1279\n",
      "alpha:         [ 1.08330666e-27  1.32081758e-27  9.35061355e-27  2.47875789e-27\n",
      "  2.68554784e-27 -3.18346279e-27  2.28053111e-26  1.77140565e-50\n",
      "  3.71630128e-50 -1.40707142e-27  3.88507445e-27]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "54 743\n",
      "alpha:         [-9.61512077e-30 -1.48836887e-30 -3.95472469e-30 -9.71510400e-30\n",
      "  2.31294056e-30  1.13337335e-31 -1.67174170e-30  2.47773727e-29\n",
      "  4.47787427e-29  1.20251336e-29 -4.14769254e-29 -5.37642811e-30]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "55 584\n",
      "alpha:         [-3.80666273e-35  3.39262234e-35 -1.36909189e-37  6.39761165e-35\n",
      " -1.38524622e-35 -7.50770475e-35  1.80896918e-36  4.43639730e-36\n",
      " -3.42035980e-35 -4.07169419e-36  8.71867117e-59  1.65085723e-41\n",
      " -7.63557845e-35 -6.07482375e-35  3.19964426e-59 -3.87716258e-36\n",
      " -2.43738339e-36 -3.46977449e-35  1.34617738e-34 -1.11305917e-35\n",
      " -4.21941858e-36  1.39491415e-35  5.72425669e-35  8.43484020e-35\n",
      "  2.26055039e-38 -1.65846661e-35  4.84288446e-35 -3.44665465e-36\n",
      " -8.30029696e-36  8.07585286e-35 -4.96254189e-36 -9.01070600e-35\n",
      "  8.38956112e-36  3.31665309e-35  1.45516969e-35  7.98578468e-35\n",
      " -9.26744171e-41 -7.55340686e-37  1.97991787e-34  1.82274668e-36]\n",
      "softmax alpha: [0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025\n",
      " 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025\n",
      " 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025\n",
      " 0.025 0.025 0.025 0.025]\n",
      "==================================================\n",
      "56 1141\n",
      "alpha:         [ 4.92765648e-46 -1.98221045e-22 -1.84122909e-22 -6.02576622e-25\n",
      "  4.81348392e-24  5.84089575e-24 -9.46822525e-22 -6.78385675e-22\n",
      " -9.92211237e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "57 1456\n",
      "alpha:         [-6.86112053e-53 -2.87346165e-29 -3.13680597e-29 -5.73262724e-30\n",
      " -1.10436766e-29 -5.53018937e-31 -1.27588610e-29 -7.19432987e-30\n",
      " -2.70004942e-30  6.72939876e-30 -8.19247708e-30 -2.64184505e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "58 325\n",
      "alpha:         [ 3.48010820e-25 -9.87452363e-24 -4.75641187e-24 -1.73790439e-24\n",
      "  3.62244078e-24 -1.05616895e-23 -1.15447402e-25 -4.53488335e-24\n",
      " -5.84000220e-24  6.70201521e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "59 648\n",
      "alpha:         [1.59112515e-20 1.30081809e-43 1.25176119e-19 2.39103017e-20\n",
      " 3.58442842e-20 2.64492066e-20 1.57210408e-43 8.12332197e-26]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "60 987\n",
      "alpha:         [ 7.25042691e-25  9.95580722e-26  9.31637033e-25 -4.95193705e-25\n",
      "  1.03376103e-24 -1.03510639e-24 -1.71451291e-24 -1.14370112e-29\n",
      " -6.65120592e-25 -4.97878435e-25]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "61 632\n",
      "alpha:         [ 2.23014020e-35  8.42286686e-35  2.90740753e-35 -5.19740185e-37\n",
      "  1.15007866e-35  1.67228348e-35 -5.15327618e-36 -1.31038683e-35\n",
      "  3.99238032e-35  9.66342404e-35  5.70388739e-37 -5.90022883e-35\n",
      "  6.36059874e-35 -2.54765082e-36  2.77119546e-35 -1.89399225e-35\n",
      "  4.27020312e-36  4.77418084e-35  1.17801032e-35  4.07197964e-35]\n",
      "softmax alpha: [0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "==================================================\n",
      "62 1035\n",
      "alpha:         [-4.53658984e-27  1.24920344e-27 -1.50771737e-26  6.41876648e-27\n",
      "  9.09386952e-27  5.85877265e-28  1.12998967e-26  1.14013539e-26\n",
      " -2.29524597e-27 -1.04439332e-27 -1.71599417e-27]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "63 1213\n",
      "alpha:         [-7.63485562e-20  5.83901514e-20 -2.12054447e-20  6.46516769e-20\n",
      "  1.83313207e-20  6.57696301e-21 -7.92663652e-20 -2.30239910e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "64 290\n",
      "alpha:         [-5.94565651e-36 -7.15321567e-35  1.92516304e-50  1.01364659e-36\n",
      " -3.07474291e-35 -1.20769377e-36 -1.24658473e-36 -3.21430939e-37\n",
      " -4.83732812e-35 -6.61280153e-35 -9.28789288e-37 -2.41343250e-35\n",
      " -6.61689843e-35 -5.22695101e-36 -1.46060402e-35 -2.15588806e-35\n",
      " -1.70271886e-35 -4.06474266e-35]\n",
      "softmax alpha: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "==================================================\n",
      "65 1278\n",
      "alpha:         [-1.88309621e-34 -8.20858491e-29 -1.23950692e-30 -1.82701724e-29\n",
      " -9.00714804e-29 -9.86989440e-29 -1.09623805e-29 -5.78841560e-30\n",
      " -1.44329866e-28 -5.10597693e-53 -4.42297751e-53  2.91516974e-30]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "66 101\n",
      "alpha:         [-6.17825188e-29 -4.73864618e-29 -1.01991582e-28 -2.75220288e-29\n",
      " -1.00269797e-28 -8.39465730e-29 -3.37397734e-29  9.84502659e-30\n",
      " -4.71250549e-30  2.79614914e-29 -1.08479205e-28 -1.49141435e-28]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "67 842\n",
      "alpha:         [ 1.38774202e-35 -4.37016173e-36  3.93578983e-36 -1.99609448e-59\n",
      "  1.20169767e-35  2.42869012e-35  7.28512478e-35  2.33666868e-37\n",
      "  5.61605127e-36  2.18977054e-35 -5.05533131e-36 -1.99237559e-34\n",
      "  2.58382717e-35  1.42585284e-35  2.96531521e-35  1.56726480e-36\n",
      "  2.03210113e-34]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "68 196\n",
      "alpha:         [-1.73237650e-21  5.51103178e-22 -3.07832499e-22 -3.92163280e-22\n",
      "  1.12393930e-23  8.83123352e-22 -4.14491835e-22 -2.98766583e-23\n",
      " -1.62860831e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "69 867\n",
      "alpha:         [ 2.25753447e-38 -3.13000327e-35  3.74199271e-35  1.51056900e-35\n",
      "  8.02813547e-36  1.46132843e-35  8.55590871e-40  8.86694420e-35\n",
      " -8.49967089e-35 -4.43704748e-35 -1.23299004e-36  4.94594675e-35\n",
      "  7.09242550e-38  6.61649989e-35  1.20630782e-34  5.02838123e-36\n",
      " -9.75548749e-36  1.24202244e-34  9.53709863e-35  2.87202783e-35\n",
      " -1.32036845e-35]\n",
      "softmax alpha: [0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905]\n",
      "==================================================\n",
      "70 48\n",
      "alpha:         [-2.20686012e-20  1.08589868e-19  4.61993432e-20 -3.41766327e-20\n",
      "  5.50832170e-20  7.97320368e-23  1.16272845e-20  4.60531661e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "71 600\n",
      "alpha:         [-4.08023334e-23 -3.07979913e-22 -5.77790486e-22 -2.77861595e-23\n",
      " -4.94927176e-23 -5.01980284e-23 -5.90398159e-23 -2.75690012e-23\n",
      " -1.75254473e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "72 1497\n",
      "alpha:         [ 1.03879973e-23 -4.16872463e-25 -3.65186059e-23 -3.55534783e-22\n",
      "  5.98038112e-23 -1.72250966e-21  5.75424706e-22  8.14754535e-22\n",
      " -5.89607098e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "73 1185\n",
      "alpha:         [2.27636196e-20 2.49145941e-20 8.32030446e-21 9.23721208e-21\n",
      " 3.98049314e-44 6.50515630e-44 4.83571135e-44 9.96996245e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "74 1435\n",
      "alpha:         [ 5.56388153e-26 -4.45331228e-26  7.95765671e-33  3.65196696e-26\n",
      "  8.81095188e-31  1.58530282e-27  3.39402358e-27 -3.71864412e-28\n",
      " -6.40860580e-27  6.94939697e-26 -4.55992080e-27]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "75 568\n",
      "alpha:         [ 3.26206059e-35  2.29157123e-35 -3.44563957e-35  1.18127794e-34\n",
      " -1.64330072e-37  4.68643813e-35  1.84658160e-35  2.94296974e-38\n",
      " -3.56002978e-36 -2.80804357e-36  4.17288539e-35 -4.41547897e-38\n",
      "  4.74678519e-36  3.26771199e-37  3.13456522e-35  1.49882148e-35\n",
      " -3.42868699e-35 -1.17339419e-34 -6.68585398e-36 -5.70765717e-37]\n",
      "softmax alpha: [0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "==================================================\n",
      "76 256\n",
      "alpha:         [-1.14707023e-24 -3.71811951e-25 -5.59365484e-24 -1.74932400e-24\n",
      "  5.38572064e-26 -1.30035467e-24 -4.16099655e-24  7.99688331e-26\n",
      "  1.32596545e-24 -2.94656884e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "77 126\n",
      "alpha:         [ 3.35329277e-24  2.44342998e-24  3.92958060e-24 -1.35834859e-48\n",
      "  3.58900525e-25 -6.59607426e-49  4.51454884e-24 -1.49942652e-26\n",
      " -5.63256396e-31  2.43095488e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "78 847\n",
      "alpha:         [ 4.70105993e-35 -8.23642211e-36  4.16060738e-36 -2.10924472e-35\n",
      "  1.25560181e-34  8.69982332e-37  3.20003071e-59  2.35304240e-59\n",
      " -5.22891132e-36  1.28231318e-35 -5.41933001e-35  1.80316388e-37\n",
      " -5.29424351e-36  3.52329049e-35  1.21035651e-35  2.56846127e-36\n",
      "  7.65878738e-35]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "79 573\n",
      "alpha:         [ 3.08489732e-35 -1.22661943e-35  4.25631544e-35  2.82910659e-40\n",
      " -3.36244886e-35  1.29661656e-35  2.12195528e-35 -1.20638223e-35\n",
      " -3.14113205e-36 -2.00300817e-35  6.02564096e-37 -2.94681945e-35\n",
      "  1.91174277e-35  3.56424448e-35 -2.82105448e-35 -2.74520901e-35\n",
      "  4.07750152e-37  2.56084764e-35  7.30585167e-35  1.10249846e-34\n",
      " -9.60500499e-37]\n",
      "softmax alpha: [0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905\n",
      " 0.04761905 0.04761905 0.04761905]\n",
      "==================================================\n",
      "80 942\n",
      "alpha:         [ 6.05501554e-35  2.45989347e-35 -9.43930067e-37 -3.98812858e-35\n",
      "  8.31306625e-35  9.57790134e-36  3.68631882e-35  9.10754750e-35\n",
      "  8.09411635e-36  4.73572987e-35  2.22107216e-35 -2.55838693e-36\n",
      " -7.26978138e-36  2.69823876e-35 -1.92233103e-37  1.60710475e-34\n",
      " -4.54689865e-35]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "81 514\n",
      "alpha:         [-1.03643997e-19 -4.32902538e-20 -6.67232198e-22 -2.29721223e-21\n",
      " -9.67050201e-44 -1.23888891e-19  9.23497311e-21 -1.11065526e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "82 354\n",
      "alpha:         [ 1.41832226e-21  1.47886051e-22  1.15749272e-22  2.61478084e-22\n",
      " -4.84558696e-22 -4.68878426e-24  1.12560445e-23 -8.72568708e-22\n",
      "  3.77998440e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "83 108\n",
      "alpha:         [ 4.39222640e-40 -1.52381996e-35  2.49846793e-35  2.25158872e-35\n",
      "  1.21966608e-34 -1.16397283e-35  3.58204886e-34  3.31713067e-36\n",
      "  3.98708418e-34  2.65310358e-35  5.17597595e-34  1.29316336e-34\n",
      "  8.67970654e-35 -3.55978839e-36  1.92360574e-34]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "84 1011\n",
      "alpha:         [-2.57179321e-22 -2.92779241e-22 -1.32796944e-21 -4.71112898e-22\n",
      " -6.39159000e-22 -1.08195655e-22 -1.04681020e-21 -1.64511259e-21\n",
      " -1.04842330e-24]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "85 562\n",
      "alpha:         [-2.63334146e-33 -7.19615869e-33 -2.38007365e-33 -4.72961985e-34\n",
      " -9.82856128e-35  1.80060281e-33  4.00890524e-57 -4.56154657e-34\n",
      "  1.33378540e-35  2.23375994e-33 -5.26526532e-33  4.40535392e-34\n",
      "  6.31562115e-36 -1.97130725e-34]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "86 405\n",
      "alpha:         [-2.59268334e-20 -6.77856456e-21  9.12278382e-44  1.77634219e-20\n",
      "  1.33332606e-19 -1.27105557e-44  9.72993078e-44  3.65672029e-25]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "87 1200\n",
      "alpha:         [ 5.74674623e-23 -3.32057675e-22 -3.11483222e-46  5.59408019e-22\n",
      " -2.65385211e-22 -4.05117119e-22  1.50803654e-22  7.06762503e-22\n",
      "  2.86240462e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "88 589\n",
      "alpha:         [ 1.14321967e-22 -2.81816367e-22  3.07187213e-22 -1.24856092e-22\n",
      " -5.92071403e-23 -1.09903460e-21 -4.28577233e-22 -1.02480295e-45\n",
      " -7.59047771e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "89 1317\n",
      "alpha:         [ 3.20041456e-35  5.11231251e-35  1.58406807e-35  6.71580082e-35\n",
      "  1.63486888e-35  2.01108635e-35 -2.30172117e-36  7.95607659e-35\n",
      "  1.53639756e-35  1.17679096e-35  1.75511072e-35  1.50018228e-41\n",
      " -1.26496295e-35  5.19748536e-37  3.13886450e-35 -1.18079353e-36\n",
      " -4.68965672e-35 -4.87245185e-35  3.45379937e-35  5.96668101e-35\n",
      " -1.44860118e-35  2.01389027e-37]\n",
      "softmax alpha: [0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455]\n",
      "==================================================\n",
      "90 462\n",
      "alpha:         [-5.50560259e-26 -6.81100139e-27 -1.75201740e-27  5.10709220e-27\n",
      "  2.23865544e-27  6.18610316e-27 -2.67171522e-26 -6.90862967e-27\n",
      "  2.04613480e-27 -1.94366331e-50  5.03311657e-28]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "91 602\n",
      "alpha:         [ 2.51934798e-35  1.72339564e-36  2.48928147e-35  1.39312437e-35\n",
      "  2.51887110e-35  1.12154493e-35 -1.16395929e-35 -1.05478051e-35\n",
      "  3.68911855e-35  5.15234956e-35  3.36929640e-36  2.29696013e-35\n",
      "  4.38235858e-35  2.97314743e-35  1.34435319e-35  2.49747517e-36\n",
      "  2.57628698e-35  1.55742567e-36  1.96564463e-36]\n",
      "softmax alpha: [0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.05263158]\n",
      "==================================================\n",
      "92 445\n",
      "alpha:         [-1.33118958e-22  1.73150829e-22 -1.37189331e-22  9.79519461e-23\n",
      " -1.73658430e-22 -2.36419295e-21 -1.80072256e-22  1.61884171e-21\n",
      " -5.04809015e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "93 90\n",
      "alpha:         [-1.08697870e-20  5.86530012e-20 -2.55832426e-21  1.57816623e-21\n",
      " -7.27113884e-20  1.28212928e-20 -3.32045598e-21 -1.31277067e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "94 807\n",
      "alpha:         [-2.66068639e-24 -3.98054992e-27  2.07766326e-23 -2.37753316e-24\n",
      "  2.18308908e-24  6.45449030e-26 -6.05471418e-25  6.41382652e-25\n",
      "  1.67026623e-25  2.67066051e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "95 1412\n",
      "alpha:         [ 4.39022947e-22 -1.99260082e-21 -1.67462257e-23  9.55621772e-47\n",
      " -7.65096827e-46 -1.37587293e-22  4.21342741e-22 -1.37138803e-22\n",
      " -7.51756375e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "96 35\n",
      "alpha:         [-6.86813843e-36 -9.22497413e-35 -1.00769536e-34 -3.33300347e-35\n",
      "  5.79500725e-36 -2.22622527e-36 -7.82914250e-36  2.67942964e-35\n",
      " -6.38183916e-35  1.87682100e-35 -2.41789014e-38 -7.30454847e-36\n",
      " -1.92319078e-35  1.18787083e-35 -2.88911324e-35  1.60110723e-36\n",
      "  2.33298733e-36 -1.89336468e-35]\n",
      "softmax alpha: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "==================================================\n",
      "97 0\n",
      "alpha:         [-3.77465843e-18  2.78641966e-20  2.33410519e-20 -6.26873528e-17\n",
      " -2.07812210e-18 -4.27190928e-17 -1.83611938e-17  3.68641237e-18]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "98 132\n",
      "alpha:         [2.37154501e-19 2.03112113e-20 1.25148624e-19 8.94432511e-21\n",
      " 1.26436332e-20 9.16103498e-20 4.54867316e-20 6.70341151e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "99 595\n",
      "alpha:         [-2.15119020e-20 -1.51882858e-20 -2.92561853e-21 -4.49650127e-20\n",
      "  1.84236022e-20 -7.80004859e-22 -1.10489960e-19 -1.05648134e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "100 1087\n",
      "alpha:         [-1.48795319e-38  3.04829455e-35 -2.08958138e-35 -6.63761353e-35\n",
      " -2.49021559e-35  7.16914746e-36 -1.57889712e-35 -1.17133078e-42\n",
      " -5.50164282e-35 -7.62281592e-36 -2.12648716e-35 -9.88430839e-61\n",
      " -9.97073335e-35 -8.86144123e-39 -1.94678056e-37 -2.44019632e-35]\n",
      "softmax alpha: [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "==================================================\n",
      "101 284\n",
      "alpha:         [ 3.80201072e-20 -3.18597425e-20  5.58755559e-20  1.89987850e-20\n",
      "  5.05499092e-20  3.51878577e-20 -7.72033961e-20 -2.08661286e-23]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "102 47\n",
      "alpha:         [ 5.29158967e-35 -1.03247831e-34 -2.12827336e-37 -1.68722699e-35\n",
      " -4.24681500e-35 -3.16811484e-35 -8.30454196e-36  5.98713825e-35\n",
      "  1.77802668e-36  4.29854833e-35  7.23479883e-59  4.31038781e-38\n",
      " -6.65718623e-35  1.74853391e-59 -4.83957857e-35  8.77671616e-35\n",
      "  3.16199552e-36 -8.34625977e-36]\n",
      "softmax alpha: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "==================================================\n",
      "103 346\n",
      "alpha:         [ 1.16995958e-23 -7.24518844e-24  1.29198968e-48 -6.00740247e-25\n",
      "  2.67031404e-24  1.63435395e-24  4.18760614e-25  6.42783985e-25\n",
      " -2.86076952e-25  3.45853303e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "104 402\n",
      "alpha:         [-1.14989013e-45  5.25007532e-22 -9.17514919e-22 -1.90434743e-22\n",
      "  2.93449675e-23 -8.91034053e-23 -3.00690125e-22 -4.79530379e-23\n",
      " -1.76223216e-45]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "105 680\n",
      "alpha:         [-8.03091143e-36 -7.54707253e-35 -7.20359413e-35 -4.11005874e-36\n",
      " -1.29751112e-59 -3.05063410e-59  1.20481984e-35 -3.98877936e-35\n",
      "  1.46974701e-35 -1.19803612e-34  1.40719303e-35 -7.27247134e-36\n",
      "  2.03479921e-36  1.93356084e-35 -8.81067904e-37 -6.09133132e-60\n",
      "  6.87938117e-35]\n",
      "softmax alpha: [0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353\n",
      " 0.05882353 0.05882353 0.05882353 0.05882353 0.05882353]\n",
      "==================================================\n",
      "106 327\n",
      "alpha:         [ 1.20885776e-41 -1.80436479e-38 -5.86927526e-37  1.36975306e-35\n",
      "  1.42766797e-35 -8.35276942e-37 -8.61567181e-37  2.13469614e-41\n",
      "  2.15683282e-34 -6.31271163e-36  1.02579527e-35  4.29367947e-38\n",
      "  1.20080176e-35  2.71407187e-35  8.14799396e-35 -6.51308255e-36\n",
      " -6.63359028e-35  9.84054206e-38]\n",
      "softmax alpha: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
      "==================================================\n",
      "107 660\n",
      "alpha:         [-2.28711222e-20 -4.13419496e-20 -4.19966061e-20 -3.22434300e-20\n",
      " -3.63139646e-21 -2.34726598e-21 -2.60926804e-20 -1.13889066e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "108 1448\n",
      "alpha:         [-1.46495397e-33 -8.98542138e-34  5.73859998e-40  2.01439987e-58\n",
      "  4.87800351e-58 -1.49320572e-33 -4.54826568e-34 -5.79412817e-34\n",
      "  3.53209318e-34  1.72497667e-35  6.35384542e-35 -2.48020370e-33\n",
      "  1.95785948e-34]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "109 1362\n",
      "alpha:         [-1.85593326e-53 -8.42622636e-29 -9.77425544e-29 -1.83692154e-29\n",
      "  2.33951680e-29 -4.15402733e-29 -8.76948082e-54 -2.64648132e-36\n",
      " -8.11907466e-30 -3.61117264e-54 -3.35011828e-29 -8.71944669e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "110 1057\n",
      "alpha:         [ 4.83336785e-20 -8.76022373e-45  1.15590350e-22 -7.06215867e-20\n",
      "  2.66887107e-20  6.28003575e-20 -3.30451852e-25  4.34619209e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "111 544\n",
      "alpha:         [ 1.65040593e-20  4.83995387e-44  7.34177648e-21  2.17628867e-20\n",
      "  3.03272312e-20 -1.20816487e-20  1.09424830e-19  6.75273586e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "112 484\n",
      "alpha:         [-3.68543147e-21  3.65650026e-20 -5.74339893e-21  7.83921271e-21\n",
      "  1.52076732e-20 -9.64991264e-44  5.35545583e-20  3.10035984e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "113 1484\n",
      "alpha:         [ 1.24572367e-35  1.25953622e-37 -1.19190236e-35 -1.87397426e-35\n",
      "  2.72085766e-35 -3.68015474e-35 -1.34461932e-35  2.27012580e-34\n",
      "  3.02327306e-35  7.25286877e-36  1.88873865e-35 -1.73881277e-35\n",
      "  1.36332684e-35  1.30753657e-36  1.15660309e-35  1.39584493e-35]\n",
      "softmax alpha: [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "==================================================\n",
      "114 147\n",
      "alpha:         [ 3.73329484e-22  7.22229890e-22  5.97320254e-22  5.72207420e-23\n",
      "  3.08198573e-22  2.20765904e-23  9.04982433e-22  2.70998490e-21\n",
      " -1.32373219e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "115 713\n",
      "alpha:         [-7.06964492e-25  8.72152219e-25 -1.20481066e-24  1.81377645e-25\n",
      " -9.68737122e-25 -1.15036236e-24 -1.28975011e-25  3.32350620e-25\n",
      " -6.73526092e-25 -1.78785160e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "116 412\n",
      "alpha:         [ 1.28289621e-21  4.73828947e-23  3.38942361e-22 -2.82872969e-22\n",
      "  9.34348347e-23  3.50750595e-21 -5.57328431e-23  6.37919510e-25\n",
      " -1.04074647e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "117 1255\n",
      "alpha:         [ 7.78675870e-20 -2.30505332e-20  4.04903370e-44 -1.43355438e-20\n",
      "  6.49769077e-20  3.60888208e-22  1.19231512e-44 -1.86497816e-21]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "118 1541\n",
      "alpha:         [ 1.98583035e-22  2.16234338e-46  2.48867920e-23 -1.29929852e-22\n",
      "  2.08532551e-46  2.73869046e-23  2.42051573e-22  3.37428236e-22\n",
      "  1.23289930e-21]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "119 1397\n",
      "alpha:         [ 2.79325184e-29 -2.90235723e-29 -1.52518100e-29 -1.58249581e-29\n",
      "  1.55981202e-29  6.56422065e-29  3.73010067e-53  1.33798562e-35\n",
      "  1.06477149e-29  3.88903084e-53  4.54240563e-29 -4.63864790e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "120 1008\n",
      "alpha:         [-3.28164622e-20 -6.32691316e-20 -8.74782506e-21  4.97781825e-21\n",
      " -6.05873707e-20  1.27475797e-20 -9.63056045e-44 -3.52997760e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "121 917\n",
      "alpha:         [-3.23723334e-26 -3.17726589e-24  3.25758789e-24 -7.02059466e-24\n",
      " -2.26054054e-30 -2.53984712e-24 -7.32157684e-31 -2.25586118e-24\n",
      " -5.20040242e-25 -6.36419629e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "122 433\n",
      "alpha:         [ 7.06746055e-25  1.73647814e-24 -5.09413485e-24  7.80612836e-24\n",
      "  1.62330207e-23  7.37919084e-24  1.49336261e-23  1.48703616e-47\n",
      "  4.71625354e-24  9.45684273e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "123 537\n",
      "alpha:         [-5.54631625e-34  2.04250823e-33  2.56228619e-33 -1.37373195e-34\n",
      "  1.82021124e-33  7.23714300e-34 -1.14311520e-33 -1.60746980e-33\n",
      " -1.30724289e-34  3.06340367e-33  1.82130255e-33 -4.10556859e-33\n",
      " -5.76795028e-36 -2.91786614e-34]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "124 1414\n",
      "alpha:         [ 6.44542317e-34  3.44845954e-34  1.63619580e-33  3.51868822e-37\n",
      "  1.12345050e-33  4.90844986e-33 -4.15451145e-40 -1.40434961e-33\n",
      " -2.72916723e-34  1.10312996e-33  1.72245006e-34 -2.32343398e-33\n",
      "  2.83576120e-33  1.56572235e-34]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "125 1539\n",
      "alpha:         [-5.20974034e-53 -7.00574934e-29 -1.08846284e-29 -4.32581987e-30\n",
      " -6.45712453e-30 -1.00484659e-28 -3.08757717e-29 -1.01566983e-29\n",
      " -6.45034002e-30 -3.37910118e-29 -1.28709682e-28 -6.72304704e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "126 635\n",
      "alpha:         [2.61979624e-29 3.62710450e-29 6.32670147e-30 3.25816404e-53\n",
      " 2.68805243e-29 1.13701972e-29 2.62027676e-29 1.20633739e-29\n",
      " 6.47438252e-30 2.98947672e-30 2.87129146e-29 1.86206507e-29]\n",
      "softmax alpha: [0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333]\n",
      "==================================================\n",
      "127 371\n",
      "alpha:         [ 3.98019895e-27  4.31242500e-27 -1.80087856e-26  1.37466154e-26\n",
      " -3.97289381e-27 -3.99229842e-26  7.41476202e-26  2.60414162e-26\n",
      " -1.18848974e-26 -2.92942933e-28 -1.74828382e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "128 941\n",
      "alpha:         [-8.68257899e-22 -7.07573480e-22  2.05465943e-23 -3.34580279e-22\n",
      "  3.50074174e-46  1.81305091e-22  6.63842271e-30  1.38325198e-22\n",
      "  4.47345674e-28]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "129 1120\n",
      "alpha:         [-8.08902831e-35  1.04774983e-34 -2.81999979e-35 -3.21758322e-34\n",
      " -1.69377276e-35 -1.06706733e-34  2.04470299e-35  3.05939811e-36\n",
      " -1.24719574e-34  5.47320823e-35 -2.06102619e-36 -1.91252879e-34\n",
      " -7.03079516e-35 -9.07736590e-35  6.11767613e-35]\n",
      "softmax alpha: [0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      " 0.06666667 0.06666667 0.06666667]\n",
      "==================================================\n",
      "130 1183\n",
      "alpha:         [ 3.93462706e-33  5.10368469e-57 -5.63033003e-34 -2.16002766e-33\n",
      " -3.29438196e-34 -1.21376980e-33  8.52183347e-34  3.52792760e-34\n",
      " -3.83168168e-33 -3.49372820e-34 -3.17868633e-36 -1.85450434e-57\n",
      "  7.29526992e-57 -1.44111898e-35]\n",
      "softmax alpha: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "==================================================\n",
      "131 511\n",
      "alpha:         [-4.30329011e-21  2.57184203e-20  2.05770203e-20 -4.76021762e-21\n",
      " -2.12989491e-21 -4.14090568e-20 -1.09555590e-19  2.32343923e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "132 823\n",
      "alpha:         [-6.22229891e-23 -4.16676649e-22 -3.72933759e-22 -2.77751559e-22\n",
      " -3.18699726e-28 -2.94989873e-22 -1.28456249e-22 -1.16323547e-22\n",
      " -1.82838000e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "133 452\n",
      "alpha:         [-2.83739186e-24 -3.52880393e-24 -5.26445964e-24 -5.26925272e-25\n",
      " -5.54483659e-24 -8.93730744e-24 -5.17554730e-26 -1.74919295e-23\n",
      " -2.63297527e-24 -5.76360456e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "134 1374\n",
      "alpha:         [-2.60296764e-22 -1.33029447e-23 -2.78667472e-22 -9.76959819e-22\n",
      "  1.30449844e-22  1.21218998e-21 -3.78954458e-22 -1.19669364e-28\n",
      " -9.91063188e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "135 461\n",
      "alpha:         [-1.26832003e-22  1.23108146e-22 -2.21798057e-22  1.69698313e-24\n",
      "  7.09066539e-23 -3.56728725e-26 -6.25634272e-22  1.25526700e-22\n",
      " -4.26717876e-24]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "136 361\n",
      "alpha:         [ 5.07209325e-27  3.68510606e-27  1.95721245e-28 -2.79016150e-26\n",
      "  2.49046042e-51 -2.02985372e-26 -1.50343089e-26 -2.18796857e-27\n",
      " -4.19423935e-29 -1.22349700e-27 -7.51138021e-27]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "137 123\n",
      "alpha:         [ 6.45838811e-26  1.22548476e-24  4.66970192e-25 -4.96111157e-24\n",
      " -3.94500592e-24 -8.07686856e-25 -1.69015082e-24 -1.30151527e-24\n",
      "  2.02004877e-26 -2.34061087e-24]\n",
      "softmax alpha: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "==================================================\n",
      "138 613\n",
      "alpha:         [ 1.49328747e-59  6.93620622e-35  1.33291572e-35  3.39400774e-35\n",
      " -1.72128714e-35  1.43420529e-36  2.50108079e-37 -2.86117051e-35\n",
      "  8.40858900e-37 -3.32792232e-36 -1.41244911e-34  4.59210281e-35\n",
      " -3.26047868e-36 -2.79354922e-35  6.24235077e-42  8.70541707e-41\n",
      " -5.21908936e-35  3.87165741e-36 -2.61173469e-36  3.49523179e-35\n",
      "  1.88491077e-35  1.40116718e-35  1.57049018e-35  5.66006717e-35\n",
      "  7.89452436e-36  9.50595466e-36  4.64860173e-35 -1.77930116e-34\n",
      "  1.29419127e-35 -7.99915795e-36 -1.10488876e-59  1.91848273e-35\n",
      " -2.15307769e-35  1.57917760e-35  3.18426473e-36  5.46758774e-35\n",
      " -1.14475205e-34  9.85155444e-35 -2.47878444e-35  4.24045591e-35\n",
      " -2.16722316e-36]\n",
      "softmax alpha: [0.02439024 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024\n",
      " 0.02439024 0.02439024 0.02439024 0.02439024 0.02439024]\n",
      "==================================================\n",
      "139 616\n",
      "alpha:         [-9.52089311e-36  2.17594888e-34 -1.78833148e-35 -7.85493710e-35\n",
      " -4.08697042e-59  2.28300356e-35 -1.18489998e-36  2.72325326e-36\n",
      " -3.90709225e-35 -2.39168754e-36 -1.45214398e-35 -1.17539850e-34\n",
      "  1.90377626e-35 -9.73136862e-38 -6.83757292e-35 -5.44633293e-36\n",
      "  1.89488890e-35  2.78744984e-35 -1.56263763e-35 -1.66857177e-35\n",
      "  9.48985906e-37  7.52179701e-36 -1.40732389e-35 -9.71796819e-35\n",
      " -2.47296524e-35 -1.35465264e-35  1.88524078e-35 -7.63716183e-36\n",
      " -2.43912708e-36]\n",
      "softmax alpha: [0.03448276 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276\n",
      " 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276\n",
      " 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276\n",
      " 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276\n",
      " 0.03448276 0.03448276 0.03448276 0.03448276 0.03448276]\n",
      "==================================================\n",
      "140 631\n",
      "alpha:         [-1.33362571e-28  1.16479866e-25  9.25318517e-27  2.44235034e-26\n",
      "  6.48163319e-27  1.82674353e-27  1.16839138e-26 -1.81277011e-26\n",
      " -1.78362423e-28  1.41448307e-32  4.60263500e-26]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "141 62\n",
      "alpha:         [ 1.52435208e-26 -5.81283895e-30 -2.63396362e-26 -4.57546914e-27\n",
      " -5.26218450e-27  5.43730240e-27 -7.90584591e-28 -5.78813649e-27\n",
      " -3.09640303e-29 -4.78747607e-26  6.54406262e-27]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "142 1326\n",
      "alpha:         [-9.21654873e-35  5.74787851e-40  2.03846625e-34 -1.95563738e-33\n",
      "  1.79387944e-33  1.11875825e-33  2.93200293e-34  8.98698653e-34\n",
      "  3.89531325e-34  7.14011356e-34 -1.42070159e-33  6.84906415e-34\n",
      " -1.77336980e-34]\n",
      "softmax alpha: [0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308]\n",
      "==================================================\n",
      "143 1381\n",
      "alpha:         [ 3.42363930e-23 -3.04924155e-23  1.44383564e-21  1.14609849e-46\n",
      "  4.68885810e-23  8.92191420e-22 -4.15517515e-23 -1.66590073e-27\n",
      "  1.95766591e-22]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "144 845\n",
      "alpha:         [ 2.25539108e-20 -5.78008883e-22 -6.68387544e-44 -2.02515636e-21\n",
      " -6.23184645e-22  5.16443279e-20  4.87767553e-22  4.21676188e-19]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n",
      "145 813\n",
      "alpha:         [-7.20899939e-23 -6.66021619e-22  1.56427356e-22  1.67262105e-22\n",
      " -2.47795195e-22 -1.70317645e-22 -3.41866199e-23 -1.42235724e-21\n",
      "  9.91405272e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "146 67\n",
      "alpha:         [ 1.05072477e-26 -4.95010683e-27  5.24190663e-28  6.79331507e-27\n",
      " -4.47889697e-28 -3.65739666e-28  6.90656582e-27 -8.91197503e-28\n",
      "  1.20758434e-32  1.15418473e-26  8.29205398e-27]\n",
      "softmax alpha: [0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "==================================================\n",
      "147 1101\n",
      "alpha:         [ 2.22598147e-22  5.25118416e-23  1.53205594e-23  2.52874673e-28\n",
      " -9.92729910e-22  2.01279076e-22 -2.20397220e-22  9.19471206e-23\n",
      "  3.65760650e-24]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "148 38\n",
      "alpha:         [ 9.48652090e-23  3.06957032e-22  2.56987501e-22  5.02402252e-23\n",
      "  4.31678774e-22 -1.89364530e-22 -1.07725658e-21  1.39908672e-22\n",
      "  5.21809059e-23]\n",
      "softmax alpha: [0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111]\n",
      "==================================================\n",
      "149 1529\n",
      "alpha:         [ 3.17155269e-21  4.67700597e-21 -1.29432536e-20 -9.62576529e-20\n",
      " -2.75912023e-25 -4.43856033e-20 -9.29240949e-21 -1.59215787e-20]\n",
      "softmax alpha: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 16\n",
    "'''\n",
    "\n",
    "#with Embedding\n",
    "result = np.zeros((usr_test_amount, movie_nb))\n",
    "RS = np.zeros((usr_test_amount, movie_nb))\n",
    "#test_idx --> Test 的 index\n",
    "\n",
    "test_yes_id = []\n",
    "\n",
    "for s in range(usr_test_amount):\n",
    "    print(s, test_idx[s])\n",
    "\n",
    "    yes = []\n",
    "    sample = random.sample(train_t[test_idx[s]],len(train_t[test_idx[s]])) #從training part 的positive feedback 取出YouTuber 當成Auxilary\n",
    "    #sample=result_yes_id[now]\n",
    "    test_yes_id.append(sample)\n",
    "    alpha = np.zeros([len(sample)])\n",
    "    \n",
    "    for a in range(len(sample)):\n",
    "        r = np.max(movie_genre[sample[a]] * usr_genre_norm[test_idx[s]]) #sample a 的category vec *user_category vec\n",
    "        #print(test_idx[s])\n",
    "        #print(np.dot(Au[test_idx[s]],np.expand_dims(U[test_idx[s]],0)))\n",
    "        alpha[a] = np.dot(A1[test_idx[s]],(relu(np.dot(Au,np.expand_dims(U[test_idx[s]],0).T) +\n",
    "                                                np.dot(Ay[sample[a]],np.expand_dims(Y[sample[a]],0).T) +\n",
    "                                                np.dot(Aa,np.expand_dims(A[sample[a]],0).T) +\n",
    "                                                np.dot(Av,np.expand_dims(all_npy[sample[a]],0).T)))) * r\n",
    "    mul = np.zeros((1,latent_dim))\n",
    "    \n",
    "    print(\"{:<15}{}\".format('alpha:', alpha))\n",
    "    print(\"{:<15}{}\".format('softmax alpha:', softmax(alpha)))\n",
    "    print('==================================================')\n",
    "    \n",
    "    for i in range(len(sample)):\n",
    "        mul += softmax(alpha)[i] * A[sample[i]] #attention alpha*Ai part \n",
    "    new_mul = mul + U[test_idx[s]]  #(U+auxilary)\n",
    "    \n",
    "    for k in range(movie_nb):\n",
    "        result[s][k] = np.dot(new_mul,Y[k].T) #(U+auxilary)*photo latent factor\n",
    "        RS[s][k] = np.dot(new_mul,Y[k].T) + np.dot(B[test_idx[s]], np.dot(E, all_npy[k].T))\n",
    "        \n",
    "#print(RS[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#取出test的資料\n",
    "testRS = np.zeros((usr_test_amount, movie_test_amount)) #shape 150*20\n",
    "target = np.zeros((usr_test_amount, movie_test_amount))\n",
    "#test_t 是true的\n",
    "#test_f 是false的\n",
    "        \n",
    "for z in range(usr_test_amount):\n",
    "    user_id = test_idx[z]\n",
    "    #positive target YouTuber list\n",
    "    youtube_t = test_t[z] \n",
    "    #not target YouTuber list\n",
    "    youtube_f = test_f[z]\n",
    "    \n",
    "    #前兩個放target的RS\n",
    "    for i in range(len(youtube_t)):\n",
    "        testRS[z][i] = RS[z][youtube_t[i]]\n",
    "        target[z][i] = 1\n",
    "        \n",
    "    for i in range(len(youtube_f)):\n",
    "        testRS[z][i+len(youtube_t)] = RS[z][youtube_f[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 16) (150, 16)\n"
     ]
    }
   ],
   "source": [
    "print(target.shape, testRS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of positive data in testing: 300.0\n",
      "total testing data: 2400\n"
     ]
    }
   ],
   "source": [
    "sumtarget = 0\n",
    "for i in range(len(target)):\n",
    "    #print(np.sum(target[i]))\n",
    "    sumtarget += np.sum(target[i])\n",
    "print('num of positive data in testing:',sumtarget)\n",
    "print('total testing data:', usr_test_amount * movie_test_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN(sortlist,n):\n",
    "    topList = []\n",
    "    for i in range(n):\n",
    "        topList.append(sortlist.index(max(sortlist)))\n",
    "        #print(max(sortlist))\n",
    "        #print(sortlist.index(max(sortlist)))\n",
    "        sortlist[sortlist.index(max(sortlist))] = -1000000000\n",
    "    return topList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_0_all = []\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),int(np.sum(target[i])))\n",
    "    count_0_all.append(top_0)\n",
    "    #print(top_0)\n",
    "\n",
    "acc_0 = 0\n",
    "total = 0\n",
    "for i in range(len(count_0_all)):\n",
    "    for j in range(len(count_0_all[i])):\n",
    "        #print(int(np.sum(target[i])))\n",
    "        total+=int(np.sum(target[i]))\n",
    "        if count_0_all[i][j] < int(np.sum(target[i])): #代表是0或1 (也就是target)\n",
    "            acc_0 += 1\n",
    "avg_acc = acc_0/100\n",
    "#print('avg_accuarcy for count_0:',avg_acc)\n",
    "#print(acc_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = (2*prec*rec)/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_0 = topN(list(testRS[i]),1) #取一個\n",
    "    count_0_all.append(top_0)\n",
    "    #print(np.sum(target[i]))\n",
    "    #print(top_0)\n",
    "    if top_0[0] < int(np.sum(target[i])):\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.17333333333333334 recall  0.08666666666666667\n",
      "F1_score: 0.11555555555555556\n"
     ]
    }
   ],
   "source": [
    "top1_prec = correct/len(testRS)\n",
    "top1_recall = correct/(sumtarget)\n",
    "print('prec ',top1_prec,'recall ',top1_recall)\n",
    "print('F1_score:',F1_score(top1_prec,top1_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_3 = topN(list(testRS[i]),3) #取一個\n",
    "    count_0_all.append(top_3)\n",
    "    #print(top_3)\n",
    "    for j in range(len(top_3)):\n",
    "        if top_3[j] < int(np.sum(target[i])):\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.10444444444444445 recall  0.15666666666666668\n",
      "F1_score: 0.12533333333333332\n"
     ]
    }
   ],
   "source": [
    "top3_prec = correct/(len(testRS)*3)\n",
    "top3_recall = correct/(sumtarget)\n",
    "print('prec ',top3_prec,'recall ',top3_recall)\n",
    "print('F1_score:',F1_score(top3_prec,top3_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in range(len(testRS)):\n",
    "    top_5 = topN(list(testRS[i]),5) #取一個\n",
    "    count_0_all.append(top_5)\n",
    "    #print(top_5)\n",
    "    for j in range(len(top_5)):\n",
    "        if top_5[j] < int(np.sum(target[i])):\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec  0.07466666666666667 recall  0.18666666666666668\n",
      "F1_score: 0.10666666666666667\n"
     ]
    }
   ],
   "source": [
    "top5_prec = correct/(len(testRS)*5)\n",
    "top5_recall = correct/(sumtarget)\n",
    "print('prec ',top5_prec,'recall ',top5_recall)\n",
    "print('F1_score:',F1_score(top5_prec,top5_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "usr_test_amount = 150\n",
    "movie_test_amount = 16\n",
    "'''\n",
    "all_sort = []\n",
    "pre_matrix = np.zeros(shape=(usr_test_amount, movie_test_amount))\n",
    "for i in range(usr_test_amount):\n",
    "    top_5 = topN(list(testRS[i]),5) #取一個\n",
    "    #print(top_5)\n",
    "    all_sort.append(topN(list(testRS[i]),len(testRS[i])))\n",
    "    for j in range(len(top_5)):\n",
    "        pre_matrix[i][top_5[j]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 16) (150, 16)\n"
     ]
    }
   ],
   "source": [
    "print(pre_matrix.shape, target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDCG\n",
    "* https://daiwk.github.io/posts/nlp-ndcg.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ideal DCG，理想状况下的DCG。也就是说，相关性完全由高到低排序时算出的DCG：\n",
    "\n",
    "def IDCG(ideal_list): #ideal_list example = [1,1,1,1,1,0,0,....]\n",
    "    idcg = 0\n",
    "    for i in range(len(ideal_list)):\n",
    "        #print((2**true_list[i]-1),math.log2(i+2))\n",
    "        idcg += (2**ideal_list[i]-1)/math.log2(i+2)\n",
    "    #print('idcg',idcg)\n",
    "    return idcg\n",
    "\n",
    "def DCG(prec_list): #找出前n名的[1,1,1,0,...]\n",
    "    dcg = 0\n",
    "    for i in range(len(prec_list)):\n",
    "        dcg += (2**prec_list[i]-1)/math.log2(i+2)\n",
    "    #print('dcg',dcg)\n",
    "    return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.09484435287567075\n"
     ]
    }
   ],
   "source": [
    "total_ndcg = 0\n",
    "num_ndcg = 5\n",
    "for m in range(usr_test_amount):\n",
    "    idcg = IDCG([1]*num_ndcg)\n",
    "    pre_list = []\n",
    "    for s in all_sort[m][:num_ndcg]:\n",
    "        #print(s)\n",
    "        #print(target[m][s])\n",
    "        pre_list.append(target[m][s])\n",
    "    dcg = DCG(pre_list)\n",
    "    ndcg = dcg/idcg\n",
    "    #print(ndcg)\n",
    "    total_ndcg += ndcg\n",
    "avg_ndcg = total_ndcg/usr_test_amount\n",
    "print('NDCG:',avg_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.1536666666666667\n"
     ]
    }
   ],
   "source": [
    "total_prec = 0\n",
    "for u in range(usr_test_amount):\n",
    "    y_true = target[u]\n",
    "    y_scores = pre_matrix[u]\n",
    "    total_prec += average_precision_score(y_true, y_scores)\n",
    "    \n",
    "MAP = total_prec/usr_test_amount\n",
    "\n",
    "print('MAP:', MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
