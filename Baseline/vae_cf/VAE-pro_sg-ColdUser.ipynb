{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders for collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
    "\n",
    "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
    "DATA_DIR = './'\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg_colduser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective for Multi-DAE for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
    "$$\n",
    "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiVAE(MultiDAE):\n",
    "\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "\n",
    "        # placeholders with default values when scoring\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        \n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # q-network\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "\n",
    "        sampled_z = mu_q + self.is_training_ph *\\\n",
    "            epsilon * std_q\n",
    "\n",
    "        # p-network\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        \n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        \n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                # we need two sets of parameters for mean and variance,\n",
    "                # respectively\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            \n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n"
     ]
    }
   ],
   "source": [
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
    "                                           os.path.join(pro_dir, 'validation_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 159)\n",
      "(20, 159) (20, 159)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(vad_data_tr.shape, vad_data_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "# training batch size\n",
    "batch_size = 500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = range(N_vad)\n",
    "\n",
    "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
    "batch_size_vad = 50 #MRM=50 # 2000\n",
    "\n",
    "# the total number of gradient updates for annealing\n",
    "total_anneal_steps = 200000\n",
    "# largest annealing parameter\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0] # 150\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "    recall = tmp / X_true_binary.sum(axis=1)\n",
    "    rec = np.sum(tmp) / np.sum(X_true_binary.sum(axis=1))\n",
    "    return recall, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prec_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "#     prec = tmp / np.minimum(k, X_pred_binary.sum(axis=1))\n",
    "    prec = np.sum(tmp) / (batch_users * k)\n",
    "    return prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(X_pred,heldout_batch):\n",
    "    X_pred[X_pred == -np.inf] = -9999999999\n",
    "    batch_users = X_pred.shape[0]\n",
    "    X_true_binary = heldout_batch.toarray()\n",
    "    \n",
    "    total_prec = 0\n",
    "    for u in range(batch_users):\n",
    "        y_true = X_true_binary[u]\n",
    "        y_scores = X_pred[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/batch_users\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-VAE^{PR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_dims = [200, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-881e9e51e708>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory\n",
    "\n",
    "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
    "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: ./volmount/log/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "log_dir = './volmount/log/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = './volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            \n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, \n",
    "                                           global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr, test_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'test_tr.csv'),\n",
    "    os.path.join(pro_dir, 'test_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)\n",
    "\n",
    "batch_size_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "#     int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "# print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I/model\n",
      "0 - 100\n",
      "X.shape: (100, 159)\n",
      "pred_val.shape: (100, 159)\n"
     ]
    }
   ],
   "source": [
    "n10_list = []\n",
    "r1_list, r5_list = [], []\n",
    "# p1_list, p5_list = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        print(st_idx, '-', end_idx)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "        print('X.shape:', X.shape) #(150, 165)\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        print('pred_val.shape:', pred_val.shape) #(150, 165)\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        \n",
    "        n10_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=10))\n",
    "        MAP = MAP(pred_val, test_data_te[idxlist_test[st_idx:end_idx]])\n",
    "\n",
    "#         p1_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        p1 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "#         r1_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        recall, rec_1 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "        r1_list.append(recall)\n",
    "        \n",
    "#         p5_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        p5 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "#         r5_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        recall, rec_5 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "        r5_list.append(recall)\n",
    "\n",
    "n10_list = np.concatenate(n10_list)\n",
    "\n",
    "# p1_list = np.concatenate(p1_list)\n",
    "r1_list = np.concatenate(r1_list)\n",
    "\n",
    "# p5_list = np.concatenate(p5_list)\n",
    "r5_list = np.concatenate(r5_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@10=0.14718739882400464\n",
      "Test MAP=0.1517017160918743\n",
      "Test Prec@1=0.14\n",
      "Recall: 0.018134715025906734\n",
      "F1@1 0.03211009174311926\n",
      "Test Prec@5=0.134\n",
      "Recall: 0.08678756476683938\n",
      "F1@5 0.10534591194968554\n"
     ]
    }
   ],
   "source": [
    "# print(\"Test NDCG@10=%f (%f)\" % (np.mean(n10_list), np.std(n10_list) / np.sqrt(len(n10_list))))\n",
    "print(\"Test NDCG@10={}\".format(np.mean(n10_list)))\n",
    "print(\"Test MAP={}\".format(MAP))\n",
    "# print(\"Test Prec@1=%f (%f)\" % (np.mean(p1_list), np.std(p1_list) / np.sqrt(len(p1_list))))\n",
    "print(\"Test Prec@1={}\".format(p1))\n",
    "# print(\"Test Recall@1=%f (%f)\" % (np.mean(r1_list), np.std(r1_list) / np.sqrt(len(r1_list))))\n",
    "# print(\"Test Recall@1={}\".format(np.mean(r1_list)))\n",
    "# print('F1@1', F1_score(p1, np.mean(r1_list)))\n",
    "\n",
    "print('Recall:', rec_1)\n",
    "print('F1@1', F1_score(p1, rec_1))\n",
    "\n",
    "# print(\"Test Prec@5=%f (%f)\" % (np.mean(p5_list), np.std(p5_list) / np.sqrt(len(p5_list))))\n",
    "print(\"Test Prec@5={}\".format(p5))\n",
    "# print(\"Test Recall@5=%f (%f)\" % (np.mean(r5_list), np.std(r5_list) / np.sqrt(len(r5_list))))\n",
    "# print(\"Test Recall@5={}\".format(np.mean(r5_list)))\n",
    "# print('F1@1', F1_score(p5, np.mean(r5_list)))\n",
    "print('Recall:', rec_5)\n",
    "print('F1@5', F1_score(p5, rec_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "def MAP(X_pred,heldout_batch, test_num = 32):\n",
    "    movie_num = X_pred.shape[1] # 165\n",
    "    print('Oringinal movie num:', movie_num)\n",
    "    movie_idx = [i for i in range(movie_num)]\n",
    "    \n",
    "    X_pred[X_pred == -np.inf] = -9999999999\n",
    "    batch_users = X_pred.shape[0] # 150\n",
    "    print('Oringinal user num:', batch_users)\n",
    "    \n",
    "    X_true_binary = heldout_batch.toarray()\n",
    "    \n",
    "    total_prec = 0\n",
    "    for u in range(batch_users):\n",
    "#         idx = random.sample([i for i in range(movie_num)], test_num)\n",
    "        y_true = X_true_binary[u]\n",
    "        half = int(sum(y_true)/2)\n",
    "        idx = random.sample(list(np.nonzero(y_true == 1)[0]), half)\n",
    "        if len(idx) != half:\n",
    "            print('Error!!!')\n",
    "            break\n",
    "        \n",
    "        if len(idx) < test_num:\n",
    "            rest = test_num - len(idx)\n",
    "            others = random.sample([i for i in movie_idx if not i in idx], rest)\n",
    "            idx.extend(others)\n",
    "        else:\n",
    "            idx = random.sample(idx, test_num)\n",
    "            \n",
    "        if not len(idx) == test_num:\n",
    "            print('Error!!!')\n",
    "            break\n",
    "            \n",
    "#         print(y_true.shape)\n",
    "        y_true = y_true[idx]\n",
    "#         print(y_true.shape)\n",
    "        y_scores = X_pred[u][idx]\n",
    "#         print(y_scores.shape)\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/batch_users\n",
    "    \n",
    "    return Map_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
