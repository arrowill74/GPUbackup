{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders for collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
    "\n",
    "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
    "DATA_DIR = './'\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective for Multi-DAE for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
    "$$\n",
    "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiVAE(MultiDAE):\n",
    "\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "\n",
    "        # placeholders with default values when scoring\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        \n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # q-network\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "\n",
    "        sampled_z = mu_q + self.is_training_ph *\\\n",
    "            epsilon * std_q\n",
    "\n",
    "        # p-network\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        \n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        \n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                # we need two sets of parameters for mean and variance,\n",
    "                # respectively\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            \n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
    "                                           os.path.join(pro_dir, 'validation_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1282, 165)\n",
      "(150, 165) (150, 165)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(vad_data_tr.shape, vad_data_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "# training batch size\n",
    "batch_size = 500 #coldstart=25 #MRM=500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = range(N_vad)\n",
    "\n",
    "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
    "batch_size_vad = 50 #coldstart=25 #MRM=50 # 2000\n",
    "\n",
    "# the total number of gradient updates for annealing\n",
    "total_anneal_steps = 200000\n",
    "# largest annealing parameter\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100): #coldstart=10 #MRM=100\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0] # 150\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "    recall = tmp / X_true_binary.sum(axis=1)\n",
    "    rec = np.sum(tmp) / np.sum(X_true_binary.sum(axis=1))\n",
    "    return recall, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prec_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "#     prec = tmp / np.minimum(k, X_pred_binary.sum(axis=1))\n",
    "    prec = np.sum(tmp) / (batch_users * k)\n",
    "    return prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(X_pred,heldout_batch):\n",
    "    X_pred[X_pred == -np.inf] = -9999999999\n",
    "    batch_users = X_pred.shape[0]\n",
    "    X_true_binary = heldout_batch.toarray()\n",
    "    \n",
    "    total_prec = 0\n",
    "    for u in range(batch_users):\n",
    "        y_true = X_true_binary[u]\n",
    "        y_scores = X_pred[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/batch_users\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-VAE^{PR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_dims = [200, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-31-881e9e51e708>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory\n",
    "\n",
    "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
    "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: ./volmount/log/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "log_dir = './volmount/log/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = './volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            \n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, \n",
    "                                           global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@10\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr, test_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'test_tr.csv'),\n",
    "    os.path.join(pro_dir, 'test_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)\n",
    "\n",
    "batch_size_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "#     int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "# print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I/model\n"
     ]
    }
   ],
   "source": [
    "n10_list = []\n",
    "r1_list, r5_list = [], []\n",
    "# p1_list, p5_list = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        \n",
    "        n10_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=10))\n",
    "        MAP = MAP(pred_val, test_data_te[idxlist_test[st_idx:end_idx]])\n",
    "\n",
    "#         p1_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        p1 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "#         r1_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        recall, rec_1 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "        r1_list.append(recall)\n",
    "        \n",
    "#         p5_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        p5 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "#         r5_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        recall, rec_5 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "        r5_list.append(recall)\n",
    "\n",
    "n10_list = np.concatenate(n10_list)\n",
    "\n",
    "# p1_list = np.concatenate(p1_list)\n",
    "r1_list = np.concatenate(r1_list)\n",
    "\n",
    "# p5_list = np.concatenate(p5_list)\n",
    "r5_list = np.concatenate(r5_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@10=0.44869246417310205\n",
      "Test MAP=0.3963166139668619\n",
      "Test Prec@1=0.52\n",
      "Recall: 0.0312625250501002\n",
      "F1@1 0.058979206049149344\n",
      "Test Prec@5=0.4746666666666667\n",
      "Recall: 0.14268537074148296\n",
      "F1@5 0.21941448382126352\n"
     ]
    }
   ],
   "source": [
    "# print(\"Test NDCG@10=%f (%f)\" % (np.mean(n10_list), np.std(n10_list) / np.sqrt(len(n10_list))))\n",
    "print(\"Test NDCG@10={}\".format(np.mean(n10_list)))\n",
    "print(\"Test MAP={}\".format(MAP))\n",
    "# print(\"Test Prec@1=%f (%f)\" % (np.mean(p1_list), np.std(p1_list) / np.sqrt(len(p1_list))))\n",
    "print(\"Test Prec@1={}\".format(p1))\n",
    "# print(\"Test Recall@1=%f (%f)\" % (np.mean(r1_list), np.std(r1_list) / np.sqrt(len(r1_list))))\n",
    "# print(\"Test Recall@1={}\".format(np.mean(r1_list)))\n",
    "# print('F1@1', F1_score(p1, np.mean(r1_list)))\n",
    "\n",
    "print('Recall:', rec_1)\n",
    "print('F1@1', F1_score(p1, rec_1))\n",
    "\n",
    "# print(\"Test Prec@5=%f (%f)\" % (np.mean(p5_list), np.std(p5_list) / np.sqrt(len(p5_list))))\n",
    "print(\"Test Prec@5={}\".format(p5))\n",
    "# print(\"Test Recall@5=%f (%f)\" % (np.mean(r5_list), np.std(r5_list) / np.sqrt(len(r5_list))))\n",
    "# print(\"Test Recall@5={}\".format(np.mean(r5_list)))\n",
    "# print('F1@1', F1_score(p5, np.mean(r5_list)))\n",
    "print('Recall:', rec_5)\n",
    "print('F1@5', F1_score(p5, rec_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
