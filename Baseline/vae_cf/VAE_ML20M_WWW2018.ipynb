{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders for collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
    "\n",
    "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
    "DATA_DIR = './'\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data and create train/validation/test splits following strong generalization: \n",
    "\n",
    "- We split all users into training/validation/test sets. \n",
    "\n",
    "- We train models using the entire click history of the training users. \n",
    "\n",
    "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv(os.path.join('../../User/output/', 'UserFollowingsMat.csv'))\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data.rename(columns={'Unnamed: 0':'userId'}, inplace=True)\n",
    "# raw_data = raw_data.set_index('userId')\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['userId', 'movieId'])\n",
    "# for uid, row in raw_data.iterrows():\n",
    "#     for movie in row[row == 1].index:\n",
    "#         df = df.append({'userId': uid, 'movieId': movie}, ignore_index = True)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('../UserFollowingRecord.csv', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../UserFollowingRecord.csv')\n",
    "raw_data = df\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
    "- Use all the items from the training users as item set\n",
    "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep items that are clicked on by at least 5 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create train/validation/test users\n",
    "n_users = unique_uid.size\n",
    "n_heldout_users = 150\n",
    "\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)] # -1282\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)] # 1282-1432\n",
    "te_users = unique_uid[(n_users - n_heldout_users):] # 1432- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_sid = pd.unique(raw_data['movieId']) #train_plays['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective for Multi-DAE for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
    "$$\n",
    "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiVAE(MultiDAE):\n",
    "\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "\n",
    "        # placeholders with default values when scoring\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        \n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # q-network\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "\n",
    "        sampled_z = mu_q + self.is_training_ph *\\\n",
    "            epsilon * std_q\n",
    "\n",
    "        # p-network\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        \n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        \n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                # we need two sets of parameters for mean and variance,\n",
    "                # respectively\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            \n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
    "                                           os.path.join(pro_dir, 'validation_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1282, 165)\n",
      "(150, 165) (150, 165)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(vad_data_tr.shape, vad_data_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "# training batch size\n",
    "batch_size = 500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = range(N_vad)\n",
    "\n",
    "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
    "batch_size_vad = 50 # 2000\n",
    "\n",
    "# the total number of gradient updates for annealing\n",
    "total_anneal_steps = 200000\n",
    "# largest annealing parameter\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=10):\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prec_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "    prec = tmp / np.minimum(k, X_pred_binary.sum(axis=1))\n",
    "    return prec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-VAE^{PR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_dims = [200, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-881e9e51e708>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory\n",
    "\n",
    "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
    "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: ./volmount/log/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "log_dir = './volmount/log/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = './volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            \n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, \n",
    "                                           global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@10\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr, test_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'test_tr.csv'),\n",
    "    os.path.join(pro_dir, 'test_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)\n",
    "\n",
    "batch_size_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "#     int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "# print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I/model\n"
     ]
    }
   ],
   "source": [
    "n10_list, r1_list, r5_list = [], [], []\n",
    "p1_list, p5_list = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        n10_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=10))\n",
    "        \n",
    "        p1_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        r1_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        \n",
    "        p5_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        r5_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "    \n",
    "n10_list = np.concatenate(n10_list)\n",
    "\n",
    "p1_list = np.concatenate(p1_list)\n",
    "r1_list = np.concatenate(r1_list)\n",
    "\n",
    "p5_list = np.concatenate(p5_list)\n",
    "r5_list = np.concatenate(r5_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@10=0.26551 (0.02034)\n",
      "Test Prec@1=0.14000 (0.02833)\n",
      "Test Recall@1=0.14000 (0.02833)\n",
      "Test Prec@5=0.12000 (0.01116)\n",
      "Test Recall@5=0.24733 (0.02390)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test NDCG@10=%.5f (%.5f)\" % (np.mean(n10_list), np.std(n10_list) / np.sqrt(len(n10_list))))\n",
    "\n",
    "print(\"Test Prec@1=%.5f (%.5f)\" % (np.mean(p1_list), np.std(p1_list) / np.sqrt(len(p1_list))))\n",
    "print(\"Test Recall@1=%.5f (%.5f)\" % (np.mean(r1_list), np.std(r1_list) / np.sqrt(len(r1_list))))\n",
    "\n",
    "print(\"Test Prec@5=%.5f (%.5f)\" % (np.mean(p5_list), np.std(p5_list) / np.sqrt(len(p5_list))))\n",
    "print(\"Test Recall@5=%.5f (%.5f)\" % (np.mean(r5_list), np.std(r5_list) / np.sqrt(len(r5_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1@1 0.14\n",
      "F1@5 0.16159709618874774\n"
     ]
    }
   ],
   "source": [
    "print('F1@1', F1_score(np.mean(p1_list), np.mean(r1_list)))\n",
    "print('F1@5', F1_score(np.mean(p5_list), np.mean(r5_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-DAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> n_items] MLP, thus the overall architecture for the Multi-DAE is [n_items -> 200 -> n_items]. We find this architecture achieves better validation NDCG@100 than the [n_items -> 600 -> 200 -> 600 -> n_items] architecture as used in Multi-VAE^{PR}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_dims = [200, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dae = MultiDAE(p_dims, lam=0.01 / batch_size, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = dae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in dae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_dir = './volmount/log/ml-20m/DAE/{}'.format(arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chkpt_dir = './volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            feed_dict = {dae.input_ph: X, \n",
    "                         dae.keep_prob_ph: 0.5}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, global_step=epoch * batches_per_epoch + bnum) \n",
    "                    \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@10\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dae = MultiDAE(p_dims, lam=0.01 / batch_size)\n",
    "saver, logits_var, _, _, _ = dae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chkpt_dir = '/volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
    "# print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n100_list, r20_list, r50_list = [], [], []\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "    \n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=10))\n",
    "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "\n",
    "n100_list = np.concatenate(n100_list)\n",
    "r20_list = np.concatenate(r20_list)\n",
    "r50_list = np.concatenate(r50_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Test NDCG@10=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
    "print(\"Test Recall@1=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
    "print(\"Test Recall@5=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
