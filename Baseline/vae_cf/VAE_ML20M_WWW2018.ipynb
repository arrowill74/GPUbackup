{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders for collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
    "\n",
    "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
    "DATA_DIR = './'\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data and create train/validation/test splits following strong generalization: \n",
    "\n",
    "- We split all users into training/validation/test sets. \n",
    "\n",
    "- We train models using the entire click history of the training users. \n",
    "\n",
    "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv(os.path.join('../../User/output/', 'UserFollowingsMat.csv'))\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data.rename(columns={'Unnamed: 0':'userId'}, inplace=True)\n",
    "# raw_data = raw_data.set_index('userId')\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['userId', 'movieId'])\n",
    "# for uid, row in raw_data.iterrows():\n",
    "#     for movie in row[row == 1].index:\n",
    "#         df = df.append({'userId': uid, 'movieId': movie}, ignore_index = True)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('../UserFollowingRecord.csv', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../UserFollowingRecord.csv')\n",
    "raw_data = df\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
    "- Use all the items from the training users as item set\n",
    "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep items that are clicked on by at least 5 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create train/validation/test users\n",
    "n_users = unique_uid.size\n",
    "n_heldout_users = 150\n",
    "\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)] # -1282\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)] # 1282-1432\n",
    "te_users = unique_uid[(n_users - n_heldout_users):] # 1432- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_sid = pd.unique(raw_data['movieId']) #train_plays['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective for Multi-DAE for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
    "$$\n",
    "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiVAE(MultiDAE):\n",
    "\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "\n",
    "        # placeholders with default values when scoring\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        \n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # q-network\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "\n",
    "        sampled_z = mu_q + self.is_training_ph *\\\n",
    "            epsilon * std_q\n",
    "\n",
    "        # p-network\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        \n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        \n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                # we need two sets of parameters for mean and variance,\n",
    "                # respectively\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            \n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
    "                                           os.path.join(pro_dir, 'validation_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1282, 165)\n",
      "(150, 165) (150, 165)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(vad_data_tr.shape, vad_data_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "# training batch size\n",
    "batch_size = 500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = range(N_vad)\n",
    "\n",
    "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
    "batch_size_vad = 50 # 2000\n",
    "\n",
    "# the total number of gradient updates for annealing\n",
    "total_anneal_steps = 200000\n",
    "# largest annealing parameter\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=10):\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prec_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "    prec = tmp / np.minimum(k, X_pred_binary.sum(axis=1))\n",
    "    return prec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-VAE^{PR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_dims = [200, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-881e9e51e708>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory\n",
    "\n",
    "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
    "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: ./volmount/log/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "log_dir = './volmount/log/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = './volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            \n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, \n",
    "                                           global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@10\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr, test_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'test_tr.csv'),\n",
    "    os.path.join(pro_dir, 'test_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)\n",
    "\n",
    "batch_size_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "#     int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "# print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I/model\n"
     ]
    }
   ],
   "source": [
    "n10_list, r1_list, r5_list = [], [], []\n",
    "p1_list, p5_list = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        n10_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=10))\n",
    "        \n",
    "        p1_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        r1_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        \n",
    "        p5_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        r5_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "    \n",
    "n10_list = np.concatenate(n10_list)\n",
    "\n",
    "p1_list = np.concatenate(p1_list)\n",
    "r1_list = np.concatenate(r1_list)\n",
    "\n",
    "p5_list = np.concatenate(p5_list)\n",
    "r5_list = np.concatenate(r5_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@10=0.24499 (0.02154)\n",
      "Test Prec@1=0.16667 (0.03043)\n",
      "Test Recall@1=0.16667 (0.03043)\n",
      "Test Prec@5=0.11067 (0.01186)\n",
      "Test Recall@5=0.21967 (0.02369)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test NDCG@10=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
    "\n",
    "print(\"Test Prec@1=%.5f (%.5f)\" % (np.mean(p1_list), np.std(p1_list) / np.sqrt(len(p1_list))))\n",
    "print(\"Test Recall@1=%.5f (%.5f)\" % (np.mean(r1_list), np.std(r1_list) / np.sqrt(len(r1_list))))\n",
    "\n",
    "print(\"Test Prec@5=%.5f (%.5f)\" % (np.mean(p5_list), np.std(p5_list) / np.sqrt(len(p5_list))))\n",
    "print(\"Test Recall@5=%.5f (%.5f)\" % (np.mean(r5_list), np.std(r5_list) / np.sqrt(len(r5_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1@1 0.16666666666666666\n",
      "F1@5 0.1471833165153044\n"
     ]
    }
   ],
   "source": [
    "print('F1@1', F1_score(np.mean(p1_list), np.mean(r1_list)))\n",
    "print('F1@5', F1_score(np.mean(p5_list), np.mean(r5_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-DAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> n_items] MLP, thus the overall architecture for the Multi-DAE is [n_items -> 200 -> n_items]. We find this architecture achieves better validation NDCG@100 than the [n_items -> 600 -> 200 -> 600 -> n_items] architecture as used in Multi-VAE^{PR}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_dims = [200, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dae = MultiDAE(p_dims, lam=0.01 / batch_size, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = dae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in dae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_dir = './volmount/log/ml-20m/DAE/{}'.format(arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chkpt_dir = './volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            feed_dict = {dae.input_ph: X, \n",
    "                         dae.keep_prob_ph: 0.5}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, global_step=epoch * batches_per_epoch + bnum) \n",
    "                    \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@10\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dae = MultiDAE(p_dims, lam=0.01 / batch_size)\n",
    "saver, logits_var, _, _, _ = dae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chkpt_dir = '/volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
    "# print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n100_list, r20_list, r50_list = [], [], []\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "    \n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=10))\n",
    "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "\n",
    "n100_list = np.concatenate(n100_list)\n",
    "r20_list = np.concatenate(r20_list)\n",
    "r50_list = np.concatenate(r50_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Test NDCG@10=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
    "print(\"Test Recall@1=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
    "print(\"Test Recall@5=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
