{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders for collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
    "\n",
    "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
    "DATA_DIR = './'\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data and create train/validation/test splits following strong generalization: \n",
    "\n",
    "- We split all users into training/validation/test sets. \n",
    "\n",
    "- We train models using the entire click history of the training users. \n",
    "\n",
    "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv(os.path.join('../../User/output/', 'UserFollowingsMat.csv'))\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data.rename(columns={'Unnamed: 0':'userId'}, inplace=True)\n",
    "# raw_data = raw_data.set_index('userId')\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['userId', 'movieId'])\n",
    "# for uid, row in raw_data.iterrows():\n",
    "#     for movie in row[row == 1].index:\n",
    "#         df = df.append({'userId': uid, 'movieId': movie}, ignore_index = True)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('../UserFollowingRecord.csv', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22893</td>\n",
       "      <td>abeautifuldaymovie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22893</td>\n",
       "      <td>captivestatemovie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22893</td>\n",
       "      <td>coldpursuitmovie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22893</td>\n",
       "      <td>currentwarmovie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22893</td>\n",
       "      <td>fordvferrari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23441</th>\n",
       "      <td>24337372261</td>\n",
       "      <td>knivesout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23442</th>\n",
       "      <td>24337372261</td>\n",
       "      <td>lighthousemovie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23443</th>\n",
       "      <td>24337372261</td>\n",
       "      <td>starwars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23444</th>\n",
       "      <td>24337372261</td>\n",
       "      <td>theirishmanfilm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23445</th>\n",
       "      <td>24337372261</td>\n",
       "      <td>uncutgems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23446 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            userId             movieId\n",
       "0            22893  abeautifuldaymovie\n",
       "1            22893   captivestatemovie\n",
       "2            22893    coldpursuitmovie\n",
       "3            22893     currentwarmovie\n",
       "4            22893        fordvferrari\n",
       "...            ...                 ...\n",
       "23441  24337372261           knivesout\n",
       "23442  24337372261     lighthousemovie\n",
       "23443  24337372261            starwars\n",
       "23444  24337372261     theirishmanfilm\n",
       "23445  24337372261           uncutgems\n",
       "\n",
       "[23446 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../UserFollowingRecord.csv')\n",
    "raw_data = df\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
    "- Use all the items from the training users as item set\n",
    "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep items that are clicked on by at least 5 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create train/validation/test users\n",
    "n_users = unique_uid.size\n",
    "n_heldout_users = 150\n",
    "\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)] # -1282\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)] # 1282-1432\n",
    "te_users = unique_uid[(n_users - n_heldout_users):] # 1432- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_sid = pd.unique(raw_data['movieId']) #train_plays['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective for Multi-DAE for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
    "$$\n",
    "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiVAE(MultiDAE):\n",
    "\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "\n",
    "        # placeholders with default values when scoring\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        \n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # q-network\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "\n",
    "        sampled_z = mu_q + self.is_training_ph *\\\n",
    "            epsilon * std_q\n",
    "\n",
    "        # p-network\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        \n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        \n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                # we need two sets of parameters for mean and variance,\n",
    "                # respectively\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            \n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
    "                                           os.path.join(pro_dir, 'validation_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1282, 165)\n",
      "(150, 165) (150, 165)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(vad_data_tr.shape, vad_data_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "# training batch size\n",
    "batch_size = 500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = range(N_vad)\n",
    "\n",
    "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
    "batch_size_vad = 50 # 2000\n",
    "\n",
    "# the total number of gradient updates for annealing\n",
    "total_anneal_steps = 200000\n",
    "# largest annealing parameter\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=10):\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0] # 150\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "    recall = tmp / X_true_binary.sum(axis=1)\n",
    "    rec = np.sum(tmp) / np.sum(X_true_binary.sum(axis=1))\n",
    "    return recall, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prec_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "#     prec = tmp / np.minimum(k, X_pred_binary.sum(axis=1))\n",
    "    prec = np.sum(tmp) / (batch_users * k)\n",
    "    return prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(X_pred,heldout_batch):\n",
    "    X_pred[X_pred == -np.inf] = -9999999999\n",
    "    batch_users = X_pred.shape[0]\n",
    "    X_true_binary = heldout_batch.toarray()\n",
    "    \n",
    "    total_prec = 0\n",
    "    for u in range(batch_users):\n",
    "        y_true = X_true_binary[u]\n",
    "        y_scores = X_pred[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/batch_users\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-VAE^{PR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_dims = [200, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-5-881e9e51e708>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory\n",
    "\n",
    "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
    "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: ./volmount/log/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "log_dir = './volmount/log/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = './volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            \n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, \n",
    "                                           global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@10\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr, test_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'test_tr.csv'),\n",
    "    os.path.join(pro_dir, 'test_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)\n",
    "\n",
    "batch_size_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "#     int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "# print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I/model\n"
     ]
    }
   ],
   "source": [
    "n10_list = []\n",
    "r1_list, r5_list = [], []\n",
    "# p1_list, p5_list = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        \n",
    "        n10_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=10))\n",
    "        MAP = MAP(pred_val, test_data_te[idxlist_test[st_idx:end_idx]])\n",
    "\n",
    "#         p1_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        p1 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "#         r1_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        recall, rec_1 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "        r1_list.append(recall)\n",
    "        \n",
    "#         p5_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        p5 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "#         r5_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        recall, rec_5 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "        r5_list.append(recall)\n",
    "\n",
    "n10_list = np.concatenate(n10_list)\n",
    "\n",
    "# p1_list = np.concatenate(p1_list)\n",
    "r1_list = np.concatenate(r1_list)\n",
    "\n",
    "# p5_list = np.concatenate(p5_list)\n",
    "r5_list = np.concatenate(r5_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@10=0.23757256908577867\n",
      "Test MAP=0.19684936565225292\n",
      "Test Prec@1=0.15333333333333332\n",
      "Recall: 0.06149732620320856\n",
      "F1@1 0.08778625954198474\n",
      "Test Prec@5=0.10933333333333334\n",
      "Recall: 0.2192513368983957\n",
      "F1@5 0.14590747330960854\n"
     ]
    }
   ],
   "source": [
    "# print(\"Test NDCG@10=%f (%f)\" % (np.mean(n10_list), np.std(n10_list) / np.sqrt(len(n10_list))))\n",
    "print(\"Test NDCG@10={}\".format(np.mean(n10_list)))\n",
    "print(\"Test MAP={}\".format(MAP))\n",
    "# print(\"Test Prec@1=%f (%f)\" % (np.mean(p1_list), np.std(p1_list) / np.sqrt(len(p1_list))))\n",
    "print(\"Test Prec@1={}\".format(p1))\n",
    "# print(\"Test Recall@1=%f (%f)\" % (np.mean(r1_list), np.std(r1_list) / np.sqrt(len(r1_list))))\n",
    "# print(\"Test Recall@1={}\".format(np.mean(r1_list)))\n",
    "# print('F1@1', F1_score(p1, np.mean(r1_list)))\n",
    "\n",
    "print('Recall:', rec_1)\n",
    "print('F1@1', F1_score(p1, rec_1))\n",
    "\n",
    "# print(\"Test Prec@5=%f (%f)\" % (np.mean(p5_list), np.std(p5_list) / np.sqrt(len(p5_list))))\n",
    "print(\"Test Prec@5={}\".format(p5))\n",
    "# print(\"Test Recall@5=%f (%f)\" % (np.mean(r5_list), np.std(r5_list) / np.sqrt(len(r5_list))))\n",
    "# print(\"Test Recall@5={}\".format(np.mean(r5_list)))\n",
    "# print('F1@1', F1_score(p5, np.mean(r5_list)))\n",
    "print('Recall:', rec_5)\n",
    "print('F1@5', F1_score(p5, rec_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-DAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> n_items] MLP, thus the overall architecture for the Multi-DAE is [n_items -> 200 -> n_items]. We find this architecture achieves better validation NDCG@100 than the [n_items -> 600 -> 200 -> 600 -> n_items] architecture as used in Multi-VAE^{PR}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_dims = [200, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dae = MultiDAE(p_dims, lam=0.01 / batch_size, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = dae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in dae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_dir = './volmount/log/ml-20m/DAE/{}'.format(arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chkpt_dir = './volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            feed_dict = {dae.input_ph: X, \n",
    "                         dae.keep_prob_ph: 0.5}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, global_step=epoch * batches_per_epoch + bnum) \n",
    "                    \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@10\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dae = MultiDAE(p_dims, lam=0.01 / batch_size)\n",
    "saver, logits_var, _, _, _ = dae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chkpt_dir = '/volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
    "# print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n100_list, r20_list, r50_list = [], [], []\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "    \n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=10))\n",
    "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "\n",
    "n100_list = np.concatenate(n100_list)\n",
    "r20_list = np.concatenate(r20_list)\n",
    "r50_list = np.concatenate(r50_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Test NDCG@10=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
    "print(\"Test Recall@1=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
    "print(\"Test Recall@5=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
