{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders for collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
    "\n",
    "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
    "DATA_DIR = './'\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data and create train/validation/test splits following strong generalization: \n",
    "\n",
    "- We split all users into training/validation/test sets. \n",
    "\n",
    "- We train models using the entire click history of the training users. \n",
    "\n",
    "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv(os.path.join('../../User/output/', 'UserFollowingsMat.csv'))\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data.rename(columns={'Unnamed: 0':'userId'}, inplace=True)\n",
    "# raw_data = raw_data.set_index('userId')\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['userId', 'movieId'])\n",
    "# for uid, row in raw_data.iterrows():\n",
    "#     for movie in row[row == 1].index:\n",
    "#         df = df.append({'userId': uid, 'movieId': movie}, ignore_index = True)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('../UserFollowingRecord.csv', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23441</th>\n",
       "      <td>1581</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23442</th>\n",
       "      <td>1581</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23443</th>\n",
       "      <td>1581</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23444</th>\n",
       "      <td>1581</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23445</th>\n",
       "      <td>1581</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23446 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId\n",
       "0           0        2\n",
       "1           0       31\n",
       "2           0       36\n",
       "3           0       38\n",
       "4           0       55\n",
       "...       ...      ...\n",
       "23441    1581       86\n",
       "23442    1581       91\n",
       "23443    1581      129\n",
       "23444    1581      142\n",
       "23445    1581      154\n",
       "\n",
       "[23446 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(pro_dir, 'UserFollowingRecord.csv'))\n",
    "raw_data = df\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
    "- Use all the items from the training users as item set\n",
    "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep items that are clicked on by at least 5 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 23446 watching events from 1582 users and 165 movies (sparsity: 8.982%)\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1582,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_uid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create train/validation/test users\n",
    "n_users = unique_uid.size\n",
    "n_heldout_users = 150 #coldstart=25 #MRM=150\n",
    "\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)] # -1282\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)] # 1282-1432\n",
    "te_users = unique_uid[(n_users - n_heldout_users):] # 1432- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_sid = pd.unique(raw_data['movieId']) #train_plays['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "100 users sampled\n"
     ]
    }
   ],
   "source": [
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "100 users sampled\n"
     ]
    }
   ],
   "source": [
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective for Multi-DAE for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
    "$$\n",
    "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiVAE(MultiDAE):\n",
    "\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "\n",
    "        # placeholders with default values when scoring\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        \n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # q-network\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "\n",
    "        sampled_z = mu_q + self.is_training_ph *\\\n",
    "            epsilon * std_q\n",
    "\n",
    "        # p-network\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        \n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        \n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                # we need two sets of parameters for mean and variance,\n",
    "                # respectively\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            \n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
    "                                           os.path.join(pro_dir, 'validation_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1282, 165)\n",
      "(150, 165) (150, 165)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(vad_data_tr.shape, vad_data_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "# training batch size\n",
    "batch_size = 500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = range(N_vad)\n",
    "\n",
    "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
    "batch_size_vad = 50 # 2000\n",
    "\n",
    "# the total number of gradient updates for annealing\n",
    "total_anneal_steps = 200000\n",
    "# largest annealing parameter\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100): #coldstart=10 #MRM=100\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0] # 150\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "    recall = tmp / X_true_binary.sum(axis=1)\n",
    "    rec = np.sum(tmp) / np.sum(X_true_binary.sum(axis=1))\n",
    "    return recall, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prec_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "#     prec = tmp / np.minimum(k, X_pred_binary.sum(axis=1))\n",
    "    prec = np.sum(tmp) / (batch_users * k)\n",
    "    return prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(X_pred,heldout_batch):\n",
    "    X_pred[X_pred == -np.inf] = -9999999999\n",
    "    batch_users = X_pred.shape[0]\n",
    "    X_true_binary = heldout_batch.toarray()\n",
    "    \n",
    "    total_prec = 0\n",
    "    for u in range(batch_users):\n",
    "        y_true = X_true_binary[u]\n",
    "        y_scores = X_pred[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/batch_users\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-VAE^{PR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_dims = [200, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-31-881e9e51e708>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory\n",
    "\n",
    "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
    "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: ./volmount/log/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "log_dir = './volmount/log/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = './volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            \n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, \n",
    "                                           global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@100\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr, test_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'test_tr.csv'),\n",
    "    os.path.join(pro_dir, 'test_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)\n",
    "\n",
    "batch_size_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "#     int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "# print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I/model\n"
     ]
    }
   ],
   "source": [
    "n10_list = []\n",
    "r1_list, r5_list = [], []\n",
    "# p1_list, p5_list = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        \n",
    "        n10_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=10))\n",
    "        MAP = MAP(pred_val, test_data_te[idxlist_test[st_idx:end_idx]])\n",
    "\n",
    "#         p1_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        p1 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "#         r1_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        recall, rec_1 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "        r1_list.append(recall)\n",
    "        \n",
    "#         p5_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        p5 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "#         r5_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        recall, rec_5 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "        r5_list.append(recall)\n",
    "\n",
    "n10_list = np.concatenate(n10_list)\n",
    "\n",
    "# p1_list = np.concatenate(p1_list)\n",
    "r1_list = np.concatenate(r1_list)\n",
    "\n",
    "# p5_list = np.concatenate(p5_list)\n",
    "r5_list = np.concatenate(r5_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@10=0.23626290773289413\n",
      "Test MAP=0.19107716046912743\n",
      "Test Prec@1=0.14\n",
      "Recall: 0.053164556962025315\n",
      "F1@1 0.07706422018348624\n",
      "Test Prec@5=0.11733333333333333\n",
      "Recall: 0.22278481012658227\n",
      "F1@5 0.15371179039301308\n"
     ]
    }
   ],
   "source": [
    "# print(\"Test NDCG@10=%f (%f)\" % (np.mean(n10_list), np.std(n10_list) / np.sqrt(len(n10_list))))\n",
    "print(\"Test NDCG@10={}\".format(np.mean(n10_list)))\n",
    "print(\"Test MAP={}\".format(MAP))\n",
    "# print(\"Test Prec@1=%f (%f)\" % (np.mean(p1_list), np.std(p1_list) / np.sqrt(len(p1_list))))\n",
    "print(\"Test Prec@1={}\".format(p1))\n",
    "# print(\"Test Recall@1=%f (%f)\" % (np.mean(r1_list), np.std(r1_list) / np.sqrt(len(r1_list))))\n",
    "# print(\"Test Recall@1={}\".format(np.mean(r1_list)))\n",
    "# print('F1@1', F1_score(p1, np.mean(r1_list)))\n",
    "\n",
    "print('Recall:', rec_1)\n",
    "print('F1@1', F1_score(p1, rec_1))\n",
    "\n",
    "# print(\"Test Prec@5=%f (%f)\" % (np.mean(p5_list), np.std(p5_list) / np.sqrt(len(p5_list))))\n",
    "print(\"Test Prec@5={}\".format(p5))\n",
    "# print(\"Test Recall@5=%f (%f)\" % (np.mean(r5_list), np.std(r5_list) / np.sqrt(len(r5_list))))\n",
    "# print(\"Test Recall@5={}\".format(np.mean(r5_list)))\n",
    "# print('F1@1', F1_score(p5, np.mean(r5_list)))\n",
    "print('Recall:', rec_5)\n",
    "print('F1@5', F1_score(p5, rec_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
