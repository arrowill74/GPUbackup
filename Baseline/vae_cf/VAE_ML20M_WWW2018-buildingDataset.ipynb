{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders for collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
    "\n",
    "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
    "DATA_DIR = './'\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data and create train/validation/test splits following strong generalization: \n",
    "\n",
    "- We split all users into training/validation/test sets. \n",
    "\n",
    "- We train models using the entire click history of the training users. \n",
    "\n",
    "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv(os.path.join('../../User/output/', 'UserFollowingsMat.csv'))\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data.rename(columns={'Unnamed: 0':'userId'}, inplace=True)\n",
    "# raw_data = raw_data.set_index('userId')\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['userId', 'movieId'])\n",
    "# for uid, row in raw_data.iterrows():\n",
    "#     for movie in row[row == 1].index:\n",
    "#         df = df.append({'userId': uid, 'movieId': movie}, ignore_index = True)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('../UserFollowingRecord.csv', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(pro_dir, 'UserFollowingRecord.csv'))\n",
    "raw_data = df\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
    "- Use all the items from the training users as item set\n",
    "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep items that are clicked on by at least 5 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create train/validation/test users\n",
    "n_users = unique_uid.size\n",
    "n_heldout_users = 150 #25 #coldstart\n",
    "\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)] # -1282\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)] # 1282-1432\n",
    "te_users = unique_uid[(n_users - n_heldout_users):] # 1432- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_sid = pd.unique(raw_data['movieId']) #train_plays['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective for Multi-DAE for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
    "$$\n",
    "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiVAE(MultiDAE):\n",
    "\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "\n",
    "        # placeholders with default values when scoring\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        \n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # q-network\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "\n",
    "        sampled_z = mu_q + self.is_training_ph *\\\n",
    "            epsilon * std_q\n",
    "\n",
    "        # p-network\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        \n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        \n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                # we need two sets of parameters for mean and variance,\n",
    "                # respectively\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            \n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
    "                                           os.path.join(pro_dir, 'validation_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1282, 165)\n",
      "(150, 165) (150, 165)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(vad_data_tr.shape, vad_data_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "# training batch size\n",
    "batch_size = 500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = range(N_vad)\n",
    "\n",
    "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
    "batch_size_vad = 50 # 2000\n",
    "\n",
    "# the total number of gradient updates for annealing\n",
    "total_anneal_steps = 200000\n",
    "# largest annealing parameter\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0] # 150\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "    recall = tmp / X_true_binary.sum(axis=1)\n",
    "    rec = np.sum(tmp) / np.sum(X_true_binary.sum(axis=1))\n",
    "    return recall, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prec_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "#     prec = tmp / np.minimum(k, X_pred_binary.sum(axis=1))\n",
    "    prec = np.sum(tmp) / (batch_users * k)\n",
    "    return prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(X_pred,heldout_batch):\n",
    "    X_pred[X_pred == -np.inf] = -9999999999\n",
    "    batch_users = X_pred.shape[0]\n",
    "    X_true_binary = heldout_batch.toarray()\n",
    "    \n",
    "    total_prec = 0\n",
    "    for u in range(batch_users):\n",
    "        y_true = X_true_binary[u]\n",
    "        y_scores = X_pred[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/batch_users\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-VAE^{PR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_dims = [200, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-881e9e51e708>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory\n",
    "\n",
    "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
    "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: ./volmount/log/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "log_dir = './volmount/log/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = './volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            \n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, \n",
    "                                           global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAADVCAYAAADw3456AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd5xU1fn48c+07WW272zvlV126b1IEQTEBioqGA3GNBKTqJhYMOrPL/oN+pVIosZoMCpFVKQ3KdKWsgXY3nvvfWdn5vfHwLDDdtiGnvfrlVdk7p25Z8/O3vvcc5/zHIlOp9MhCIIgCIIgCMKwkQ53AwRBEARBEAThp04E5YIgCIIgCIIwzERQLgiCIAiCIAjDTATlgiAIgiAIgjDMRFAuCIIgCIIgCMNMBOWCIAiCIAiCMMzkw92AkaK6uhGtduirQzo4WFFZ2TDkx71dif7qH9Ff/Sf6rH9Ef/Wf6LP+Ef3Vf6LP+mco+0sqlWBnZ9nltiELyrOzs1m7di01NTUolUrWr1+Pj49Pl/tmZWVx7733smLFCp5//nkAXn31Vc6cOYOJiQkWFhb85S9/ISIiAoDHHnuMoqIirKysAFi5ciX3339/v9qn1eqGJSi/dmyh70R/9Y/or/4TfdY/or/6T/RZ/4j+6j/RZ/0zEvpryILyV155hRUrVrB06VJ27tzJyy+/zObNmzvtp9FoeOWVV5g7d67R6zNmzODPf/4zCoWCo0eP8swzz3D48GHD9hdffJHZs2cP+s8hCIIgCIIgCANtSHLKKysrSUpKYvHixQAsXryYpKQkqqqqOu374YcfMmvWrE6j6LNnz0ahUAAQFRVFSUkJWq120NsuCIIgCIIgCINtSEbKi4uLcXFxQSaTASCTyXB2dqa4uBh7e3vDfikpKZw8eZLNmzezadOmbj/v888/Z9asWUil1+8p3nrrLTZs2EBwcDDPPvssLi4u/Wqjg4NVP3+qgePkZD1sx74dif7qH9Ff/Sf6rH9Ef/Wf6LP+Ef3Vf6LP+mck9NeImeipVqt56aWXePPNNw3Be1f27NnDrl27+Pzzzw2vvfXWW6hUKjQaDR988AG///3v+fLLL/t1/MrKhmHJJ3Jysqa8vH7IjzsStKo1mMilSCSSPr/np9xfN0P0V/+JPusf0V/9J/qsf0R/9Z/os/4Zyv6SSiXdDgQPSVCuUqkoLS1Fo9Egk8nQaDSUlZWhUqkM+5SXl5OXl8dTTz0FQF1dHTqdjoaGBl577TUADh06xDvvvMOnn36Ko6Oj0eeDfgR+5cqV/P3vf0er1RqNpAsjS0Ozmj9/eJa5Yz24e5rvcDdHEARBEARhWA1JUO7g4EBoaCi7d+9m6dKl7N69m9DQUKPUFTc3N2JiYgz/3rhxI01NTYbqK0ePHuXNN9/kk08+wcPDw7Bfe3s7NTU1hiB9z549BAUFiYB8hDsaV0hDs5oD5/OYO84DCzPFcDdJEARBEARh2AxZ+sq6detYu3YtmzZtwsbGhvXr1wOwevVq1qxZYyhv2J0XXngBhULBmjVrDK99+umnmJqa8tRTT6FWqwFwdnZmw4YNg/eDCLesTa3hyIV83BwtKapo5EhsIUum+Ax3swRBEARBEIaNRKfTDX9hxhFA5JQPnWNxhWw+kMpzD0ezLyaP7OI63v7lFExNup9LcM1Psb9uheiv/hN91j+iv/pP9Fn/iP7qP9Fn/TNScspFjocwpLRaHfvP5eGrsibYS8niKd40NKs5Hl843E0TBEEQBEEYNiIoF4ZUbFo5ZdXNLJzojUQiIdBDSYiXkv3n8lC3i7rzgiAIgiD8NImgXBgyOp2OfTF5OCvNGRPkZHh90RQfahraOH2leBhbJwiCIAiCMHxEUC4MmbzSBrKL65g33hOp9Hpt8jBvO1QOFpxPKRvG1o1Mx+MLef/ry4ipH4IgCILw4yaCcmHInLpSjFwmYVK48WqrEomESH8H0vJraGlrH6bWjTw6nY4D5/K5mFZOWn7NcDdHEARBEIRB1K+gvLa2lqKiImprawerPcKPVLtGy7mkUkYHOGLZRU3ySD8H2jU6knOrh6F1I1NRRSMlVU2Avq57X6jbNcSll4uRdUEQBEG4zfQalKvVajZs2MC0adOYNGkSd9xxB5MmTWLatGm88847hvrggtCTxOwq6prUTAl37XJ7oKcSUxMZl7OqhrhlQ+tiahlnk0r6VH7zYmo5EmBCqDMXU8upbWzr9T2HLxSwccdlMbIuCIIgCLeZXoPydevWERcXx9tvv83p06e5cuUKZ86c4e233yY+Pp5169YNQTOF292ZxBKszBVE+Dt0uV0ukxLmbcflzMof7Shval41m769woffJfHSxzHEJJX2GJxfSC0nwMOWpdN80Wh1/JBQ1OsxziSW6N+bUj5g7RYEQRAEYfD1GpQfOHCATZs2MXnyZOzs7JDL5SiVSiZPnszGjRs5cODAULRTuI01tbQTm1bBhFBn5LLuv3IRfg5U1rVQVNk0hK0bGg3Naj7clYSz0pyn7g5DKpXwwXeJrPvkHIk5nZ8OlFY1UVDewNhgZ1QOloR623E8vrDHID6/rIGC8kZMFTIupJYN+WJYF1PLiU+vGNJjCoIgCMKPRa9BuZmZGWVlXVfFKC8vx9TUdMAbJfy4XEgto12jZfKorlNXronw04+iX86sHNT2JOdW89dPz1Pb0Dqox7lGp9Px7z3J1De18fTSUUwKc+XVJybwi7vDaWnT8Lct8fzf9gRD/jjo+wxg7NXSkbOj3amsa+VSVvd9czaxBKlEwgOz/KltbCO9oPsUloF+GqHV6th8IIUvj6QN6OcKgiAIwk9Fr0H5z3/+c1atWsU777zDvn37OHnyJPv37+fdd99l1apVrF69eijaKdzGTl8pwcXeAj+VTY/7Odia4e5oyeUeAs+BcCG1jJySejYfSB2SVJkjFwuIz6hg2ewAvF2tAZBKJEwMc+GN1RNZNsuftIIa/vrpecNE14up5fiqbHCwNQMgKtARWysTjsZ2PeFTq9NxNqmUUX72TI1wxUQu7TaFJS2/ht+8e4LUvO4n1Wp1OjZ9e4UrffxdZBTWUt+kprymhbKa5j69RxAEQRCE6+S97fD444/j7+/Pt99+y7Fjx2hqasLCwoKAgADefPNNpk+fPhTtFG5TpdVNpOXXcO90XyQSSa/7R/g5cOhCPs2t7Zib9vr1vClZhXUo5FLi0iuISSplUjeTTwdCc2s7O05kEenvwNyxHp22K+QyFk7yZmKYC+9sS+CdbfHcP9OfnJJ6ls3yN+wnl0mZHunGntM51Da0Ymtl/IQqNa+G6vpWls8OwMxEToS/AxdSy9DckMJS29DKP3ZeoblVw9mkUoK97Lpsd1ZRHRdSylDIpIzy63oeQEexafpJqTogKacK5yj33jtHEAThNlZd38qWI+kA/PKeUcPcmv5pU2uQSiU9ppQKQ69PUc/06dNF8C3clMMXCpBJJUyLdOvT/hF+9uw/l0dKbjXRHVb9HCitbRryyxpYMNGL1PxqPj+URoi3HcobgtysojoOnMtjxdzATgGw4bPUGv766XmsLUwYF+zE2GBn7KyN9z2bVEprm4YlU316vCmxtzHj+UfG8N6OS2z9PgOAscHGP//EUGd2n84hNr2C2dHGQe/ZxBJMTWREBToCMD5EX7ElObsSFxt9m9o1Wv6xM5HmlnZ8VdbEZ1TwmE6HtIt2xaXpR9lzS+u7bfM1Op2O2LRyRvk5UFDeQFJONbNEUC4Iwo+UVqefeL/taCbNrfq1NRaV1uPlYj0s7VG3a3h3+yUam9XYWJmgtDLlwfkhWMq7v+a8sy2BitoW/vhQFK72FoPavoqaZt78PBa5TILSyhQHGzOWzQ7odL0U+linvLq6mq1bt/L666/zwgsv8Prrr7N161aqq0VNaaF7TS1qTl4qZmKYS5//+K6VRjyfOjire+aU1KHV6Qj0sOWJu0Jpa9fyn30phhMrwA+Xivifzy9yPqWMs0ml3X5WVmEtxZVNlNc088XhdP74/im+jy0wbNfpdByLK8TL2arX1B0AK3MFf3wwigmhzkQFOOJsZ3yidHO0ROVgwYUbVj5Vt2u4kFrG2CAnTBUyACL9HVDIpZzqULHl6+NZpOXXsGpBCHPHelLb0EZuSeeg+1qQDVBc2Uhrm6bHdueXNVBR28KYIEfCfOxIzqka8kmmgiAIQ+Wro5n8Z38q3i5W/GXlWOQyCScvFw9be/bF5JGcW421pQkNTWrOp5Txt88vou0mPTO7uI7UfP3T1Tf/e5GckrpBbd+lrEqq61vxcrFGJpVwNqmU01cGtr90Oh2tag1NLe3UN7Wh0WoH9POHSq9B+ZkzZ5g/fz7fffcdOp0OZ2dnAHbt2sWdd97J2bNnB72Rwu3peEIRrWoN88d79vk9cpmUWVFuxCSWUlDWMOBtyijUL3zl52aDysGS+2f6k5BZye/eO8nGHZf41+4kPtmbQqCHEhc7cy71MOk0Nb8GCfDakxN5/ecTCfW2Y/vRTKrqWgD9aHt+WQOzot37lLoDYKqQ8fTSUax5ILLTNolEwthgZ1Lzaqhrul6zPDatguZWDZM7pOGYmciJ9HPg5KUivjicxp8/PMv+c3nMHuPO5FGuRPg7IJVIiOuiWkpRZROl1c1E+Dmg00FeWc+j5ddSV6ICnQj3saexpb3X9wgjX0xSKW99EUtTi1hld7jVNrRyMbWcbd9nsO9s7nA3p99Kq5vIH4Tz+XC5nF1JqLcdzz4cjb+bLdGBTpxNLEXdPvSBYHlNM3vO5DI+xJk/PhjFy4+PZ+X8YHKK64hL67oa1vcXCzA1kfGXlWMxkct464s4UgZx4b60/BqUVib86p5RPLdiDF7OViRmD+yaJP/cmcgv/3ac37x7gt+9d5KXPz5Hdf3QFHMYSL0G5a+99hpvvPEGn3/+OS+99BLPPPMML774Iv/973954403ePXVV4eincJtpl2j5fCFAkK8lP1+pLdosg9mpnK+Op5p9PoPl4p4/6sE9p3N5XxKGeeSS/n2hyw2fXuFb05kdRoVuJRZyVfHMo0mc2YV1eFiZ461hQkA88d78sKjY5gV5UZOST2nr5Rw5wRP/vDgaKKDnEjLrzEaRe8oLb8GTxcrLMzkuDlasmphCBqtjm1H9eknx+IKMTWRMTHMpV8/f0/GBTuh1ekMpQc1Wi3fncpG5WBBqLdxfvjEMBdq6ls5FleEo60Zj8wL4uE5gYB+VD7Qw7bLEobXUlfume4LQE4Xo+kdxaZVEOBhi62lCaE+9gADfsIdCdo1WhKzq/j8YBrfncoe0M/OLann5Y9j+GRvMleyKmnXDP8oz4mEIlLyavhkX/Kwrh2gbtd2O+L3U7DjeCbP/P0U739zmf3n8vjqWCYNzbfXon2f7E3h7S/jaGkbmBs8rVbH6SvFbNxxicralgH5zL7SaLWUVDbh42ptGGyZHqmioVlNQsbQl4T94lAaUomEh66e2wEmhDnj5mjJrlPZnf5265raiEkuY8ooV3xVNvz5sbHYWpmy+UDqoLRPp9ORll9DkKfS0F/hvvakF9T2+n3Q6nRcSCnjtf+cZ39MXrf7JWZXcT5F/zM9dEcAy2b7U1XfyltfxlEzRFXWBkqvOeVFRUXMmjWry20zZ87kT3/6U58OlJ2dzdq1a6mpqUGpVLJ+/Xp8fHy63DcrK4t7772XFStW8PzzzwPQ3NzMCy+8QGJiIjKZjOeff57Zs2f3uk0YHhdTy6mub+WxO4P7/V4rcwWLJnvz1bFMUnKrCfG24+D5fLYcScfcVEZz6/V0CokE7KxNDSkd987wAyCzqJb3v7mMul1LVKAjAe626HQ6MgtrO01cDPRQEuih5KG5gTS1tGNlrgBgtL8D+2PySMqp7pTf3a7RkllUx8yo67nyzkpz7prkxXenchgXXMa5lDKmRqgGdMKqp7MVznbmXEgpY8ZoN05fLqG4solf3xuBVGo8Gj822Il3npmJmRRDWktHUYGObP0+g4qaZhyV5obX49L1lV98XK2xsTQhr4egvKymmYLyBh68IwAAW0sTPJysSMqpZtFkn4H5oUeA4/GFbDuaQXOrxjChNdzHHn9321v+7IZmNe9/c5nm1nYqasv44VIxVuYK1jwQScAAfP7NaGlrJy2/BkdbMy6mlnPofD7zJ3gNeTvqmtp4/T8XCPGy44lFoUN+/P7QanV8dTyTSWEuA5ZbXFnbwv6YPKIDHblrkjftGi3rv4gjKaeKCaEDd7M/mFrbNGQW1qLR6vg+tpC7Jnnf9GfpdDoSMirZcSKTwvJGAOqb1Dz/SDQy6dBMWCyrbkaj1eHmaGl4LczHHjtrU364VMy4EOchaQfoz9UJmZUsvyE/WyaVsnxuEO9uiSM+o4LowOvXrx8SimjXaLljjL7wgJ21KdMiXNlxPIuGZrXh+nej6vpWKmqbCfRQ9quN5bUt1DS0EeR5/X1hvvbsi8kjLb+GSH/HLt+XmFPF9u8zyCtrwFQh46tjmQR5KvFzM04F1ep0bD+WgaOtGasWhKCQ678HAe62bNiawNtfxvHcijHYWpr0q93DpddvcWRkJO+88w5NTcYLujQ1NfHuu+8SGdn5MXtXXnnlFVasWMGBAwdYsWIFL7/8cpf7aTQaXnnlFebOnWv0+scff4yVlRWHDh3in//8Jy+++CKNjY29bhOGnk6n48C5PFzsLYjsZgXP3swd64GdtSnbj2VwPL6QLUfSGRvsxJev3cX7z8xg3c/Gs+5n4/nHH2by9i+nMC1Sxa7TOZxJLKGitpmNX13C1tIEUxMZx+P1ZQTLa1uoa1Lj79Z1frdUIjE6Ifm722JuKuNyVufRj5ySetTtWoI9jU9Qd03yxtHWjA++S0TdrmVWVN8muPaVRCJhXLAzybnVVNe38u3JbHxVNowJ6nxik0gkBHgouwzIAaIC9O+J7zC6U1XXQnZxPWOCHJFIJPi4WpPTw2TP2FT9qPqYDpNyw3zsSC+opU3dcy56d7KL61j3yTn+tOkUv9pwnKfePsrz/zzN21/G8d+DqUM+8qHV6vjmh2yc7SxYc38k76yZho2Fgu1HM255BFmr0/HhrkRqGlp5ZnkU/7dmGr+9PwJThYyP9ySjbr+5PrxVKbk1aLQ6Hl8YQnSgI9uPZfZY934waHU6/rUriYraFk5dLqawfGSnP8SlV7A/Jo9/703u85yKj3YlsvX79G63772aqrJibhD+7rYEeNhiYSofsU+iqutbO6U7pRXov0u2Vibsj8m76dHyuqY2/v71Zd7bcYn2di1PLw1n9ZIwMgpr2XlyYJ9c9aSoQh8LdQzKpVIJUyNUXMmuNKQvllU3kdzFwnADpVWt4YtD6bg7WjJ3XOfKXrPGeOCkNOO7kzmG85RGq+VYXCGh3na4d2i/v5v+5j+rqOvc8tS8al759znWfx5HY0v3T2kyi2p564tY6jukV6bl6c8bHYPyIA9bFHIpV7r5Hjc0q/m/7Qk0t7WzenEYb/9qCkprEz7anUTrDdeVc0ml5JU2cO8MP0NADvrBtmeWj6aqrpV3tyXcNvOceg3K33zzTeLi4pg0aRKLFi3ioYceYvHixUyePJnY2FjWr1/f60EqKytJSkpi8eLFACxevJikpCSqqjr/Qj788ENmzZrVaRR93759PPjggwD4+PgwatQoTpw40es2YehlFtWRU1LPvHEeXVb26AsThYx7pvuSXVzPf/anMsrPnl/cHY5MJsXcVI6XizVeLtaYKGRIJBJW3hlMiJeST/Ym879b4lFrdPx+2Wgmh7lwPrmMphY1WVfzyfs6uimXSQn3sedSZmWn4CstX3+iCbwhKDdRyHh4biAarQ5/N5tBmY0/LsQJjVbH37++THV9Kw/M8u9zznpHLvYWqBwsjB65XgvQr42seLtYU1TR2OlEeE1cejmezlY4dRhpD/Oxp12jJb2gtt9t0n9mBfllDYR62zE90o254zzxVdnQptbww6Vi1n1yvk/5jw3Nat7+Mq7XAKa6vrXHyayZRbXUNbaxYIIXUYGO2FiYcPc0X9IKanucc9AX353M5kpWFSvmBuHnZoNCLiM60InHF4ZQWtXEd6dybunzb9bl7EpMFTICPZQ8uSgUBxsz/rkz8aZvtG7GvrO5XMmu4r4ZfpiYyNh1OmdQjlNV18K+s7m3nCKz/1wuJgopeaUNnLhU1Ov+qXnVnEks5cC5/C7XA6iqa+GHS0VMj1QZ1iuQSaWE+tiRmFM1rClFHWm0WuLSytmwLZ4/vX+KD75LNNqenFONXCbhqSXhNDSru11roSfnk0p4+eNzXM7Sjwq/9vOJTAh1YXK4K9MiVOw5nTuoAXBHRZX6Ab8bK5ZMi1Sh08F3p7L5584rvPDhWd7eEs+27zMGJf1qz5lcKutaeHR+UJdlDWUyKYsn+5BbWs+hCwUUVzYSm1ZBZV2rYZT8Gh+VNRIJZBV1PmcfjS3gf7fEI5Hob5SvBdk3am3T8NGuJFLyajh56fokzrSCGiyvpnheo5DLCPJUkpTT9Xk8IaOCdo2Op5eOYvIoV6zMFTxxVyilVU18dex6Wqu6XcvXJ7LwdLbqMk00yFPJqoXB5JbWczappMtjjTS9Pld3d3dny5Yt5OTkkJGRQWNjI5aWlgQEBHSbfnKj4uJiXFxckMn0I3YymQxnZ2eKi4uxt7c37JeSksLJkyfZvHkzmzZtMvqMoqIi3N2vl1lTqVSUlJT0uq2vHBys+rX/QHJyGp4ySoPlv4fTMTeVc/eswFtK3Vg6O4jTiaWYm8j5yxMTMDPRf1Z3/fXy6sn86f9OUFLVxKurJzE6yBlLazOOxRdxObeGoqpmzExkRIW6IutjbdapUe5cSC2nsV2Hb4cR9pzSBjycrfD37vwkYJ6jFQ2tGsJ8HQbld+voaIWzvQXZxXWMCXZmxrie0wp6asOUSDd2nsjE1MIUhVzKpawq3J2sGB2qnzQaGezMrtM5NLRp8XAzvgFpbm0nq6iOe2cFGB1jqo05f//6EtmlDcyaYPyoWqPR0tKmwbKbR6QAlfWtuDlasfbxiZ225ZbU8ean5/nfLXE8ujCU+2cHdkrbuWbz5xdJzq2mTaNl5ngvoxsXdbuWmMRi9p/JISG9gnGhLrzy80ld9tl3Z3KRy6TcMdEbCzN9u++fG8yR2EJ2nsph9kQfZN20AaCytpl9p3OwslBga2WKTCohLa+G5JxK0vJqmDveiwfmBRu1b5aTNfFZleyLyWP+ZF/8BiCNpaCsntziepTWptjZmOJsZ9HlxVyn05GUU83oQCfcVPrjrnkwmhc/OE1qUR13dPF9G8jvuVar40pWBd+cyGJGlDuP3z0KmULGV9+ns3KxDm/X3isZ9cdHe5I5c7mYqFAXIgNurgxrcnYVmYV1/OLeCE4mFPHtD9ksnOqHlUX3j8wPXihAaWWKpbmC/x5K4+/P3mF0vtzxg37097FF4Th1CAAnRbhxMbWcVp0ET+fhvXZU17Xw1w/PkFNch4OtGWF+DiRmVyI1keNgq79RTy+qJcTHnhnjvDgSW8iB8/ksmx/Sp2tDu0bLJ7sT+e5EFj4qG9745VR8bqhk9buHx5BdcpyP9yZz93R/3JyscHeyxM3JalBqcFfVt+FkZ46Xh/EcHicnayIDHDmRUIy5qZz7ZgXQ1NLOvjM51Dar+cPDY8grredkQhEVNc0883A0CnnXTzF7U1TewP6YPGaN9WDa2O7P/3fPDuRInP5J85Yj+tcclebMm+zT6Rro7WpDQUWT0d/yrh+y+OxgGuNCXfjdg9E8+fpBcssbmT/Vr9OxPvjmEmXVzTjbW3DycgmPLgpHKpWQWVTHKH9HXJyNf28TR6n4965EJAq5UfokQGJuEo62ZoyPcDOcF2c6WZNaWMeuH7JwtLPAzsaM3JI6KmpbeHX15E6ff82i6VYciS3ku9O53DU9wGg0/UYjIRbrc8Tk4+PT5yD8ZqjVal566SXefPNNQ/A+lCorG4bl8YaTkzXl5T+eShUNzWpOxBUyfbSKhrpmbvWB87MPRiGRQH1tM/X03l/PPRxNdX0r7nbmlJfXY2sqw8fVmj0ns5DJpPi4WlNV1ffUJh8n/d398Qt5WF3NkdZqdSRmVTAh1KXbtkwfpQ9qB+t3OybQkf0xeSyZ7N3jMXrrryB3G9o1Oh55eZ/htYWTvAzvsTPXnyLiU0pxsDQOpC9nVaLR6vB2sux0jAB3W07GF7JwgodRrudHuxKJz6jguYfHGFY3vVFOUS0qh86fCWAhk/DnR8fwn/0pbN6bTGZ+NY8vDOmUTxqXVs6x2AK8nK3ILKjlVGy+YaGkVrWG1/5zgaKKRhxsTBnt78CF5FKOn88lzMfeqM90Oh0n4wsJ87Gjsb6Fxvrrk8qWTvXhnzsT2XUsnakRqm77+N3tCZ1G1BVyKb4qG5ZO82XhRC8qKjr/pSyd4sP5pFI2fH6RF1eNvaWcWZ1Ox7qPYiitup6G6OlsxdpHxnQKjkqrmiitamL+OA9DP6iUprjaW/Dd8UwivDsHI339nqvbtXx5JB0rczkB7kp8VNbklzYQm1bOpcwKahvbaNfoz8MuduY8ONufiooGpo9yZdcPWfxnV+KALtKSXVzHmaul7A6eyUF1dUS6v748kIylmZwoX3tUSjNe/fQ8H++8zIq5QVTVtXAxtZwgT6XhO1/d3E5cWjnLZvnj727L/3wey7++uWSYrFdd38qBszlMGaVCotEY9a+3oz5A/+FiPvP6UdlqoNU2tvHWF7FU1rXwi7vDGRfiRFl1M3/5qJJ9J7O4c4IXDc1qsgpqWTrdl/LyehZM8OT/pZax/VAKCyf2nFteXd/KP769QkZhLUum+7F4ohcKuaTL79rqxaH8/evLfLonyfCaXCbF3ckSbxcr7pzghcrBstP7bkZ2UQ0uV68vN3pgph8RvvZMDnfBwkyBTqdDaaFgy5F0ViTvM6rOMiXMudvF2zqqrG3h3e0JTAp3YeFEbyQSeG9bAgq5hKU9nP+dnKyprmrkhUfGUFDeQEllE6XVTYR42XV5DfR2seJ8chmlZXWGJ9x7TmXh727D00vCULe04e9uS1xqWadjpuRWs/tkNnPHeuDnZkI5lzgAACAASURBVMOHu5I4cTEPd0dLiisamR6h6vSea9fWExfzmN5hHZNWtYbYlDKmR7p1Oi8umuDJ5fRyth5OM7wW5mOHh71Zj+egpVN92LA1gR2HU5nTxSJ+1/prqGIxqVTS7UDwLc1AU6vVPPnkk2zevLnH/VQqFaWlpWg0GmQyGRqNhrKyMlSq6xey8vJy8vLyeOqppwCoq6tDp9PR0NDAa6+9hpubG4WFhYaR9eLiYiZO1I+k9bRNGDzxGRV8cSiNp5eOMky+OH25mHaNdsAWj+luFLQ7NpYm2NwwoWNmlBv/2a+fWb5ocv8mGdlameLtak1CZqVh4mJ+WQPNrRqjHLmhtmSKD2ODnLoNbPsqwN2WFXMDaW5tRy6XYiI3rhZjZ22KtYWiy3rmybnVyKQSAjw6j+LOG+/Jxh2X+eFSseG7kFNSx5nEUqQSCRu2xbP2kTGdLpTtGi2lVc2dJtZ2ZG4q5xd3h6NysGTnyWyaWtp5emm4YdSpoVnN5gOpeDpb8dyKMTz/z9MculBguADuPp1DUUUjq5eEMTHUBY1Wy58/jGHb0Qxefny80bHySvU12JdM8enUjnEhzvjE5PH1iSxGBzh2OUEqPqOCS1cnYs0Y7UZ9Uxutag1ujpa9juJZmSt4ZF4Q//j2CofOF7BgYtcjYm1qfZ36AA8lzjeMOF2TVVRHaVUT987ww09lQ1FlI1uOpPPJ3mR+ec8oo1H6S1dTKcI7TIiWSCTMinZny5F08m5hkZQLqWUciyu8Oln2emk/E4WUUb4OuNibYyqXYaKQMT7E2XDDYGWuYO44D/aczqWgvAEPp4F5svn1iSyszBX4u9lwIaWMR+Z1nQrQk5KqJuLTK1g0xQdTExleLtbMHO3G9xcLKShrIDWvBh36ydZrHogk1NuObYfTsDSTMyvaHXNT/f8fupCPq4MFNfWtJGRUotPB4i7OV45Kc1zsLUjMqeoUlF9bYyAxp5p7p/saqkwNtI4B+TPLRhv+tlQOlni7WnM2sZQ7J3iRkluNDgjz1l+bA9xtCfe1Z39MHndEe2Bq0vUAXHJOFR98l0irWp87vmhGQI8Bk5eLNW/9cgpNLe2UVjdRUqkvwZhXVs+55DLOJZfx5KJQxgb3PAnzclYlXxxOJ9RLycoFIZ22a7U6iiv1gW1XPJysjL6bEomEeeM9cbE351xyGaHedgR42PLCB2fJKKztU1B+4FwehRWN7DieRWJ2FWODnUnMruLhHha268hUIcPfzdaQN94dPzcbjscXUVrVhMrBktKqJgrLG3l47vWnkSHednxzwnhCaEtbO//em4yznTn3z/RHKpVgdTid43GFhkmvXV0r3Z0ssbU0ISmn2igov5JVRVu7lugu5kmZKGS8uGocrW0a2tq1tKo12FmZ9Jq+Ge5jT4iXkl2nspka4Wp46j4S3VLLdDod58+f73U/BwcHQkND2b17N0uXLmX37t2EhoYapa64ubkRExNj+PfGjRtpamoyVF9ZsGABW7duJSIigpycHC5fvszf/va3XrcJg6OsuomPdiXR3NrOh7sSWfez8ZgqZByNLyLA3RZP5+FLB7rRxDAXtnyfQWubptcTU1ci/RzYfSbHcCJKuzrh7cZJnkPJ3FQ+IJU/JBIJc8d1P9omkUjwdrXusixicm41/m42XVd2CXAkwMOWnSezmRzuapg9b2Wu4Jnlo3l3ewJ/2xrPnx8di73N9dHJ0qomtDodbr2MakkkEpZO88XCTM6Xh9N5Z1sCk8JdMZFLOZ9SRkOzmmeWj8biauCz90wuZTXNaDRa9sfkMWWUq6Guu1Qq476Zfny0K4mYxFLu7vAY9GJaORIJhpVSO5JKJDx2ZzD/77OL/HtPMr+9P+KGFBkNXx5OQ+VgwdxxHshlUizM+nfKHRfsRKS/AztPZjMh1Nmor5pa1HwfW8ihC/nUN6mJ9Hfg98tGd/k5pxNLUMilzB3rgbmpnHBfezQaffnOfTF5RhUxrmRV4WJv0SnAnzLKlR3HMzkWX8TKm6iqBHA0rhAXO3Nefnw8OcV1ZJfUo7K3INzXHpNuJiRfM3+8F4cvFPDZgVT+8GBUtxOYdTod1fWt5JbUk1NST3ltM61tGlrVGmwsTLhvph+Otuak5lWTmF3F8tkBuNibk5BZSVJOtdHk9J6qUVxz8FweMpnUaATu3hl+xKZXUFXXyt3TfAn3tefTfSm8uz2Be6b7EpNYwtJpvoabjgdm+hOfXs7m/alIJODuaMmKeUGdHutfM8rHnh8uF6Fu1xoex+eU1LHlSIZhvktSdhW/Xz6619UaS6uaeOvLOOaO82DBBK9eAxytVsc7W+M7BeTXTA53ZcuRdIorG0nOq8bURIaP6vpN3NKpvvy//17kaFxhpxtNrU7HvrO5fH0iC1d7C55bEWGUi9wbCzM5viobfFU2TL76WlVdC+9/c4X3v7nCwkle3DfDr9NTp9rGNr48nMa55DIsTOUciy8ixNuuU4WbiroW1O3afrUJINLf0ajKiKu9BRl9mHPT0KzmxKUipoxyJdhLyReH0knJq8HL2Yo7xgzsqskdJ3uqHCwNC8iN6VC5JcRLf81Lzas23OAcPJ9PRW0Lax8ZY7jJmhrhyuEL+oX0TBUyvFw6xwMSiYQwH3suZ1Wi7bCydFx6OZZm8m4HvaQSCeamcsz7sRioRCLh/pn+vPHZRQ6dz2fJVN++v3mI9XqFmDNnTrfb+jPRZN26daxdu5ZNmzZhY2NjmCC6evVq1qxZQ0RERI/vf/LJJ1m7di3z5s1DKpXy17/+FSsrq163CQOvTa1h0zdXkErgyUWh/HtPMl8eTmdSuCulVU0sWTyySpeZmciZHObC8fiiTuWU+iIq0JFdp3N476tLrFwQbCgV1zFA+jHzcbVmb3YebWqNIXBqbFGTV1rf5Qgy6E+CD8z0538+j+XwhXx8XG1IyqnmoTsC8FXZ8IflUbz1ZSzvbk/g1ScmGAKBosrOlQ16Mm+cJ5Zmcj7Zm0JKhwlI90z3NYzm3jHGg/0xeRy+kE9heSMmChnLZgcYfc7EMBcOnsvn6xOZLJh2PV8yNq2cYE9ltyOOviobls8O4Msj6Rw8n8+dHcoG7j+XT3mNfhnrm81tlUgkPDIviJf+FcMXh9P5zX3682ROSR3vbEugvklNhJ8DZiYyLqaWU9vQ2mn0rF2j5VxSKdGBjkapKndO8CSnpI4dxzPxcLIi0t+BNrWG1LxqZozuXDXIylzBhFBnziSWsGyWf7/nixSUNZBRUMuDdwRgbion1MfeUNe+L6zMFaxcEMxHu5LYuOMSa+6P7BTIa7X6ajbnkvUlUiUScLAxw8xEhqlCRlxhBXEZFSyfHcCZxBKUVibcMUa/uJe5qZxzyaWGoPx4fCGb96fy1N3hRk+PCssb2Pj1Zeoa29ABbW0apo92Myq5Zm1hwv/+agoyqcTw3X5+RTQbtiWw/Wgm5qZyoyDewkzO2kfHUl3Xgrerda8jeeG+9hyJLSCjsJYgT1t2HM9if0we1hYKVt4ZjJujJX//+jJvbL7Ab+6L6HFEdtfpHKrrW9l+NJOK2hZWzA3sMVUqPqOCvLIGVi8J6/JzJ4Y6s/X7dM4klpKcU02wp9Lo+x/gYUu4jx37YnKZHe1uCOSaWtr51+4k4jMqmBDqzOMLQwZkRNPexoy1j4zhy8Np7DubR05xPb9YGo7N1b/py1mVfLQriZa2dpZO82XBBC/e+jKOzw6kEuihNCo1WFShT/vob1B+owAPW+LSytHpdD3eBH1/sYA2tZaFE71wd7Ii0EPJdyezWTDRa8BLQLo6WGBuKiezqI6pESouppXj42ptmGQM+vOdiUJKSm4NY4OdUbdr+T62kAg/B6MgesZoNw6cy+dCajnhPnbdnv/Cfe04k1hCXmk9Pq42tGu0JGRUMDrAccDnA/i72xId6Mi+mDymj3ZD2YenDMOh1298bW0tzz//PB4enfNw2traePrpp/t0IH9/f7Zv397p9Y8++qjL/X/7298a/dvCwoL33nuvy3172iYMvC8Op5FX1sDvHohkdIAjJVVN7DmTS1q+fpb1uF4eEQ6HB2b5Mz7UpVNqS1/4qmx4clEoW7/P4NVPziOVSkbkzzhYvF2s0ep05Jc3GEZT0vJq0OnotGBRR0GeSqICHNl7NhcHGzMcbMyYfXXWv7erNffP9Oe/B9MorW42jOYVVTQioXNlg55MGaUiOtCJppZ22q6WEOyYFmNnbcr4UGe+v1iIVqfjkXlBnWrWSiUSls/25+0t8Xz83RXumuBFbWMrRRWNzJ4X1OPx547zICWvmq+OZeKrssHWyoSiikb2nM5hbLB+ldNb4aQ0Z8lUH3YczyIhowJzUznvbk/A0kzBy4+PxsfVhuLKRs6nlHEmsbTT6OPlzEoaW9qNVnwFfcD/s4WhFFU08u72BII8lfiqrGlr13aq5X/NrGh3Tl0u4WxSKbOj+zdSdzSuELlM2mP+fW8mhbmi0ej4955kNn59mTX3RxjSlnQ6HZ8dTOVcchkLJ3oRHeSEp7OV0Yh6RU0zn+5P4bOrC6WsvDPYENiPDXLiQmoZ6nYN1Q1tbDmiXwRs84FU/N1tcLQ1p6WtnU3fXqGltZ3pkW5IJCCTSZjXxdOmG4MKawsTnns4mk/2pTAuzLXTCLyz0rzb9KMbBXspkUklnEsuZe+ZHBJzqpkV5cYDswIMT2NeXDWO/7v6ROq1Jyfi0sXfVGl1E2cTS5k3zhOZTML+mDyq61r5xdLwbp9E7D+Xh6OtGRNCuz4H2lqZEuZtx4n4Quqa1EZrOVxz9zRf3vxvrGG0vKmlnb9tjSOvtIEVcwOZM9bjpipKdUchl7JyQQi+bjZ8diCNv356nl8uHUVCZgW7T+fi4WTJ00vHGILtp5aE8con5/h4TxJ/eDDKMIpbfC0od+j7+akrAe62nLxUTMnVVJGutKo1HL5YwGh/B9yvpsS42lvw1N3ht3Ts7kglEvxU1mQV1lJd30pWUR33zTCe0CmXSQn0UJKSp6+aci65lLrGNuaNN44PVQ6WhHgpScmr6VShrKNwXwfkMikf707mmeWjKalqorGl3ajE7kBafkcAL/0rhu1HM1i9ZHD68Vb1eisSFhaGqakpkydP7vJ/I6UskzA0LmVWcCKhmEWTvRl9tc710mm+eLtaU1rdzNQIVa+PoYeDhZmixwCyN1MjVLyxeiKTwl1Qt2uJ8L+1QOt2ci1vvWNeeXJeNQq5FL9e0oHum+lHS5uGgvJG7p3hazTz/drv49rjdtAH5U5K835/h8xN5TjYmqFysOzyIjd/vCdanQ5vF+tug8lQH3tmjFax93QOf9p0in/vTQYguovUlY4kEglPLArFztqU//k8lhc+OMvGHZeRy6SGRZVulX6imgWf7k9hw9Z47KxNeeHRMfhcrUSicrDE382GU1eKO52TTyeWYG2hINy383fW1ETGcyvGcP9MP2oaWjlwLh+FXEqwV9cXUj+VDV4uVhyNLezXub+5tZ3TiSVMCHXuNR2kN1MjVDx+VwhJ2VW8vvkip68Uo27XsvNkNsfji1g02ZtlswMIcLftFFg6Ks3544NRPL4whGmRKqZFXr9BmBDmTEubhoSMSj7Zk4xUCs+tiEZ3tV66VqvjswOplFQ28Yu7w3l4biAPzQlk2ayAPo+6mZvK+dU9o1h0i4/Pr6WvHY8vIjW/hscXhrByQYhRepSz0pxnH44GMKQS3GjP6VxkMgl3TfJi+ewAHp0fRHxGBfvO5na5f2ZhLRkFtfogvoeR2knhrtQ16etZd3XeDfRQEuZjx/6YXOoa23h3ewJ5pQ38+r4I5o7zHNCAvKPpkW78+bExSJDwxmcX2X06lxmjVby4cpzR6LeLvQUPzwkkKaeaIxev911RRSNKKxNDFaabdW1RsJ5SWE5eKqahWc3CW1hsqb/83GzJL2/gbKK+el1XwXGIl5LCikbqGts4dD4fd0fLLgcerpVdDOthUMLW0oRnlkVSWdfCG59d5OD5fEzk0i7PVQPBxc6CBRO9OJNYSmpe72V1h4Ns3bp163rawc3NDScnJ1xcOteAlEqlTJw40agc4e2qubmN4bi/sLQ0palDof2RTr+qYTtrHog0jB5IpRJCveyorm815PkOluHsL1OFjDFBTsyOdsfPzWbQLhwDaSD6y9xUzqnLxRSUNzI90g2ZVML2oxm4OVoaTdDpio2lCa1qDQq5lOWzA4z6zMpcYRg9vXby/+5UNq72Fl3WnL0VSitT7KxNWTDBq8fJb1GBTswa70V5VSOJ2VUEeNgyf3zvK1mayGVE+DtgbaFgyigVd07w4r6ZfgP2iFQqleDhZMmRi4W4O1ny7MPRnT5bq9Vx8lIx0YFOhm2NLWr+sz+FaREqw010p7Yr9DWD54z1INTbjklhrt0+qZBIJMikEk4kFGFraYKvyqZP37FTl4uJTStn5Z3BA5L25e1ijbujJUk5VZxIKOZobAFXsquYFqFixdzAHv82r82TiA50MppI7mBrxtHYQi5lVVJU2cRjdwYzJsgZO2tTDl0oIC2/hviMSu6Z7su0Xr73vRmo81hxZRO/vT/SaMXGjsxM5JRWNxOTVModY9yNSvCV1TTz6b4UZo9xZ3yI/u/NV2VDbkk9F9PKmTPWo1PZvC1H0qlpaOPni8N6Li2nNOfQhXwsTOUsvyOgy9+Ho605R2ILOXWlmLLqZp5eGt7tCOlAnveVVqZMGeVKY4ua+RO8WDLFt8sSud4u1mQW1Rn6Ti6TsudMDvY2ZkwZdfNPewAszRUcuViAqYmsy99du0bLh98lonK04J5pvjd1rbmZPmtTazh7dTEeB1sz7pneufShTCbhh4RiWtv1N7D3z/Q3DA50pHLQn8e9e5kU7qQ0J8LP4WoaSwOjAxyZMsq1x/fcCj83W84mlpCcW82MKDdDHDOUsYVEIsGim+tQr0G5h4dHlwH5tQ/+MQTkIILyvmhoVrN5fyozotyI8DO+wOvzTV0GNSCHkdFfpiay2yIgh4HpL4lEgoudBYcuFKDRaPF0sWLb0UymR7r1qQJNuK89U0a5dqqkI5FIyCqsI6uojnnjPdFotWw5kkFUoOMtp3x0xdvVuk+jtJ4qW8I8lUyPVBkmqfaFlbmCYC87vFz0eZgmN1mDuDuOtuZEBTiyYKIXll2M1DnbmXPwfAFSqcSQF336Sglx6RU8Mj/IKDe2KxKJBEdb824nF17j6WJFdnE9R+MKifR3xM3FutN3rKC8gQ93JXIps5Ly2maOxxdhZ2XKvTP8Buxvx83RkjvGuBPooaS2sQ0/NxsevysE6U3m2kolEipqW0jNr2G0vwPLrt5EejhZUVLVREJmJeG+9qxaEHLLP8NA/F16uVgzZ6xHrzc5DjZmHIktwNrCxDBCC7D9aAYF5Y388p5RRvMDlFYmHI0rxN7WzCjYKqtu4rODacwb59ntDd41CrkUnU5HoIctwZ5dP6F0sDUjvaCGonJ9JaQJPdyID/R530QhIyrQqceCBPrznv7GwdJMgb+7DVuOZDDK156Im1ypuuNnp+XXUFDe0KlEX25JPe99dYniKv2N4c2WcryZPrM0k7M/Jo+2di0zo9y6HOW2tTTh0Pl8MgpqDYv6dHVTI5FI+lz9x9bKlHFBTpRWN7NgopdRHvtAk8ukONiYc+RiAVZmCkPBhJESlPcrgsrIyCArKwsXFxciIiJu+uQn3J7OJ5ei0eo65aYKP36jAxyZGeVmOGFDz/nkN+ouiAnyVHIxrZyquhZa1Ro02t4rrwyVkTiRt6cSmBZmCsYEORKTVMqDdwSQlFPN3jO5qBws8LnF0pkdSSUSfr44lHWfnGfTt5fZeMOCO1V1LbyzLYE2tQYzE5lh0uXjC289mL2RRCIh3Nd+wB533zHGnfKaZlZ1aKt+xeAQ3J2smNVhZO124e1qTZCHLUcuFjBvnCdSqYTs4jpOXS5hVpR7p5u1IE8l3i7WHDqfz4zR13/eQ+cLkEok3dZ5vtHdfUjR+cXd4VTUtuCrGtgFoQaKv7stod52HDiXx+gAB0M504EQ4G7LpcxKQ4Wfdo0+BWvfWf2E3V/fG0FULzc/A83awgRnO3PKqpu7fWohk0oJ8lRyKbOSWdHuA5au6qg077Z61EAbE+TIKF97Dl0Y3lr/XelTUF5SUsLatWuRyWQEBwdTUlJCUVERmzZtMiprKPy4nb5SgoeT5aAsHS+MfA/eEUDy1RxLUxPZLddIh+v1a9PyawyP1gfqovdTNGWUinPJZbz88TlKqppwUpqx8s7gAQ+GrS1M+OXSUaz/IpZ3vozlkbmBWJkraGxR8862BFra2ln7yFg8na2ob2qjrKZ5xAZeHbk7WfGHB6M6vW5hJu+20tDtYN54T97/5gpx6RWYmcr4+9eXUVqZsmhK53xliUTCnRM8+XBXEpczKxkd4MiFlDKOJxQyKcyl1ycu/WFtYTJotdQHypIpPrz1ZRzbvtdP/B2o81Pg1fUdMgtrGR3gyFfHMjl4Pp+pEa48NCewy6dhQyHU2w4J9HgjP9rfgdT8mgEvyzhUJBIJv7xnFKXVTb3vPMR6DcobGxv5+c9/zrPPPsvMmTMNr+/du5cNGzbw+uuvs3v3bhYvXjyoDRWGV2lVE5lFdSyb7T/cTRGGiZmJnCcXh/I/n8cS5KEckJJVns5WmJnISCuoNVzsVbdY2eCnLNzXDkdbMxpb1DwyL4iZUW6DstQ46Mu6LZvlz5bvMzifVEqQpy0tbRpKqpr4w4NRhtSA2yHw+rGLDnTCwcaMbUfTqaprxdXBgj8sj+p2zsO4EGe2H8vkwLk8Sqqa2PZ9Bn7uNiwfoInLt5NgLyUBHrYkXF2Vd6CCch+VDVKJhIzCWtTtWg6ez2fuWA9W9FLtabCtmBuIul3b4438zGh3JoW79rss6khibirvMhd+uPXao5988gkLFixg5syZvPTSS7S3twOg1WqJjY0FYOfOnWi1Wu6+++7Bba0wbM4kliBBX5JM+OkK9FCy5v7IXvOO+0p6dUXQtHz9ghj6mtK374l+uMmkUl752XjkMmmfc+FvxfwJXkyMdOdwTA6xaeWUVDXx1JLwW6p0JAw8qVSfdrLtaAaBHraseSCyx5FYuUzK3HEebD+aSUpeDWODnVi9OGxEVtYabBKJhMWTfXh3ewI2Fopbrh50zbVFdWLTyjlysQA/t5Fx06OQy4wmBHfl2gI+wsDrtVcPHjzIBx98AIC7uzs5OTksXLiQ/fv3G0bHf/Ob37B+/XoRlP9I6XQ6ziSWEOpjN6CPLoXbU2+TvPor2FPJjuNZtLa14+YoFv26VUP92DvAU4mtmT/3z/Snpa1d3FSNUHPGemBracKYYKc+3bDNHO3OyUvFjA5w5IFZ/rddLv1AivCzx9/NZsCf+AR42HL4QgGWZnJ+uXTUoD3VEm4fvZ49S0tLUan05X+2bdvGgQMHUCgUTJ48maVLl/K73/2OUaNGkZmZOeiNFYZHRmEt5TUtfZq4Iwj9dS2vvLKulXEhP51FmX6MREA+cinkUib3o9SchZmcN1ZPGsQW3T4kEgl/eigaBvi+JNzHnu8vFrJ6SfigVhwRbh+93pZZWVlRUVEB6L+YGRn6yQ6ZmZm0tenLxzQ2NmJmJr5QP1aXMiuRSSWDtsqW8NPm42pjGCEaKZVXBEEQOjI1kQ14SlikvwMbfz/dUMJUEHoNyidNmsShQ4cA+OMf/8jPfvYzli9fzhNPPMGzzz4LwIkTJxg3btzgtlQYNmn5NXi7WoscMmFQKORS/N30E25E5RVBEH4qJCI3W7hBr9+GJ598kqeeeoo5c+Zw1113MXXqVHJzc/H29sbW1paKigree+893nvvvaForzDE1O0asovrmDt2ZNXyFH5cQr3tyCisvemFMgRBEAThdtfrSLmfnx/PPfccjz32GHv37sXCwoLIyEgsLS05ePAgjz76KGvWrCEkJGQo2isMsezieto1OgI9bXvfWRBu0p0TvXhp1bhBXxFWEARBEEaqPl0B58+fT0BAAB999BF/+9vfAJBKpURHR7Nx40YCAwMHtZHC8EnLrwH0pfAEYbDoy4OJRakEQRCEn64+D0v5+fnx5ptvDmZbhBEoraAGN0fLAavNKgiCIAiCIHTWp6BcrVajUOiDsgsXLqDT6QzboqOjkcvFI+cfI61WR2ZhLRNDXYa7KYIgCIIgCD9qvUbTX3zxBXFxcbz99tuAfuKnUqlPZWhpaeFPf/oTy5Yt6/VA2dnZrF27lpqaGpRKJevXr8fHx8donx07dvDpp58ilUrRarUsW7aMlStXAvDcc8+Rmppq2Dc1NZX333+fOXPmsHHjRr744gucnfU1jseMGcMrr7zStx4QupVf1kBzq4ZAT5G6IgiCIAiCMJh6Dcp37tzJq6++avi3iYkJx48fByA5OZl169b1KSh/5ZVXWLFiBUuXLmXnzp28/PLLbN682WifO++8k/vuuw+JREJDQwNLlixhwoQJhISE8NZbbxn2S0lJYdWqVUyfPt3w2j333MPzzz/f+08s9FlagT6fPEjkkwuCIAiCIAyqXquvFBQUGFVW8ff3N/x3SEgI+fn5vR6ksrKSpKQkFi9eDMDixYtJSkqiqqrKaD8rKyskV5fybWlpQa1WG/7d0VdffcWSJUswMRnYJW8FY+n5NTjYmIqVxgRBEARBEAZZryPlTU1NNDU1YWFhAcCWLVuMtjU3N/d6kOLiYlxcXJDJ9KthyWQynJ2dKS4uxt7e3mjfI0eOsGHDBvLy8vjjH/9IcHCw0fa2tjZ27drFp59+avT6nj17OHnyJE5OTvz2t78lOjq613Z15OBg1a/9B5KT08irOqHT6cgoqiMq0GnEtW+ktWekE/3Vf6LP+kf0V/+JPusf0V/9J/qsf0ZCf/UalAcGBnLq1CnmzZvXadvJkycJCAgY0AbNmTOHrlvyEAAAIABJREFUOXPmUFRUxK9//WtmzJiBn5+fYfvhw4dxc3MjNDTU8NpDDz3E008/jUKh4NSpU/zqV79i79692NnZ9fm4lZUNaLW63nccYE5O1pSX1w/5cXtTWtVETX0rXk6WI6p9I7W/RirRX/0n+qx/RH/1n+iz/hH91X+iz/pnKPtLKpV0OxDca/rKqlWrePXVVzl8+DBarRYArVbLoUOHeO2111i1alWvDVCpVJSWlqLRaADQaDSUlZWhUqm6fY+bmxsREREcO3bM6PUdO3Zw//33G73m5ORkqA4zdepUVCoV6enpvbZL6N6VbH1qkZjkKQiCIAiCMPh6HSlftGgRpaWlPPvss6jVapRKJTU1NSgUCn79618b8sR74uDgQGhoKLt372bp0qXs3r2b0NDQTqkrmZmZhpz1qqoqYmJimD9/vmF7SUkJFy9eZMOGDUbvKy0txcVFX7YvOTmZwsJCfH19e//phS4Vljfw1fFMfFU2qBwshrs5giAIgiAIP3p9KjD+xBNPsHz5cuLi4qiurkapVBIdHY21dd/zb9atW8fatWvZtGkTNjY2rF+/HoDVq1ezZs0aIiIi2Lp1K6dOnUIul6PT6Xj00UeZNm2a4TO++eYbZs+eja2t8ZLvGzZsIDExEalUikKh4K233sLJyanPbROua2hWs3HHZcwUMn5zXwTSLibaCoIgCIIgCANLouu4ElAXampquHTpEjNmzOi07cSJE4wePbpTkHw7EjnloNFqeXdbAqn5NTy3YgwB7iPv9zqS+ut2IPqr/0Sf9Y/or/4TfdY/or/6T/RZ/4yUnPJeR8r/8Y9/oFQquwzKk5OTOXPmjKgPfhtLy6/h0Pl8KmpbqKhtprGlnZ/dFTIiA3JBEARBEIQfq14neh49epQHH3ywy23Lly/nyJEjA94oYWhU1bWwcccl0gtrsbE0YUKoC0/dHcb/b+/Oo6Osz/6Pv2eSsGjMShImLIZQCFGgUiNWZVESIU+Nsmgs0ghixQUKSIGaapvg8tQn8CsH9QnlPChQWopUoETD4hLFIi5AoYKGKEYkhWyQBRJCFib37w/K1EiSmcEkd5L5vM7hnMm9zH3NdWa+XPnmur8zcmi42aGJiIiIeBSnM+WnTp265IbMiwICAjh16lSLByWtr94weDkzmzp7Pb+ZGkNYkG7oFBERETGL05lyf39/vv7660b3HT16FD8/vxYPSlrfm3vyyMkrZ0rcQBXkIiIiIiZzWpTHxcXx3//931RXVzfYXl1dzfPPP8+4ceNaLThpHccKK9j8/tdcPzCEkUObXiteRERERNqG0/aVuXPnMm3aNOLi4hg5ciQhISGcPHmSXbt2YbPZmD17dlvEKS3kvL2el7dmc9UVPkz7r0FYtOShiIiIiOmczpT7+vry6quvMnfuXGpqavjss8+oqalh7ty5rFu3Dl/fxpd1kfZpxyd5nDh5lqnjBuHb3cfscEREREQEF788yMfHh8TERBITE1s7HmlFhaVVvL77G2KiQrhuQA+zwxERERGRf3OpKD916hSrVq3iH//4B+Xl5QQEBBATE8MDDzygb87sIAzDYO2OHHy8rUy5faDZ4YiIiIjItzgtyk+ePMmkSZMICgoiNjaW0NBQioqKeO+998jIyGDz5s2Ehoa2RazyPXxwsICcvHKmxUcR4NvV7HBERERE5FucFuUrVqxg2LBhLFu2DKv1Py3oc+bMYd68eaxYsYKUlJRWDVK+H8Mw2PrRMSLD/Rj5Q30xkIiIiEh74/RGz927dzN37twGBTmAxWJh9uzZ7N69u9WCk5aRm3+G4vJzjL4uHKtWWxERERFpd5wW5SdPniQiIqLRfRERERQXF7d0TNLCPvqsEB9vKzFRajMSERERaY+cFuUAXl5eTW7XOtft23l7PXsOFzFsQA+6d3Xpvl4RERERaWNOq7Samhp+9atfNbrPMAxqa2tbPChpOQdzSzhbfZ6bB/c0OxQRERERaYLTovzRRx/9XvvFXB99VojfFT5c2y/I7FBEREREpAlOi/Jf/OIXbRGHtILKc3V8mnuKW4f1wsvqUqeSiIiIiJjAaVG+d+9ep09yww03OD3m6NGjJCcnO758KC0t7ZIbSDdt2sSaNWuwWq3U19eTmJjI1KlTAXjppZf4y1/+4lgT/Uc/+hGpqakAnDt3jl//+td8/vnneHl58cQTT3Dbbbc5jamz25tTzHm7odYVERERkXbOaVG+YMGCRrdbLBbOnDnDuXPnOHz4sNMLpaamMmXKFMaPH09GRgYpKSmsXbu2wTHjxo1j0qRJWCwWKisrufPOOxk+fDiDBg0CYMKECTzxxBOXPPcrr7yCr68vb7/9Nt988w0/+9nPeOutt7jyyiudxtVZnT5by5uf5GELvoKrw64yOxwRERERaYbTnob333//kn+bN28mLi4OgMmTJzu9SElJCdnZ2SQkJACQkJBAdnY2paWlDY7z9fV1rOZSXV1NXV2dS6u7bN++nZ/+9KfAhWUaBw8ezN///nen53VWZ6pq+X/rD1B+toZp8YO0Qo6IiIhIO+fWGnlnzpxh5cqVrF+/nttvv53XX3+d3r17Oz2voKCAsLAwx9KKXl5ehIaGUlBQQFBQwxsQs7KyWLp0KXl5ecyfP5+oqCjHvq1bt/LBBx8QEhLC7NmzGTZsGAD5+fn06tXLcZzNZqOwsNCdl0ZwsK9bx7ekkJCWm8k+c7aWZX/cx8nyc6TO+DFDfxDSYs/dXrRkvjyB8uU+5cw9ypf7lDP3KF/uU87c0x7y5VJRXlVVxapVq1i7di0333wzf/3rX4mMjGyVgGJjY4mNjSU/P59Zs2YxatQoIiMjmTx5Mo8++ig+Pj7s3r2bmTNnsm3bNgIDA1vkuiUlldTXGy3yXO4ICbmKkycrWuz5fr/hnxwvrmTOPUOw+Xdr0eduD1o6X52d8uU+5cw9ypf7lDP3KF/uU87c05b5slotTU4EO21feeWVV4iNjeXzzz9n7dq1LFu2zO2C3GazUVRUhN1uB8But1NcXIzNZmvynPDwcIYMGcLOnTsBCAkJwcfHB4BbbrkFm83GkSNHHMeeOHHCcW5BQQE9e3rezY1nztaSfbSUn/y4L4P7BZsdjoiIiIi4yOlM+ZIlS/D39+f06dM8++yzjR6zbt26Zp8jODiY6OhoMjMzGT9+PJmZmURHR1/SupKbm0v//v0BKC0t5ZNPPmHs2LEAFBUVERYWBsDhw4c5ceIE/fr1AyA+Pp4NGzYwZMgQvvnmGw4dOsTvf/97Zy+t0zn0dQkGMGxA52tZEREREenMnBblzz//fItcaNGiRSQnJ7N8+XL8/PxIS0sDYMaMGcyZM4chQ4awYcMGdu/ejbe3N4ZhkJSUxIgRIwBYunQpn3/+OVarFR8fHxYvXkxIyIXi8+c//znJycncfvvtWK1WnnnmGXx9zesRN8unuSX4+3ahb5jnvXYRERGRjsxiGEbbN1K3Qx29p/y8vZ65L+4iJiqU6T+JboHI2if1yblH+XKfcuYe5ct9ypl7lC/3KWfu6TA95dIxHDl+mnM1dn74gx5mhyIiIiIiblJR3kl8+tUpvL0sXBPRMqvRiIiIiEjbUVHeSRzMLSGqbyDduri19LyIiIiItAMqyjuBorIqCkurGNpfyyCKiIiIdEQuT6vW1tbyt7/9jcOHD1NVVdVg3+LFi1s8MHHdwa9KAPihinIRERGRDsnlojw5OZmcnBxuu+02evTQzYTtycHcU9iCryA08AqzQxERERGRy+ByUb5r1y6ysrLw8/NrzXjETYZhkJt/hpsGe943mIqIiIh0Fi73lNtsNmpra1szFrkMFVV1VNfa6alZchEREZEOy+WZ8gkTJjBz5kymTp1KcHDD3uWbbrqpxQMT1xSXnQMgLKi7yZGIiIiIyOVyuSj/85//DFz4uvtvs1gsZGVltWxU4rKisgs33aqfXERERKTjcrkof/fdd1szDrlMRWXnsFigh383s0MRERERkcvk1jfNnD9/ngMHDlBUVETPnj257rrr8PbWl9WYqbisih7+3fD20pLzIiIiIh2VyxV1bm4ujz32GNXV1dhsNgoKCujatSsrVqygf//+rRmjNKOo7JxaV0REREQ6OJenV59++mnuvfde3n//fTZs2MDf//53Jk+ezKJFi1oxPGmOYRgUl50jNFA3eYqIiIh0ZC4X5Tk5OUyfPh2LxeLYNm3aNHJyclolMHGu8lwd52rOE6aZchEREZEOzeWiPDQ0lD179jTYtm/fPkJDQ1s8KHHNxeUQNVMuIiIi0rG53FM+b948Zs6cya233kp4eDj5+fns3LmTJUuWuHT+0aNHSU5Opry8nICAANLS0oiIiGhwzKZNm1izZg1Wq5X6+noSExOZOnUqAOnp6Wzbtg2r1YqPjw/z5s1j5MiRACQnJ/Phhx8SGBgIQHx8PI899pirL63DurgcYpiKchEREZEOzeWiPDY2ls2bN7N9+3aKi4sZMGAAc+bMoV+/fi6dn5qaypQpUxg/fjwZGRmkpKSwdu3aBseMGzeOSZMmYbFYqKys5M4772T48OEMGjSIoUOH8uCDD9K9e3dycnJISkrigw8+oFu3C0sBPvzwwyQlJbnx0ju+YsdyiCrKRURERDoyt9Yz7NevHzNnznT7IiUlJWRnZ7N69WoAEhISePbZZyktLSUoKMhxnK+vr+NxdXU1dXV1jh72i7PiAFFRURiGQXl5OT179nQ7ns6iuOwcwX7d8PHWcogiIiIiHVmzRflvf/tbnn32WQAWLlzY4CbPb1u8eHGzFykoKCAsLAwvLy8AvLy8CA0NpaCgoEFRDpCVlcXSpUvJy8tj/vz5REVFXfJ8W7ZsoW/fvg0K8tWrV7Nhwwb69OnD/Pnz3V6mMTjY1/lBrSQk5KrLOq+0sobeoVdd9vkdlae93u9L+XKfcuYe5ct9ypl7lC/3KWfuaQ/5arYo7927t+Px1Vdf3erBwIU2mdjYWPLz85k1axajRo0iMjLSsX/Pnj288MILrFq1yrFt3rx5hISEYLVa2bJlCw899BDvvPOO45cAV5SUVFJfb7Toa3FFSMhVnDxZcVnnniiuZHh02GWf3xF9n3x5IuXLfcqZe5Qv9yln7lG+3Kecuact82W1WpqcCG62KH/kkUccj3/6058SEhJyyTEnT550GoDNZqOoqAi73Y6Xlxd2u53i4mJsNluT54SHhzNkyBB27tzpKMoPHDjAwoULWb58eYNCPSwszPF4woQJPP/88xQWFtKrVy+nsXVUlefqOFt9XiuviIiIiHQCLjcjjxs3rtHtd9xxh9Nzg4ODiY6OJjMzE4DMzEyio6MvaV3Jzc11PC4tLeWTTz5h4MCBABw8eJB58+bx4osvcu211zY4r6ioyPF4165dWK3WBoV6Z6TlEEVEREQ6D5dv9DSMS1s7Kisrm+wz/65FixaRnJzM8uXL8fPzIy0tDYAZM2YwZ84chgwZwoYNG9i9ezfe3t4YhkFSUhIjRowALnyjaHV1NSkpKY7nXLx4MVFRUTzxxBOUlJRgsVjw9fXlD3/4A97ebt3D2uEUO5ZD1BcHiYiIiHR0TivX0aNHY7FYqKmp4dZbb22wr7y83KWZcoD+/fvz2muvXbJ95cqVjsdPPvlkk+dv2rSpyX1r1qxxKYbOpKjsHBYgJKCb2aGIiIiIyPfktChfsmQJhmHw8MMPN1hlxWKxEBwc3KC3W9pOcVkVQX5d8fF2/WZWEREREWmfnBblw4cPB+Djjz+me3f1L7cXxWXnCFXrioiIiEin4HLjdffu3Tl8+DD79u2jrKysQY/53LlzWyU4T1RVfZ6NO7/i1mG96Bv2nzUz687bWbvjC74pqqDibC1nquq4dVjnXV1GRERExJO4vPrKhg0buO+++/j4449ZuXIlX375JatXryYvL6814/MohmGw9s0cdv4zn5c2HaLyXJ1j36vvfsXuzwoJ8e/OjwaGcOfNEcTf2NfEaEVERESkpbg8U/7yyy/z8ssvExMTww033EB6ejrvv/8+27Zta834PMqugwXsOVzMzYN78kl2Ea9kZjP7nqHsPVzMe/tPED+8L/eO+YHZYYqIiIhIC3N5prykpISYmJgLJ1mt1NfXM3r0aN57771WC86TnDhZyV/e/pJrIgJ58I5oJscO4NPcEta99SVrduTwg97+TBqtm2pFREREOiOXZ8p79uzJ8ePH6d27NxEREWRlZREYGIiPj09rxucRztvrWZHxOd26eDEj4RqsFgtjftSLI8fLee/ACXy7+/DoXdfi7eXy71AiIiIi0oG4XJQ/9NBD5Obm0rt3b2bOnMncuXOpq6vjqaeeas34PMK/iis5ceosP78jGn/frsCFJScf+K9B+HhbGTk0nCA/rUcuIiIi0lm5XJRPmjTJ8Xj06NHs2bOHuro6rrzyylYJzJOcOVsLQM/ghkscduvizc/vuMaMkERERESkDTVblNfX1zd9orc33t7e1NfXY7WqreL7OFN1oSj3u6KLyZGIiIiIiBmaLcqvueYaLBaL0yc5fPhwiwXkiSqrLix9eNUV6s8XERER8UTNFuVZWVmOxzt37uTNN9/kkUceITw8nPz8fFauXMnYsWNbPcjOrqKqDh9vK119vMwORURERERM0GxR3qvXf74xcs2aNWzatAk/Pz8A+vXrx+DBg7n77ruZMmVK60bZyZ2pqsXvCh+X/iohIiIiIp2Py83gFRUVnDt3rsG26upqKioqWjwoT1NRVYev+slFREREPJbLq69MnDiR6dOnM23aNHr27ElhYSF/+tOfmDhxYmvG5xEqqmrVTy4iIiLiwVwuyhcuXEjfvn3Ztm0bxcXFhISE8LOf/Yx77723NePzCBVVtYT30NKSIiIiIp7K5aLcarVy3333cd99913WhY4ePUpycjLl5eUEBASQlpZGREREg2M2bdrEmjVrsFqt1NfXk5iYyNSpUwGw2+0899xz7Nq1C4vFwsMPP0xiYqLTfR1BRVWdZspFREREPFizRfmWLVuYMGECABs3bmzyuHvuucfphVJTU5kyZQrjx48nIyODlJQU1q5d2+CYcePGMWnSJCwWC5WVldx5550MHz6cQYMG8cYbb5CXl8dbb71FeXk5EyZM4KabbqJ3797N7mvvqmvOU3u+XmuUi4iIiHiwZm/03Lp1q+NxRkZGo/9ef/11pxcpKSkhOzubhIQEABISEsjOzqa0tLTBcb6+vo4VSKqrq6mrq3P8vG3bNhITE7FarQQFBREXF8eOHTuc7mvvyitrAPDVTLmIiIiIx2p2pnzlypWOx3/6058u+yIFBQWEhYXh5XVhHW4vLy9CQ0MpKCggKCiowbFZWVksXbqUvLw85s+fT1RUlOM5wsPDHcfZbDYKCwud7nNVcLDvZb227+vLvDIAetv8CQm5ypQYOhrlyT3Kl/uUM/coX+5TztyjfLlPOXNPe8hXs0V5fX29S09itbq8sqJTsbGxxMbGkp+fz6xZsxg1ahSRkZEt9vxNKSmppL7eaPXrfNfpf8+UG3V2Tp7U8pLOhIRcpTy5Qflyn3LmHuXLfcqZe5Qv9yln7mnLfFmtliYngpstyq+55ppmv9DGMAwsFguHDx9uNgCbzUZRURF2ux0vLy/sdjvFxcXYbLYmzwkPD2fIkCHs3LmTyMhIbDYb+fn5DB06FGg4O97cvvbuYlGuGz1FREREPFezRXlWVlaLXCQ4OJjo6GgyMzMZP348mZmZREdHX9K6kpubS//+/QEoLS3lk08+YezYsQDEx8fz2muvMXbsWMrLy3nnnXdYt26d033t3enKWkBFuYiIiIgna7Yo79WrV4tdaNGiRSQnJ7N8+XL8/PxIS0sDYMaMGcyZM4chQ4awYcMGdu/ejbe3N4ZhkJSUxIgRIwAYP348n376qaNInzVrFn369HG6r707fbaWLt5Wuvp4mR2KiIiIiJjEYhiGy43UWVlZ7N27l7KyMr592uLFi1sluLZkVk/5n985wqdfFrNk5i1tfu2OSH1y7lG+3KecuUf5cp9y5h7ly33KmXvaS0+5y3do/u///i+pqanU19ezY8cOAgIC+OCDD/Dz82uxQD3R6coafLVGuYiIiIhHc7ko37RpE6tWreLJJ5/Ex8eHJ598khUrVnD8+PHWjK/TO322Vl8cJCIiIuLhXC7Kz5w5w8CBAwHw8fGhrq6OoUOHsnfv3lYLzhOcrqzRTZ4iIiIiHq7ZGz2/rW/fvhw5coQBAwYwYMAA1q9fj5+fH/7+/q0ZX6d3urJWRbmIiIiIh3O5KH/88ccpLy8HYMGCBcyfP5+qqipSU1NbLbjOrqbWTm2dXe0rIiIiIh7OaVFeX1+P1Wpl9OjRjm1Dhw7l7bffbtXAPMGZqgtrlPtqplxERETEozntKR81ahSLFy/myy+/bIt4PEpFVR0AV2mmXERERMSjOS3KFy1axPHjx7nnnnuYOHEif/zjHyktLW2L2Dq9in/PlKt9RURERMSzOW1fiYuLIy4ujjNnzrBt2zYyMjJYsmQJI0aMYOLEiYwZMwYfH7VfXI6L7Su60VNERETEs7m8JKKfnx+TJ09m/fr1bN++ncGDB/P8888zYsSI1oyvU6t0tK+oKBcRERHxZC4X5RfV1tZy6NAhDh48yKlTpxxrl4v7Kqrq6OLjRVcfL7NDERERERETubwk4r59+8jIyGDHjh0EBQVx1113kZqaSq9evVozvk7tTFUt/r5dsFgsZociIiIiIiZyWpS/9NJLvP7665SXlxMfH8+KFSu4/vrr2yK2Tq+iqg7/K3WTp4iIiIinc1qUf/rppzz++OPExcXRtWvXtojJY1RU1RIc0N3sMERERETEZE6L8pdffrkt4vBIFVW1RPYOMDsMERERETGZ2zd6SsupqKrD31d/fRARERHxdCrKTVJTa6f2fL16ykVERETE9dVXvq+jR4+SnJxMeXk5AQEBpKWlERER0eCY9PR0tm3bhtVqxcfHh3nz5jFy5EgAHnjgAcrKygCw2+0cOXKEjIwMBg0aRHJyMh9++CGBgYEAxMfH89hjj7XVS7ssF784yN9XRbmIiIiIp2uzojw1NZUpU6Ywfvx4MjIySElJYe3atQ2OGTp0KA8++CDdu3cnJyeHpKQkPvjgA7p168aaNWscx73zzjssW7aMQYMGObY9/PDDJCUltdXL+d4qz1344iA/ta+IiIiIeLw2aV8pKSkhOzubhIQEABISEsjOzqa0tLTBcSNHjqR79wurkURFRWEYBuXl5Zc838aNG7n77rtbP/BW1DvEl4SbIxj6gx5mhyIiIiIiJmuTmfKCggLCwsLw8rrwzZVeXl6EhoZSUFBAUFBQo+ds2bKFvn370rNnzwbbT548yUcffcTvfve7BttXr17Nhg0b6NOnD/Pnz6d///5uxRgc7OvW8S3hkbt/CEC3kKva/NodWYjy5Rbly33KmXuUL/cpZ+5RvtynnLmnPeSrzdpX3LFnzx5eeOEFVq1adcm+LVu2MHLkyAbF/Lx58wgJCcFqtbJlyxYeeugh3nnnHccvAa4oKamkvt5okfjdERJyFSdPVrT5dTsq5cs9ypf7lDP3KF/uU87co3y5TzlzT1vmy2q1NDkR3CbtKzabjaKiIux2O3DhRs3i4mJsNtslxx44cICFCxeSnp5OZGTkJfs3b958SetKWFgYVuuFlzJhwgSqqqooLCxshVciIiIiItLy2qQoDw4OJjo6mszMTAAyMzOJjo6+pHXl4MGDzJs3jxdffJFrr732kufZv38/FRUVjBo1qsH2oqIix+Ndu3ZhtVoJCwtrhVciIiIiItLy2qx9ZdGiRSQnJ7N8+XL8/PxIS0sDYMaMGcyZM4chQ4bw9NNPU11dTUpKiuO8xYsXExUVBVyYJZ8wYcIlbSlPPPEEJSUlWCwWfH19+cMf/oC3d7vszBERERERuYTFMIy2b6Ruh8rKzprSUx4c7EtJSWWbX7ejUr7co3y5Tzlzj/LlPuXMPcqX+5Qz97RlvqxWC4GBVza6T0W5iIiIiIjJ2qSnXEREREREmqaiXERERETEZCrKRURERERMpqJcRERERMRkKspFREREREymolxERERExGQqykVERERETKaiXERERETEZCrKRURERERMpqJcRERERMRk3mYH4KmOHj1KcnIy5eXlBAQEkJaWRkREhNlhtRtlZWX86le/Ii8vjy5dunD11VfzzDPPEBQURFRUFAMHDsRqvfA75eLFi4mKijI5YvONGTOGLl260LVrVwAWLFjAyJEj+ec//0lKSgo1NTX06tWLJUuWEBwcbHK05jt+/DizZs1y/FxRUUFlZSV79uxpMpeeJi0tjTfffJMTJ07wxhtvMHDgQKD58cvTx7bGctbceAZ49JjW1Husuc+gp49pjeWsufEMms9nZ9fc56+595Ip7zNDTHH//fcbW7ZsMQzDMLZs2WLcf//9JkfUvpSVlRkff/yx4+f/+Z//MX79618bhmEYAwcONCorK80Krd267bbbjC+++KLBNrvdbsTFxRl79+41DMMw0tPTjeTkZDPCa/eee+454+mnnzYMo/FceqK9e/ca+fn5l+SjufHL08e2xnLW3HhmGJ49pjX1HmvqM6gxremcfdu3xzPD8OwxranPX3PvJbPeZ2pfMUFJSQnZ2dkkJCQAkJCQQHZ2NqWlpSZH1n4EBARw4403On6+7rrryM/PNzGijumzzz6ja9euxMTEADB58mR27NhhclTtT21tLW+88QZ333232aG0KzExMdhstgbbmhu/NLY1njONZ01rLF/N0ZjmPGcazxpq6vPX3HvJrPeZ2ldMUFBQQFhYGF5eXgB4eXkRGhpKQUGB48+Z8h/19fWsX7+eMWPGOLbdf//92O12Ro0axezZs+nSpYuJEbYfCxYswDAMrr/+en75y19SUFBAeHi4Y3/I9ixbAAAGd0lEQVRQUBD19fWO1gK54N133yUsLIxrr73Wse27ufTz8zMxwvajufHLMAyNbU40Np6BxrTGNPYZ1JjmXGPjGWhMg4afv+beS2a9zzRTLu3es88+yxVXXEFSUhIAO3fuZPPmzaxbt46vvvqK9PR0kyNsH9atW8frr7/Opk2bMAyDZ555xuyQOoxNmzY1mFVSLqW1fHc8A41pjdFn8PJ9dzwD5fOixj5/7YmKchPYbDaKioqw2+0A2O12iouL3foTnqdIS0vj2LFjLFu2zHET1MU8+fr6kpiYyP79+80Msd24mJcuXbowZcoU9u/fj81ma/Bn8tLSUqxWq2aUvqWoqIi9e/dy5513OrY1lku5oLnxS2Nb8xobz0BjWmOa+gxqTGteY+MZaEyDSz9/zb2XzHqfqSg3QXBwMNHR0WRmZgKQmZlJdHS0/rz7HUuXLuWzzz4jPT3d8afc06dPU11dDcD58+d58803iY6ONjPMdqGqqoqKigoADMNg27ZtREdHM3jwYKqrq9m3bx8Ar776KvHx8WaG2u787W9/Y/To0QQGBgJN51IuaG780tjWtMbGM9CY1pjmPoMa05r33fEMNKZB45+/5t5LZr3PLIZhGK1+FblEbm4uycnJnDlzBj8/P9LS0oiMjDQ7rHbjyJEjJCQkEBERQbdu3QDo3bs3Dz30ECkpKVgsFs6fP8+wYcN48sknufLKK02O2Fz/+te/mD17Nna7nfr6evr3789vfvMbQkND2b9/P6mpqQ2WderRo4fZIbcb48aN46mnnmLUqFFA87n0NM899xxvvfUWp06dIjAwkICAALZu3drs+OXpY1tjOVu2bFmj41l6ejoHDhzw6DGtsXytWLGi2c+gp49pTX0u4dLxDDSmNVVPpKenN/teMuN9pqJcRERERMRkal8RERERETGZinIREREREZOpKBcRERERMZmKchERERERk6koFxERERExmYpyERFpFVFRURw7dszsMEREOgRvswMQEZG2MWbMGE6dOoWXl5dj28SJE0lJSTExKhERARXlIiIeZcWKFdx8881mhyEiIt+h9hUREQ+3efNmJk+ezDPPPMP1119PfHw8H330kWN/UVERjz76KMOHD+f222/nr3/9q2Of3W5nxYoVxMXFMWzYMCZNmkRBQYFj/4cffsjYsWOJiYnh6aef5uL31R07doykpCSuv/56brzxRh5//PG2e8EiIu2QZspFRISDBw8SHx/Pxx9/zNtvv80vfvELsrKyCAgI4Je//CUDBgxg165dfP3110yfPp0+ffpw0003sXr1arZu3cr//d//0a9fP7744gvHV1kD7Ny5k40bN1JZWcmkSZO47bbbGDVqFC+88AK33HILa9eupa6ujkOHDpn46kVEzKeZchERDzJr1ixiYmIc/y7OegcFBTFt2jR8fHz4yU9+Qr9+/di5cycFBQXs37+fBQsW0LVrV6Kjo0lMTCQjIwOA1157jblz5xIZGYnFYmHQoEEEBgY6rjdjxgz8/PwIDw/nxhtvJCcnBwBvb2/y8/MpLi6ma9euxMTEtH0yRETaERXlIiIeJD09nX379jn+3XvvvQCEhYVhsVgcx4WHh1NcXExxcTH+/v74+vo22FdUVARAYWEhffv2bfJ6ISEhjsfdu3fn7NmzACxcuBDDMLjnnnu444472LhxY4u+ThGRjkbtKyIiQlFREYZhOArzgoICxowZQ2hoKKdPn6aystJRmBcUFBAWFgZAz549ycvLY+DAgW5dLyQkhOeeew6Affv2MX36dG644QauvvrqFnxVIiIdh2bKRUSE0tJSR3/39u3byc3NZfTo0dhsNoYNG8bSpUupqakhJyeHjRs3ctdddwGQmJjICy+8wDfffINhGOTk5FBWVub0etu3b6ewsBAAf39/LBYLVqv+SxIRz6WZchERD/Loo482WKf85ptvJjY2lqFDh3Ls2DF+/OMf06NHD1588UVHb/jSpUtJTU1l5MiR+Pn5MXv2bMeyitOnT6e2tpYHH3yQsrIyIiMjSU9PdxrHoUOH+N3vfkdlZSXBwcE89dRT9OnTp3VetIhIB2AxLq5PJSIiHmnz5s289tprrF+/3uxQREQ8lv5WKCIiIiJiMhXlIiIiIiImU/uKiIiIiIjJNFMuIiIiImIyFeUiIiIiIiZTUS4iIiIiYjIV5SIiIiIiJlNRLiIiIiJisv8PJMM25Sjq5U4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@100\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr, test_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'test_tr.csv'),\n",
    "    os.path.join(pro_dir, 'test_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)\n",
    "\n",
    "batch_size_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "#     int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "# print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I/model\n"
     ]
    }
   ],
   "source": [
    "n10_list = []\n",
    "r1_list, r5_list = [], []\n",
    "# p1_list, p5_list = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        \n",
    "        n10_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=10))\n",
    "        MAP = MAP(pred_val, test_data_te[idxlist_test[st_idx:end_idx]])\n",
    "\n",
    "#         p1_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        p1 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "#         r1_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        recall, rec_1 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "        r1_list.append(recall)\n",
    "        \n",
    "#         p5_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        p5 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "#         r5_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        recall, rec_5 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "        r5_list.append(recall)\n",
    "\n",
    "n10_list = np.concatenate(n10_list)\n",
    "\n",
    "# p1_list = np.concatenate(p1_list)\n",
    "r1_list = np.concatenate(r1_list)\n",
    "\n",
    "# p5_list = np.concatenate(p5_list)\n",
    "r5_list = np.concatenate(r5_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@10=0.4509555768985105\n",
      "Test MAP=0.3955997488960455\n",
      "Test Prec@1=0.56\n",
      "Recall: 0.033667334669338675\n",
      "F1@1 0.06351606805293006\n",
      "Test Prec@5=0.46\n",
      "Recall: 0.13827655310621242\n",
      "F1@5 0.21263482280431437\n"
     ]
    }
   ],
   "source": [
    "# print(\"Test NDCG@10=%f (%f)\" % (np.mean(n10_list), np.std(n10_list) / np.sqrt(len(n10_list))))\n",
    "print(\"Test NDCG@10={}\".format(np.mean(n10_list)))\n",
    "print(\"Test MAP={}\".format(MAP))\n",
    "# print(\"Test Prec@1=%f (%f)\" % (np.mean(p1_list), np.std(p1_list) / np.sqrt(len(p1_list))))\n",
    "print(\"Test Prec@1={}\".format(p1))\n",
    "# print(\"Test Recall@1=%f (%f)\" % (np.mean(r1_list), np.std(r1_list) / np.sqrt(len(r1_list))))\n",
    "# print(\"Test Recall@1={}\".format(np.mean(r1_list)))\n",
    "# print('F1@1', F1_score(p1, np.mean(r1_list)))\n",
    "\n",
    "print('Recall:', rec_1)\n",
    "print('F1@1', F1_score(p1, rec_1))\n",
    "\n",
    "# print(\"Test Prec@5=%f (%f)\" % (np.mean(p5_list), np.std(p5_list) / np.sqrt(len(p5_list))))\n",
    "print(\"Test Prec@5={}\".format(p5))\n",
    "# print(\"Test Recall@5=%f (%f)\" % (np.mean(r5_list), np.std(r5_list) / np.sqrt(len(r5_list))))\n",
    "# print(\"Test Recall@5={}\".format(np.mean(r5_list)))\n",
    "# print('F1@1', F1_score(p5, np.mean(r5_list)))\n",
    "print('Recall:', rec_5)\n",
    "print('F1@5', F1_score(p5, rec_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
