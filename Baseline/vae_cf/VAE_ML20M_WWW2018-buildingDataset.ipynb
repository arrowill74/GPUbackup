{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders for collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
    "\n",
    "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
    "DATA_DIR = './'\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data and create train/validation/test splits following strong generalization: \n",
    "\n",
    "- We split all users into training/validation/test sets. \n",
    "\n",
    "- We train models using the entire click history of the training users. \n",
    "\n",
    "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv(os.path.join('../../User/output/', 'UserFollowingsMat.csv'))\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data.rename(columns={'Unnamed: 0':'userId'}, inplace=True)\n",
    "# raw_data = raw_data.set_index('userId')\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['userId', 'movieId'])\n",
    "# for uid, row in raw_data.iterrows():\n",
    "#     for movie in row[row == 1].index:\n",
    "#         df = df.append({'userId': uid, 'movieId': movie}, ignore_index = True)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('../UserFollowingRecord.csv', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>99</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>99</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>99</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>99</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>99</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1395 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  movieId\n",
       "0          0       26\n",
       "1          0       48\n",
       "2          0       75\n",
       "3          0       77\n",
       "4          0       78\n",
       "...      ...      ...\n",
       "1390      99      126\n",
       "1391      99      127\n",
       "1392      99      128\n",
       "1393      99      151\n",
       "1394      99      160\n",
       "\n",
       "[1395 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(pro_dir, 'UserFollowingRecord.csv'))\n",
    "raw_data = df\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
    "- Use all the items from the training users as item set\n",
    "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep items that are clicked on by at least 5 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 1395 watching events from 100 users and 153 movies (sparsity: 9.118%)\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_uid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create train/validation/test users\n",
    "n_users = unique_uid.size\n",
    "n_heldout_users = 25 #coldstart=25 #MRM=150\n",
    "\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)] # -1282\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)] # 1282-1432\n",
    "te_users = unique_uid[(n_users - n_heldout_users):] # 1432- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_sid = pd.unique(raw_data['movieId']) #train_plays['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n"
     ]
    }
   ],
   "source": [
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n"
     ]
    }
   ],
   "source": [
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective for Multi-DAE for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
    "$$\n",
    "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiVAE(MultiDAE):\n",
    "\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "\n",
    "        # placeholders with default values when scoring\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        \n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # q-network\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "\n",
    "        sampled_z = mu_q + self.is_training_ph *\\\n",
    "            epsilon * std_q\n",
    "\n",
    "        # p-network\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        \n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        \n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                # we need two sets of parameters for mean and variance,\n",
    "                # respectively\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            \n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    }
   ],
   "source": [
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
    "                                           os.path.join(pro_dir, 'validation_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 153)\n",
      "(25, 153) (25, 153)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(vad_data_tr.shape, vad_data_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "# training batch size\n",
    "batch_size = 500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = range(N_vad)\n",
    "\n",
    "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
    "batch_size_vad = 50 # 2000\n",
    "\n",
    "# the total number of gradient updates for annealing\n",
    "total_anneal_steps = 200000\n",
    "# largest annealing parameter\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0] # 150\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "    recall = tmp / X_true_binary.sum(axis=1)\n",
    "    rec = np.sum(tmp) / np.sum(X_true_binary.sum(axis=1))\n",
    "    return recall, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prec_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "#     prec = tmp / np.minimum(k, X_pred_binary.sum(axis=1))\n",
    "    prec = np.sum(tmp) / (batch_users * k)\n",
    "    return prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(X_pred,heldout_batch):\n",
    "    X_pred[X_pred == -np.inf] = -9999999999\n",
    "    batch_users = X_pred.shape[0]\n",
    "    X_true_binary = heldout_batch.toarray()\n",
    "    \n",
    "    total_prec = 0\n",
    "    for u in range(batch_users):\n",
    "        y_true = X_true_binary[u]\n",
    "        y_scores = X_pred[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/batch_users\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-VAE^{PR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_dims = [200, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-31-881e9e51e708>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory\n",
    "\n",
    "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
    "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: ./volmount/log/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "log_dir = './volmount/log/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = './volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            \n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, \n",
    "                                           global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@100\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr, test_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'test_tr.csv'),\n",
    "    os.path.join(pro_dir, 'test_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)\n",
    "\n",
    "batch_size_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "#     int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "# print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I/model\n"
     ]
    }
   ],
   "source": [
    "n10_list = []\n",
    "r1_list, r5_list = [], []\n",
    "# p1_list, p5_list = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        \n",
    "        n10_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=10))\n",
    "        MAP = MAP(pred_val, test_data_te[idxlist_test[st_idx:end_idx]])\n",
    "\n",
    "#         p1_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        p1 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "#         r1_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        recall, rec_1 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "        r1_list.append(recall)\n",
    "        \n",
    "#         p5_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        p5 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "#         r5_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        recall, rec_5 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "        r5_list.append(recall)\n",
    "\n",
    "n10_list = np.concatenate(n10_list)\n",
    "\n",
    "# p1_list = np.concatenate(p1_list)\n",
    "r1_list = np.concatenate(r1_list)\n",
    "\n",
    "# p5_list = np.concatenate(p5_list)\n",
    "r5_list = np.concatenate(r5_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@10=0.17108615080647865\n",
      "Test MAP=0.14764935298883178\n",
      "Test Prec@1=0.08\n",
      "Recall: 0.029850746268656716\n",
      "F1@1 0.043478260869565216\n",
      "Test Prec@5=0.072\n",
      "Recall: 0.13432835820895522\n",
      "F1@5 0.09374999999999999\n"
     ]
    }
   ],
   "source": [
    "# print(\"Test NDCG@10=%f (%f)\" % (np.mean(n10_list), np.std(n10_list) / np.sqrt(len(n10_list))))\n",
    "print(\"Test NDCG@10={}\".format(np.mean(n10_list)))\n",
    "print(\"Test MAP={}\".format(MAP))\n",
    "# print(\"Test Prec@1=%f (%f)\" % (np.mean(p1_list), np.std(p1_list) / np.sqrt(len(p1_list))))\n",
    "print(\"Test Prec@1={}\".format(p1))\n",
    "# print(\"Test Recall@1=%f (%f)\" % (np.mean(r1_list), np.std(r1_list) / np.sqrt(len(r1_list))))\n",
    "# print(\"Test Recall@1={}\".format(np.mean(r1_list)))\n",
    "# print('F1@1', F1_score(p1, np.mean(r1_list)))\n",
    "\n",
    "print('Recall:', rec_1)\n",
    "print('F1@1', F1_score(p1, rec_1))\n",
    "\n",
    "# print(\"Test Prec@5=%f (%f)\" % (np.mean(p5_list), np.std(p5_list) / np.sqrt(len(p5_list))))\n",
    "print(\"Test Prec@5={}\".format(p5))\n",
    "# print(\"Test Recall@5=%f (%f)\" % (np.mean(r5_list), np.std(r5_list) / np.sqrt(len(r5_list))))\n",
    "# print(\"Test Recall@5={}\".format(np.mean(r5_list)))\n",
    "# print('F1@1', F1_score(p5, np.mean(r5_list)))\n",
    "print('Recall:', rec_5)\n",
    "print('F1@5', F1_score(p5, rec_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
