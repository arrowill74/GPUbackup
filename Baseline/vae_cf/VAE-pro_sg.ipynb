{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders for collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
    "\n",
    "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
    "DATA_DIR = './'\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data and create train/validation/test splits following strong generalization: \n",
    "\n",
    "- We split all users into training/validation/test sets. \n",
    "\n",
    "- We train models using the entire click history of the training users. \n",
    "\n",
    "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the dataset at http://files.grouplens.org/datasets/movielens/ml-20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv(os.path.join('../../User/output/', 'UserFollowingsMat.csv'))\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data.rename(columns={'Unnamed: 0':'userId'}, inplace=True)\n",
    "# raw_data = raw_data.set_index('userId')\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['userId', 'movieId'])\n",
    "# for uid, row in raw_data.iterrows():\n",
    "#     for movie in row[row == 1].index:\n",
    "#         df = df.append({'userId': uid, 'movieId': movie}, ignore_index = True)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('../UserFollowingRecord.csv', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../UserFollowingRecord.csv')\n",
    "# raw_data = df\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
    "- Use all the items from the training users as item set\n",
    "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def get_count(tp, id):\n",
    "#     playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "#     count = playcount_groupbyid.size()\n",
    "#     return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "#     # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "#     if min_sc > 0:\n",
    "#         itemcount = get_count(tp, 'movieId')\n",
    "#         tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "#     # Only keep the triplets for users who clicked on at least min_uc items\n",
    "#     # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "#     if min_uc > 0:\n",
    "#         usercount = get_count(tp, 'userId')\n",
    "#         tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "#     # Update both usercount and itemcount after filtering\n",
    "#     usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "#     return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep items that are clicked on by at least 5 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data, user_activity, item_popularity = filter_triplets(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "# print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "#       (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unique_uid = user_activity.index\n",
    "\n",
    "# np.random.seed(98765)\n",
    "# idx_perm = np.random.permutation(unique_uid.size)\n",
    "# unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # create train/validation/test users\n",
    "# n_users = unique_uid.size\n",
    "# n_heldout_users = 150\n",
    "\n",
    "# tr_users = unique_uid[:(n_users - n_heldout_users * 2)] # -1282\n",
    "# vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)] # 1282-1432\n",
    "# te_users = unique_uid[(n_users - n_heldout_users):] # 1432- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unique_sid = pd.unique(raw_data['movieId']) #train_plays['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "# profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if not os.path.exists(pro_dir):\n",
    "#     os.makedirs(pro_dir)\n",
    "\n",
    "# with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "#     for sid in unique_sid:\n",
    "#         f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def split_train_test_proportion(data, test_prop=0.2):\n",
    "#     data_grouped_by_user = data.groupby('userId')\n",
    "#     tr_list, te_list = list(), list()\n",
    "\n",
    "#     np.random.seed(98765)\n",
    "\n",
    "#     for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "#         n_items_u = len(group)\n",
    "\n",
    "#         if n_items_u >= 5:\n",
    "#             idx = np.zeros(n_items_u, dtype='bool')\n",
    "#             idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "#             tr_list.append(group[np.logical_not(idx)])\n",
    "#             te_list.append(group[idx])\n",
    "#         else:\n",
    "#             tr_list.append(group)\n",
    "\n",
    "#         if i % 100 == 0:\n",
    "#             print(\"%d users sampled\" % i)\n",
    "#             sys.stdout.flush()\n",
    "\n",
    "#     data_tr = pd.concat(tr_list)\n",
    "#     data_te = pd.concat(te_list)\n",
    "    \n",
    "#     return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "# vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "# test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def numerize(tp):\n",
    "#     uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
    "#     sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
    "#     return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_data = numerize(train_plays)\n",
    "# train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vad_data_tr = numerize(vad_plays_tr)\n",
    "# vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vad_data_te = numerize(vad_plays_te)\n",
    "# vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_data_tr = numerize(test_plays_tr)\n",
    "# test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_data_te = numerize(test_plays_te)\n",
    "# test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective for Multi-DAE for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
    "$$\n",
    "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiVAE(MultiDAE):\n",
    "\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "\n",
    "        # placeholders with default values when scoring\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        \n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # q-network\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "\n",
    "        sampled_z = mu_q + self.is_training_ph *\\\n",
    "            epsilon * std_q\n",
    "\n",
    "        # p-network\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        \n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        \n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                # we need two sets of parameters for mean and variance,\n",
    "                # respectively\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            \n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
    "                                           os.path.join(pro_dir, 'validation_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1282, 165)\n",
      "(150, 165) (150, 165)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(vad_data_tr.shape, vad_data_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "# training batch size\n",
    "batch_size = 500 #coldstart=25 #MRM=500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = range(N_vad)\n",
    "\n",
    "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
    "batch_size_vad = 50 #coldstart=25 #MRM=50 # 2000\n",
    "\n",
    "# the total number of gradient updates for annealing\n",
    "total_anneal_steps = 200000\n",
    "# largest annealing parameter\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100): #coldstart=10 #MRM=100\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0] # 150\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "    recall = tmp / X_true_binary.sum(axis=1)\n",
    "    rec = np.sum(tmp) / np.sum(X_true_binary.sum(axis=1))\n",
    "    return recall, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prec_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "#     prec = tmp / np.minimum(k, X_pred_binary.sum(axis=1))\n",
    "    prec = np.sum(tmp) / (batch_users * k)\n",
    "    return prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(X_pred,heldout_batch):\n",
    "    X_pred[X_pred == -np.inf] = -9999999999\n",
    "    batch_users = X_pred.shape[0]\n",
    "    X_true_binary = heldout_batch.toarray()\n",
    "    \n",
    "    total_prec = 0\n",
    "    for u in range(batch_users):\n",
    "        y_true = X_true_binary[u]\n",
    "        y_scores = X_pred[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/batch_users\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-VAE^{PR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_dims = [200, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-31-881e9e51e708>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory\n",
    "\n",
    "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
    "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: ./volmount/log/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "log_dir = './volmount/log/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = './volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            \n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, \n",
    "                                           global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAADYCAYAAABMQZ2kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdZ2BUVf7w8e+09N57JwWSkAQIvUlXECyIsir2x7Wgrqviroqu7vJXV2xrWV17AxSlKZ1AIPQUQnrvbdJ7MpmZ58XAaMykAUkAz+cV3Htn7pmTmXt/95zfOUei1Wq1CIIgCIIgCIIwYqQjXQBBEARBEARB+KMTQbkgCIIgCIIgjDARlAuCIAiCIAjCCBNBuSAIgiAIgiCMMBGUC4IgCIIgCMIIE0G5IAiCIAiCIIywYQvK8/PzWbFiBQsWLGDFihUUFBT0emxeXh5jx47l1Vdf1W976aWXWLhwIddffz233norZ8+e1e+74447mDNnDkuXLmXp0qVs3rx5KD+KIAiCIAiCIFxS8uE60dq1a1m5ciVLly5l69atvPDCC3z55Zc9jlOr1axdu5a5c+d22z5jxgz+9re/oVAoiImJ4YknnmDfvn36/c899xyzZ88e8s8hCIIgCIIgCJfasLSU19TUkJaWxuLFiwFYvHgxaWlp1NbW9jj2o48+YtasWfj4+HTbPnv2bBQKBQARERFUVFSg0WiGvOyCIAiCIAiCMNSGpaW8vLwcZ2dnZDIZADKZDCcnJ8rLy7Gzs9Mfl5GRwZEjR/jyyy95//33e32/b775hlmzZiGV/vpM8dprr7F+/XqCgoJ46qmncHZ2HlQZ6+pa0GiGf3FTe3sLamqah/28VypRX4Mj6mvwRJ0NjqivwRN1NjiivgZP1NngDGd9SaUSbG3NDe4btvSV/qhUKp5//nnWrVunD94N+fnnn9m+fTvffPONfttrr72Gq6srarWa//73vzz++ON89913gzp/bxU0HOztLUbs3FciUV+DI+pr8ESdDY6or8ETdTY4or4GT9TZ4FwO9TUsQbmrqyuVlZWo1WpkMhlqtZqqqipcXV31xyiVSoqKinjggQcAaGxsRKvV0tzczMsvvwzA3r17efPNN/n8889xcHDo9v6ga4G/8847+c9//oNGo+nWkt6fmprmEWkpd3S0RKlsGvbzXqlEfQ2OqK/BE3U2OKK+Bk/U2eCI+ho8UWeDM5z1JZVKen0AGJag3N7enpCQEHbs2MHSpUvZsWMHISEh3VJX3NzcOHHihP7/7777Lq2trTzzzDMAxMTEsG7dOj777DM8PDz0x3V1dVFfX68P0n/++WcCAwMHFZALgiAIgiAIwkgatvSVF198kTVr1vD+++9jZWWln+7w/vvvZ/Xq1YSFhfX5+meffRaFQsHq1av12z7//HOMjY154IEHUKlUADg5ObF+/fqh+yCCIAiCIAiCcIlJtFrt8OdsXIZE+srw6FJrkEklSCSSC3r9H62+Lpaor8ETdTY4or4GT9TZ4Ij6GjxRZ4NzuaSviBwPYdi0tqt44t0jvLExieqGtpEujiAIgiAIwmVDBOXCsMksrqelvYvMonqe/+QkMYmlaERHjSAIgiAIggjKheGTXliHQi7l5fsm4u9mxVe7M9l2JH+kiyUIgiAIgjDiRFAuDJuMwnoC3K1xsTPjyRURjA92YteJIuqaOoa9LF1qsRqsIAiCcHWrbWyntV010sUQBkgE5cKwaGrtpETZTLC3LQASiYSbZ/mj1mjZOsyt5QeTSln99mEaWjqH9byCIAiCMJz+75sEPvk5faSLIQyQCMqFYZFZVA9AiJetfpuTjSmzI905nFxGWXULAFqtljM51ZTXtAxJOTo61WyJzaO9U018ZtWQnEMQBEEQRlpdUwfVDe2cyakRjVBXCBGUC8Mio6gOY4UMH1fLbtsXT/XBxEjG5kO51DS089b3ybz9QzLrvk7oEZirutRU1bZS29hOXVOHwSksd54o5KXPT1FZ12qwHPvii2lsVWFhquBUugjKBUEQhKtTXlkDABqtlhOpFSNcGmEghm3xIOGPLaOonlEe1shl3Z8DrcyMWDTRmx9j80gtqAVg2XRfDiSU8u8NSfzt9nHYW5sQn6nk672ZNDT/+rQf5GnDUysjkZ6b87yto4sdRwto61Dzzy/jWX1zOAHu1vrjW9tV7DpRRLi/PT4ulmyPK6C+uQMbC+NhqAFBEARBGD555Y3IpBLcHMyJS6lgfrTXSBdJ6IdoKReGXENzB2XVLfp88t+bN8ETV3szAj1sePneiVw/1Ze/3DKW9k41/96YxHs/neW9n85iZWbEwzePZdXCIOaN9ySzuJ6ETKX+fQ4lldHWoebBpWMwN5Hz2reJHE0p17eo7z5ZTEt7FzfO8GNCsBNaIP43rxcEQRCEq0V+WSOeThbMjHCjuKqZokqxmNDlTrSUC0Mu41w+ebCX4aDcWCHjlfsmdlvl08vZkseXh/PGhiRqGtq5aaYfC6K9cHWxRqlsQqPRklpQy4+xeUQGOqDVwt7TxQR72RAd4sxoHzve3ZzM/3ak8/3BXCaGOHPoTBnjg53wctal0Lg7mHMqvZI54zyGvhIEQRAEYZioNVryK5qYEupCdIgzG/Znc+RsOSudLft/sTBiREu5MOQyiuowNZbh7WJ4WVmgW0B+3igPG56/awL/vH8i10326Zb6IpVKuGG6HxW1rRxNqeBkeiV1TR0snKjrnrMwVfDUbZE8tCwUP1cr9seXoFJpuGG6r/49JgQ7kV3SoJ+SMb2glte/S6RE2XypProgCIIgDLuSqiY6OtX4uVphYaogIsCB46mVYjrgy5xoKReGXEZhHYEeNsikg38GdHcw73VfVKADPi6WbDuSj4mxHDcHc8L87PX75TIp44OdGB/sRFNrJ42tKlztf32/8cFObDmSz+nMKuytTPhwawpdai1vbEhize1RONuaDbq8giAIV4tOlRqFXGqw0US4vGUX1QHg52YFwJQwV05nKjmbW0NkoONIFk3og2gpF4ZUakEtlXVtveaTXwyJRMJNM/2paeygVNnCgmjPXm8elmZGPQJ8NwdzPBzN2Xm8kPd/SsHL2ZJnb49CrdHy7++SqG1sN/hepcpmgzO/CFe+/+1I45NtKSNdDOEqptZorojrR3Obir/8J46DiaUjXRThAmQW1WNqLMfZTte4FOprh5W5EUfFLCyXtQEF5XV1dWzcuJFXXnmFZ599lldeeYWNGzdSV1c31OUTLmMarZb88sZe9xdWNPHej2dxdzRnerjbkJRhtI8tId622FoaM2m0y6BfPyHYifrmToK9bfjrrRGM8rDhLyvG0tKu4o2NST1WQitRNvPCJyfZc6r4Un0E4TKh0Wg5nVnFtsN5VNe3jXRxhKuQVqvlH5+f5uMtZ0e6KP06kVZJa0cXh5PLR7oowgXIKqrD19VSPzuZXCYlKtCRlLxaVF3qES6d0Jt+g/Jjx44xf/58tm3bhlarxcnJCYDt27ezYMECjh8/PuSFFC5PCZlKXv7iNInZPWcwUda38eb3ZzAzkfOXWyIwMxmaTCmJRMIjN4bxwl0TUMgH3/Ezb4Indy0K5rGbx2JipCujj4sVj94UTnlNK0d+d0M6nlqJFtgfX4xaI3LzriaVda10qnStmLtOFo10cYSrUKmyheKqZvadKqK9s2uki9Onoym6a19BRRNVvaz7IFyeOlVqCsob8XW16rY9cpQDHSo16YWiQfVy1W+k9PLLL/PPf/6T+fPn99i3d+9eXnrpJXbu3DkkhRMub2fzagD45VghEQEO+tSR1nYV6zedQa3W8PRt47C1HNp5wE2N5Zhe4ClMjOTMGNuzFT/E2xZ/NysOJ5czb4IuLUaj1XIirRJLMwU1jR0kZVczLsjpIksvXC6KKnUDfIO8bIk9U86SKT5YX0Vz2H+zNwszYzk3zPDr9Zis4nryyhr1A6aFS+t8A0Z7p5rTGUqmhbuOcIkMK6tuIb+8ibnjPdh3uoRTGVVcN9lnpIslDFBhpW6GsvP55OcFe9libCQjMbuacH+HESqd0Jd+mxbLysqYNWuWwX0zZ86krKxsQCfKz89nxYoVLFiwgBUrVlBQUNDrsXl5eYwdO5ZXX31Vv62trY3HH3+cefPmsXDhQmJiYga0TxgaWq2WtIJajI1k5JY1klVcr9+3OTaPqrpWHr0pHLc+Bmpe7qaGu1Ja3UJBhW5u19zSBmoa27lldgD2VibsO10ywiW8elQ3tBGTUIJWO3K5tkVVTchlElaviECt0bDn9NCnKDW3qfo/6BLILqlnf3wJx/rJJ91xrIBNMTmknVvI61Jrbe/ik5/T9A/0vSlVNtPSPjx1M5wSsqvxc7PSLeZytve0kC61ZlApBrmlDXz6S/ol6707mlKBVCLhukne+LtbcVKsfnxFyS/TpZX+vqVcIZcS5mtHUk41mhG81gq96zcoDw8P580336S1tXv3VWtrK2+99Rbh4eEDOtHatWtZuXIlu3fvZuXKlbzwwgsGj1Or1axdu5a5c+d22/7JJ59gYWHB3r17+fDDD3nuuedoaWnpd58wNKrq2qhp7GDZNF8sTBXsPKHr7s8ra+RgQilzojwI9LQZ4VJenOhgZ4zkUn1O5fG0Sozkury8OeM8yCyuF4sxXCL7Tpfw1Z4sErJGbjGn4spm3BzM8XKxYkKwEzEJpUMaGB5LrWD124fZdCBnSAf+abVaNsXkAFDd0E5bh+G0iS61huxi3bLcG/Zf+jJptVo+25lO3NkK3tp0hi2H8wwGBrWN7fzji9N8uSvzkp5/sLRaba919VsDDYRrG9sprGjSXT8meJFZXE+VgbELWq2W9RuTeP6TkwN+aPv5WCFHkss5m3vxD1MajZZjqRWE+tlhbWFMdLAzxVXNlNdceffUlnYVO44WXPAYkYNJpRw+M7CGx+HQ2NrJ+k1J/OvreP7z41m+3pNpcEKCvPJGHGxMDa5WHTHKgYbmTgrKL697l1arZX98CYeTy6iobR3RBpqR1G9Qvm7dOhITE5k0aRLXXXcdt956K4sXL2by5MkkJCR0a83uTU1NDWlpaSxevBiAxYsXk5aWRm1tzwvIRx99xKxZs/Dx8em2fefOnaxYsQIAHx8fQkNDiY2N7XefMDRSz7WkRYxyYN54D5JzayisaOLLXRlYWxj12UV+pTAzkTMuyIkTaZW0dXRxKr2KiFEOmBrLmT7WFSOFlP3xV0ZruVarpabB8GwyQ+3rPZm8/MWpPi+yBecGDG+KyUHVdely9cuqW+hUDazFsaiqGS8n3cIa1032ob1TzdbD+T3m9c0ra2TbkXze/+ksf//4OOu+jh/wOc5rbe9i44EczE3k7DpZxLubkwcUAF6I+EwluaWNRATouqvLqg0HVwXlTXSo1ESHOFGibOZw8qUNRvbHlxCfqWTZdF8mh7qwLa6At74/0+PBZ/vRAlRdGuIzlb3OgDRQja2dlFT1ve5AdUMb3+7LYlNMDluP5PNTbB5vbjrDY+8c4ZG3Yimo6H0we1FlE4+9fYQ9AxiDkJhdDejyeq8Z74lEAnEGBlEeTakgo6ieqro2Pt6e1m+LZmNrp77nIfYSBJDpRXXUNXUwJVQ3cH58sBMSuOJay1Pya3jhk5P8GJvH+k09v2f9qW/u4Js9WXy2M4MfY/NGPEjUarV89nM6GYV1yKUSKutaiT1Txjd7s7odp9FoySltIKiXxfrC/R2QSiQk5QxNA8iF1tPuk8V8szeLz37J4G8fHefxd4/w7uZkdp0oIqe04Q/Tst9vUO7u7s6GDRvYtm0bTzzxBLfddhuPP/44W7duZcOGDbi59T+rRnl5Oc7OzshkMgBkMhlOTk6Ul3e/IGVkZHDkyBHuuuuuHu9RVlaGu7u7/v+urq5UVFT0u08YGmkFddhbmeBkY8rsKA+MFTLe+v4MRVXNrJwbiKnx1TEF/vRwV9o6uvhqTybNbSomjnYGwNxEwZRQV46nVdLU2nlB751WUEtOScOlLG4PzW0q9p4q5u8fn+CpD44O+wCf5jYVsWfKyS9v6pbi9FsajZbCyma8nC1Q1rezL/7XtJHWdhVJ2RfW1ZpeWMdz/zvBq98m9vs3amjuoLGlE09n3QJXnk4WTB7jwr74Ev720XEOJZWSkKVk3dfxvPLlabYeyaeoqhkHa1OySxrYfChvUGXbFpdPU0snf1kRwR3zAzmbV8u/voqnoeXCvku96VJr+OFgLu6O5qy4JgCA4l4Wx0ov1D1o/2leIKM8rPkpNu+SPSjklzey8UAOY/3tWTzFh3uvC+HOBUGkF9Tx/k8p+tbmytpWDp8pJyrQES1aDiRc+HR81fVtvPLFaf7xxak+W3m/25fN/vgS9seXsPVIPjuOFlDb1E7kKAeM5LJepwRUdan5eEcarR1dbIzJIaOf31ZithIXOzNc7c1xsDFljI8dR1PKu323W9u7+P5gLn5uVtw+P5CzeTVsjyvo831PpVeh1miJCHDgTG71RT/IHD1bjqmxnMhRuoc4W0tjRnnacDK9csQD04HQaLR8vSeT9RvPYGIk484FQVQ3tPHej2cHtXDOwcRSNBot4wId2XG0gG/3ZaPWaCiuaiYmsZSYxFKUFzlLU11TBxsPZNMxgIf6AwmlnMmtYfnsAJ5eGcXL907k2kneJGZXU/qbB+0T6ZXUNnYw1cBYKdAtrBfoaa1/SLxYao2G5NxqvtuXzfOfnGD124dJzu39vVvbVfx3W2q3Y7JL6vnhYC7jghx5+b6JrFoYRLifPaXKFjbF5PCvr+L57Jf0Hu9VVdd60d/3y82AIycfH58erdeXkkql4vnnn2fdunX64H042dv3vtrkUHN0vLKWvVWrNWQW1TF1rDtOTrqctYWTfdgam8v4EGcWTvMb0sUmhrO+7O0tcNmTyfHUSixMFcyO9tHP8rJ8biAHE0uJz6lh+ZxAg6/XarWUV7dgY2mMmYlCvz0uuYz1G5OwszLhf8/NRyb9tb4+3nqW2IRSZkS6c814T/zcrS+oPk+nV/J/6w/R0akmyNuW2sZ2MksamDF++AbxxR3KpUutwUgh42haFdPG9Tx3YXkjHSo1N10TyJEzpew4WsiSmQFUVLfy+jenUda18cCyMJZMH3jvS0ubis92ZuBgY0qpspnXvkviHw9MxsnO8IJQRTW69LzwQN3AXUdHS569O5r4jCq+25PBF+dSKZzszLh/WShzJ3jp/54f/pjMz3H5zBznydgBLMpRWNHIvvgSFkz2ITrcnehwd4J8HfjHJ8f5Zl82L9w78ZL8ftQaLT8cyKKqvo21901i9CgnTIxk1DZ1GvwN5ZY34etmhZ+3PQ/eNJYn344l5kw5q64b3e+5+vpNNrep+O/249hZm/DMXdFYmhkBsHy+FbY2pry9MYmdJ0u4e8kYPt+diUIh5fHbovjgx2QOJ5dxz7IwjBW93xNqGtpIzFQik0mYHOqKibGcqtpW/r3pDG2daowVMjbG5PLKg1N61Gtafg2J2dXcsSiEW+YGotFoUWu0+t/42xsSiUsu5ZEVUT0aGj7ZlkKpsoVn7hzPN7sy+GhHGm89MRN7a1ODdZBZVM+ymf76ulo01ZfXv46nvL6diHPfu4+3nKWptZOX7p+Mv4c1ZbVtbIvLJyLYmfEhzgY//6nMKnzdrHhoeQQPrNtHYl4tt84L6rW++tLariIhu5pZUR64uf6afjgn2osPNifTqgYf15G5Xw30ur/3RCEHEkpZMt2PVdeNxlghw9HBgje+iWdDTC6P3xrZ7+9L1aUm9kw5E0a78Nw90Xy6PZUth3KJPVPWoyfP3dGCsAAH3BzMcbE3x9vFElcH8wH9hn88nM/uk8W4O1txw6yAXo8rKG9kU0wO40OcuW1hiP69b5kfzK6TxcQklfHEbVGoujRsP1qAn5s1U8PdkEoNl2FqhAefbEtBLZXiYn/h474qalp447tEMgrrUMiljPG1RyGX8d5PKTx3z0SiDEyEsGlfFifSKjmRVsmNswJYOtOfj7an4WxnxlN3TMDcVEFEyK/TG9c1tvP9gWy2H85j7kQf/e+gvLqFl784TZdGy/9bFsbcaK+Lvm5eDrHYRTVnqlQq7r33Xr788ss+j3N1daWyshK1Wo1MJkOtVlNVVYWr668jz5VKJUVFRTzwwAMANDY2otVqaW5u5uWXX8bNzY3S0lLs7OwAXev7xIkTAfrcN1A1NSOzIIyjoyVK5eWV29Wf3NIGWtq78HOx0Jd91lhX6hpaWTLFl+rqoVumfiTqa/JoZ346nE9UoCP1db+2SJjKJIz2sWX74TymjXFGLvu146lE2czRsxUkZCmpqm/DykzB7fODGB/sRGp+LW//cAYLMyOqG9o5El/EaB/dd7e1vYtdRwuwMjfil6P5bDucR7i/PY/dHD6oC05+eSOvfpuAh6Mld8wPxNvFkvWbkjiZWsGyqT6XrG7KqlswNZYbnGFHq9Wy40ge/u5W+LlacyChhJyCGqzNjbodF5+q6zFzsFCwbKoPCRlV/P39OEqVLdhZGRPoYc1nO1LxdjTrtiJrXz7ZkUZtQzt/u2McXWoN7/yQzJNvH+LplVG4GAjMz2bpuuYtjXTB3/nvmLeDGc/cFklaYR2dnWrCA+yRSaW0NLXT0qRroVk8yYvT6ZW88W08L98b3e3hy1Cd/GdjIqZGMq6N9tSfx83WhOWzA/hmbxYbd2cwZ5wHoGsJ+v5gLhLAwdoUBxsTJo52xryPc5Qom4k9U8apjCoamjsJ9bPDy96Umppm3B3MyS6q6/EbUnWpScuv5Zood5TKJmxN5Uwe48KWQ7lMG+OM1e/+ZufllTXy6S/pOFib4O1sSYCHNaG+dt2+qx9tT6W6ro01t0fR3tJBe0uHft9YXztmR7rz48EculRdxCaWct1kb7o6VMwIc+HY2XJ2HMoxOEPS0ZRydh4v6tZKaGosY+JoF1Lyamht7+LJWyMoqGjiq92ZbDuYzZTQX+85Wq2Wj7ecxdrciCkhTgavK9FBjuw7VcTOw7lM/00ZMgrr2Hool1mR7gS5WfH/rh/DK1+c5p+fnuCp2yK7XQsAjqdWoNZoCfKwRqlswtHRkgAXC8yM5az/NoEJwU54O1uy/UgesyLcsTaRUV3dzC0z/cguquPdTYm8/ueeDxXlNS1kFdVzy+wA5FoNo31s2XU0n9nhrr0GZKC7ziRkKZk42rnbVLJHksvp6FQzLsChW30EuVkhlUj45Uguy/sIHi+FsuoWvtuXRU5ZI9dEuXPtJG98PO0GdN1Xdan5amc6fm5WLJviTWO97mF7jKc1y6b5suVIPml5NQR6WjPKw4aoQEeDvbpxZ8upb+5gergL1dXNLJnkhZWpnJKqZvzdrfF3t0ar0ZKcV8PZ3BoOJ5bQ0v5rr5K1uRGBnjaMC3IkupeHqbaOLvad0qU9/bA/iwmBDgYfPlvbVfzf1wmYGsu5fe6oHvfXGeGuxCSUsGiCJ8l5NVTUtPL48nCkUkmvdTbKTRd87j9RyPwJnt32HU0pJ6u4geun+mBnZQLoetxiEkvJKq7Hx8WSAHdrqhva+WZvFhKJhHuvC2FCsBNGChnNbSpe/y6RVz49wWM3h+vvbef/PltjcwnxtsXZzowfD+awIy4PjQb+fsc4WpvbaW3u2fK9eKIX8emVvLspkZfvnYhUKuFfX8UD4ONsyTubkjiWXMadC4P6vDb+VkpeDaczq7hrUQgwvLGFVCrptSFY9uKLL754oW+sVqt5/vnneeSRR/o8zszMjMOHDyOXywkODmb79u0olUr+9Kc/6Y+xtLTk/vvvZ9WqVaxatYqOjg4CAwN5/vnnAaitreXEiRNcc801FBQU8MEHH/Dcc89hZGTU576BamvrZCR65szNjWm9wPSHkRJ3tpyMonruWBCkv4iYGMmIGOU4ZPORnzcS9eVka0ZGYR03zPDrMXDGzFjBoaQyPJws9CuGVje08eKnp8gpbcDHxZI54zyobmxn3+kS8ssb2Xm8CGdbU569fRyxZ8pRdWkYF6RrYT2SXEZidjVP3hrBjTP80WohLqWC0T522Fub6M+bX97Ix9tT2XOqmF0nCjmYWIpao8Xd0ZzaxnZe/y4RcxMF6x6ehpWp7m/S3KrieFolU0Nd+gwcByo+U8kbGxNJK6hlZoRbj4Aho7COPaeKuWmmH5GjHNgXX4KFqbzHAOBDZ8qorGtl+ewArMyMaGnrIjG7mujRzjy+fCxRgY7Enikno7COqWG6YEOj1VJV34aZibzHeeMzlWyOzWPxFB+mhLpgb21CeIA9+xNKUKk1jDUwFdj++BI6VWqunezd4zsmkUhwsjHF1d5cvxDHb8llUvxcrdh3uoTs0gbyyho4kVZJakEdHo4W+t+EqkvNxgM5nMyo4tY5owj6XT34ulqSX97EoTNlRAU6UlTRxPpNZ6iqb6dDpSE1v5aknGpS82uJDnFCIe95Az+dUcX6TUkUVDQR7GXLsum+LJ3mi+xckJhX1khmUR2LJnZvVcoqbuBIcjnXTfHRP7S4OZix73QJxkYygnvJT/3hYI5uATEJxGcpOZZaSVObijA/eyQSCSfTK9lyOJ/rp/nqc5R/b4yvHWmFtRxPrcTMWM6fl4ViJJdhb2VCQlY1eWUNzIp071ZeZX0b6zcmYWVuxIJoT1ZcM4pJo53p6NRwIq0StUbLX2+NwNfVCm8XS1LzazmZXsX0cDeMzl2zknKq2XWiiBXXBBDgYW2wbLaWxpzKqKKspkX/YNDcpuLNTUlYmBnxyA1hyGVSrMyMcLAxYe+pEuKzlBjJZbg5mCOVSmjv7GJbXAGtHV3cOmcUEokEc3Nj2ttVeLtaoqxv51RGJaczlViYKnjkxjB9GWUyKXKZhGMplUQFOvaYonPv6RKyS+q559oQTI3lKOQyYs+U4+9ujbOt4V6hrOJ63tiYxNGUCsxN5AS4//rZN+zPRiqVsHy2f7f6NjaSUVDRRHJONXPHe/YZ8P+eVqultrGDLo2mzx6Pto4uNh/K5dNf0mlqVRHsZUtccjkHE8tQyGV4Opj12zCx/3QJpzOV3Ld4NI423XssAj1tsDY3oqVNRUqe7vtwIq0SP1crffB5vryf/ilVFRYAACAASURBVJKOhamCW2YHIJFIkEgk+LhYEe7vgKeTBeYmCixMFfi7WTM51IVrJ3kzZ5wH44Od8HW1RCKVkFVcz5GzFdhaGuPt0rMF9khyGQlZ1dwyO4CE7GosTBXd/hageyh/fUMSlXVtPHxDGJ5OPQM5Nwdz9sWX0NapJvZMGZ5OFtw007/Pe6W5iYLTmVUUlDcyLcxV/xBZqmzm7R+SyS9v4mBSKRIJdKjUvPdTCsdSKmjvVJOQVU3c2QoSs6vxdbXiyVsjCPay1V9jjBQyxgc5cianmgMJpYzxtdM32sSdreBEWiV3LQpm7nhPXO3NyCiq59ZrAggP6H2KRplUgpezJXtPFdPaqXugTMuv5aEbwrhhuh9GChkxCaWk5NcyPdzV4HX6t7RaLR9sSaGhRcWsSF3q83DGFhKJBDMzw/FpvxHUnDlzet03mPyyF198kTVr1vD+++9jZWWlHyB6//33s3r1asLCwvp8/b333suaNWuYN28eUqmUf/zjH1hYWPS7T7j0Ugvq8HK20HdDX+1sLY158Z5og/vC/e1xtDFh3+liJgTruuo2HdDNdPGvBybpbwzXjHNn98lithzOx87SmCdXROhmNghx4lhqBbd36PLwD527qPq4WCKRSFg6zZdDZ8o4mFiqD2a1Wi1f7s6kpqGdAHdrTIxk1DS2s2F/NtuO5GNsJEOj0fLELWOxtTJBqdQNcAr1s4P9kJJfq78QXaijKeV8+nMGFmYKiiqbSSuoY4yvXbdjYpLKMDeRMz5I14IS4m3LwcQyFk307nZTzy9vxMfFSn8hXT7bn0ljnPV1YGos584FQby/JYXNh3KxMFUQe6YMZX07Ho7mLJnqy7ggR2ob2zmWUsGeU8V4O1uy5Dc9Ah6OFgS4W5PbSw5/UVUzXs4X3nXp52bF8tn+bD2ST3lNCyZGMuqbOzl6VhfohvvZ88nP6ZQom5kT5cFMAy2/EomEe64N5vlPTrJ+YxL1zR24O5jzyE3hONmYotFqSc6t4b0fz/LmpjP8ZUVEt1a+mIQSvt6Thb+7NY/eFGbw9+nhaE7smS7qmzu79W5kFNYhlUi6PSi42psz1t+eAwklXDvJq8dDQHtnF/FZSmaP82TFLH86OtVsPZLPrpNFqNUalkzx5ctdmfi5WbF4inevdSeXSXloWRhvbExiTpS7vqVLIpEwd7wHn+/MILOonmDvXx8MfjiYi1Qi4fHlY7t9jkBPG/40bxQqtVbfIyOVSLhzYTAvfXaKL3ZlMH+CJ6725mw+lIeznVmfc4VLJBKmh7uxKSaHUmUzDjamvP3DGRpaVDzzp0iMjX6tk0mjXZBJpWyPK+DTX9LZHJuLQial+twA61mR7j2ChTE+dozxsaOto4u0glrsrU2wMO3+wBzuZw/Amdyabt9RjVbL8dQKRp9b0Rh0g0gtzRT664VUoktjamzppL65kzO5ugcRB2sTPBwt2He6mLnjPZBJpVQ3tJFRVM+y6b4Gg9+ZEW4k5VSTlF3N+OD+12dIza/l0JkycksbqGvqwNbSmLV3T8DKwPeytV3FvzckUVjRxIwIN26Y4YeVmRFFlU18fzCXT7alYGceSYi34YdD0AX1O44VMubcKs+/J5FImB3lwewoDzRaLVlF9Xz6Szrrvoln6VRfrp3sjVwmJbukgaLKZu5cGDSo3kkLU12g7utqxcwId9QaDW//kMxXuzNxsDbp1mKs1erGS3g7W7Ig2pOU/Bp2Hi9kVqS7/sElq7ie//x4Fq1W94DZ28BNe2sTJo121g/y/fPS0AGVe8XsAN7cdIbPd2XwwJLRqDVa/rcjHVNjOY/dPJZfjhfqx8o42pjw6E1hRAQ40NLeRU5JA+2dXUwIcUIm7Tk00dLMiL/eGsnLX5zmvZ/O8sKqCViYKdh9sggvZwv93yc6xLnXnoTfC3C3Zs65efMBlk7zJdxf99u4dpI3DtYmfLg1lb2nSvpdZ6GgoomiqmbumG847XQk9RuUNzQ08Mwzz+Dh4dFjX2dnJw8++OCATuTv78/333/fY/vHH39s8PhHH3202//NzMx45513DB7b1z7h0mrv7CK3tKFHl9cflVQqYc44Tzbsz6awoonWdhWnz80w8duWGplUyrWTvJk8xgUjhVQfeEwJdeFQUhkJWUrcHc0pqmzmT/MC9RdVYyPZuWNKubV1FFZmRqTm11JY0cRdi4K7devnljWw60QRmUX1PHbz2B6pHi52ZthbmXA2r+aigvJDSaV8sSuTEG9b/rwslBc+OcEvxwu7BeUNzR0kZimZM85D3+o3O9Kd97ekcDavhrHnWkVUXRpKqpqZH/3r90kuk/aYX3d8sBOTxziz+6RuEGiQpw0zI9yJO1vOB1tSsLYwoqG5U7/vrkXBPVIIAtyt2X60gLaOrm7BbHtnF1W1rUwePbCbQ28WRHuxIPrXm0F1QxsbD+TwU2weP8XmYWWm4LGbw/Wf3RBrC2PuvjaY/2w+y7hgJ+69NkQf+EklEiICHPjzslDe/ymFd35IZtEkb+qbO8grayT2TBlj/e15cFlory2SHo66xopSZXO3YDa9qA5vF8seXfnzo714/btEjqVW9kghic9U0qnScM143d/O2EjG8tn+yOUSdhwt5HSGki6NhvsXjzZ44/4tW0tjXrmvZ8rhpNHO/HAwl6/2ZPL0yiiszY3IKW3gVEYV10/1MZg2ZagXyNPJgsVTvNkWV0B85q+zTjy0LLTH9+T3poS6sPlQLoeSyqhuaCevtJE/LwvF361n6/qEYCfGBzmSml9LTGIpcpmU6eGueDhadAvKfs/UWN7rQmTWFsb4uFiSnFvNkik++u05JQ1UN7SzbLqvfptcJmVqmCu7ThTx5zcOGXy/aeGu3DZnFOmFdfznx7MkZFUzIdiJYym6yRGmjDHcoxHmZ4+9lTEHk0r7DcpLlc28szkZMxM5wV62uDuYsy2ugE92pPPY8vBuDyet7V28sTGJ4qpmHr0pnIhRv/4+vJwtWX1TGE99cIx9p4v7DMp3nyyiuU3FjTP9+ywb6H5Lwd62vHRPNF/tyWTLkXy2Hy3AwcaUri4N5ia69K2LIZNK+fPSUP71dTzv/ZTC3+8Yp1+3I6u4ntLqFu5eFIxEIuH6qb783zcJHEosJSrIkZ0niohNKsPBxpTHbw7HuZexMOctnORNXIpuGsuBTkUc6mfPDTP8+DE2D18XS9o61RRWNvHwDaH4uVnxyI1hpBXUUt3QzuQxzvqHcgtTRbe/UW+szI145MYw/vV1PB9uTWHOOE/Ka1p5YMnoC879vnGGH6n5tbjYmXVrdAHdb+94aiVbDucRFeSIk03PsR3nHUwsxUghZdJF/o2HQr9B+ejRozE2Nmby5Mk99nV2dl4Ro7GFSyezqB61RtvnDeaPZlqYKz/F5rHnVBFFlc04WJuwMNrwk/rvg4gAd2ucbE2JO1uOi50ZRnIpk8d0Dw5nRbqzP76EuORyFk3yZsfRAmwtjXukA/i7WfPwDb33OEkkEsL87DieVkmXWtNvMGKIRqNl44EcQrxteXx5OAq5jHkTPPk+JpeCCl2LN0DMuXSa3wb/EaMcsLYwIiaxVB+YFlc1o9Zo8XWxMni+37p9fhA+LlaE+tnpHzgWRntxOrOKoykV+EVYMTnUpUe39XkB7tZotbqW+d9+f0uULWhBP/PKpeJgbcrDN4SRkl9DSl4tiyZ598inNyRylCPrH52GlZnC4M0rKtCR+5aE8PG2NDJ/M6PNzAg3bp8f2GcA7HGu+7tE2ULouRbY9s4u8ssauz1QnBfsZYOXkwV7ThUzPdy1W3mOplTgaGNCiI+dPs9VIpFw4wx/5DIpWw7nc9ei4H4Dir4YKWQ8tCyUt344w2vfJvDXWyPZsD8bawujQa86umy6H9PCXSlVtlBa3YJWq9WnjfXFytyIiHPpV6CbnaavoFQikRDqZ6+v30sh3N+e7XEFNLV26ntADiaVYqyQEfW7wcXXTfbG1sKYLo0GjUaLVCLBytwIawsjHKxN9elJEQEOONqYsOdUEeODHDmaUkGQpw0Ovfx+pFIJ08e6seVwPpV1rb2mx6i61Px3WxomRjJevDta/503M5Hz9Z4sdp8sYtFEXc9Ja7uKNzedoaiymYeWhRoM9hRyGYsm+7BpXxZVda04GThvQ0snu08VMz7IsccDfV9MjeU8sGQMk0Y7k13SQGVtK1V1bSyI9uwz1WYw7//YzeG88sVp3tiYxPLZ/kQHO7M/vgRzEznR5xoCAj1tCPG25afD+Xx/MBeAqWGu3DzLv0fPiSHuDuY8vnyswfSWvlw32ZvCiiY2xejOOXmMc7eHw4u9z3u7WLJqYRD/25FOXlkj9lbGA+pl6Y2JkZyX7olGJpX0uDZKJBJunx/Ic/87wZe7MnhyRYTB62dbRxcn0iuZGOJ8Wc4S12+JHn74YUxNDf9IFQpFv4M8hatLfKYSEyMZgZ6GczD/iMxM5EwNc9FP3/bwDb/mhPZHIpEwJdSFLYfzyStvZHywU4+WPncHcwI9bTiYVIqvqxVZJQ2snDvqgoLqUD97DibpupR76w7tS3FVM+2daqaPddW3nMyKcGfH0UJ2Hi/iz8tCiUkoYXtcAZGjHLoNqpTLpMyOcGfLkXx9AJ9fbnjlOUNMjeXM+10PjVQqGXAXqJ+bFRIgp7Sh282m+NwCUN4Xkb7Sl1Bfe0J9Bxeg9Re8TxrtgqejBa0dXdhaGGNtYdxtwF5vLEwVWFsYUfKbaRFzShpQa7S9dvnPj/bkfzvSSc2v1QeatY3tZBTWsWSqj8Eb3/VTfZkV6W4wVWGwgr1teWL5WN76Ppm1n+oW1Ln72mBMjAZ/Q3WwNsXB2rTP3gpDZkW6E5+p1OcOD7exAQ5siysgJa+WyaEuVNe3cTKtirnjPXrUg7mJosfvxBCpVMLc8Z58ty+bvadLqKxr49rJvacZAUwPd2PbkQJiz5T1OuDzh4N5lCibeezm8G7f49mR7qQX1vHjoTyM5DJySxtIyFaiVmt5cGkokX3MXLRoig8/HMhmX3wJK+f2TDn4dm8WarVmQK3khoT7OwzZsvMO1qY8fstYPtmRzkfb0th2pICqujbmT+ge+N8404///HiWCUGuLJzo1S3PfSDOp3IMhkQi4Z7rQvjnV/G0dXSxct6lT+eYEupKfnkT++NLmDfB64LuW7/V1+vtrEy4eZY/X+/J4mhKBVPDeqamHU+toFOluegUzqHSb+1MnDix11U7JRIJ0dGGc22Fq0+XWkNClpLIUY4GB5n9kZ2/UY/xsSUqcHAX9/PdxZ0qjcFZJkB3Q1PWt/PxjjSszBS9HtefEG9bZFIJZ/MubOW/rBJdy2ygx69dpKbGcmZHunM6s4qvdmfy1Z4swv3teeD6MT1eP2+CJxamCn2uYkF5I1bmRthZ9UxDuNTMTBS4OZqTU9o9r7yoqhlzE8MzyFzO3B0tGOWha9kcSEB+noejRbegPLWgFplU0utgx+gQZ6wtjNh5okg/p/aJtEq0wOReBm8ClyQgPy/Iy5a/rBiLSq3By8mCqaG954EPhTE+dvz7oSncNHNkFkXzdrHEytyIM+fmdt59shiJBIO9G4MxLcwVU2MZmw7kYCSXMr6XFJrzbC2NGRtgT1xyeY85vztUak6mV7L3dDFzojx6PPhIJBLuXhSMraUx3+zN4mxeDVPGuPC3O8b122Nhb21KdIgTR5LLe8ydn5Cl5FRGFUum+hqcWely4ONixUv3Rp9Ll5Igk0mYFdU9KPR3s+bNR6axcl7goAPyi2FqLOf5O8fzj3ujBzxzyWCtuCaAx5eHM2fc0AfCsyLdCXC3ZsP+bBp/t+6DVqvlYFIZXufGbV2OBtXUkJOTQ15eHs7OzoSFhSHtJ09QuLqk5tfS2tFFdMiFdz9drVztdd2H3s4Wg86X0y0kYktDSyejegmMogIdsTRTUNfUwfJZ/gNuif89U2PdbAspeTXcPGvwrUrZJQ3YWxn3uGnMHe/BnlNFxCSWMi3MlVWLggymUZgay7lusjcbD+SQXlBLfkUTvucGdA6HAHdrTqZXodFq9XmtRZVNeDkPXxlGmoejOfvj61FrNDS2qDiYVMbYAMPTsYGuZWrBBC82xeSw7ut47pgfxNGUCvzdrXpNYRgKozxs+Nf9k1DIpYOa/eNSGc5A6fek51LPErOqqW/uIDa5jCmhLhf9IGlqLGfGWDd2nywmKshpQN35MyPcScyu5r9bU5HJJDS1qlDWt1HT0I4WcHc0Z/lsw9cWMxMFT90WSWVtK8HetoNqNZ03wZNjqZUcTi7Xj2lqbVfx1Z5MPJ0sWDTIdKbhJpVIGB/sRFSQI20dXUMWAF8IYyMZxgxdQ5tcJh2ynojfk0okrFoUzIufnmTD/uxujUP55U0UVzVzx4LBDeIdTgMKyisqKlizZg0ymYygoCAqKiooKyvj/fff188NLlz9TqZXYWYs7zHLhqBzId2H5z10QxhqjbbXC4VCLmXOOA9iEksvutst1M+OzYfy+PlYAfVNndQ3d7B0mq8+37g3Wq2W7JJ6g2kONhbG3DY3kPbOLhb2s4jDNVHu7DlVzMYDOZRXtxB9ETmGgxXgbs2hpDLKq1twd7SgtLqF/PKmboPlrnYejhZ0qTVU1rbx87EC1GoNt/QSRJ23INoTSzMFm2JyeOnzU2i1jMjMBVdab8alNNbfgbizFXy0LZWuLs2gc+p7M2+8J8m5NcyJGlhaTqivHb6ulmQU1WF+bsYRPzcrpoW54uZgzmgf2z4bDRxtTHsd99EXHxcrRnlYs+90Mc62utz4n48V0tSi4vGbx150WsRwkUokl1VAfjVydzBn8RQfth7JZ9IYF8L97alr6uCLXRkYG8mYdJGD+odSv0F5S0sL9913H0899RQzZ87Ub//ll19Yv349r7zyCjt27GDx4sVDWlBhZKm61CRmKxkf5HTFXPyuJANpoVoyxYdrJ3lfdP1HBDjw46E8Nh/Kw9RYhlqjRdnQxvOrxvc5SFBZ30ZDcyejPAyP7p89wIcFhVzGsmm+fLYzAwCfQQzMuljnUzRyShtwd7Rg94kijOTSAZf9anB+BpaDSaUcS63kusneBgfP/ZZEImFqmCtjAxz48VAumcX1TBjgVGbCpTHG1w6ZVEJGUT3jghwHvJBWf+ysTPjn/ZMGfLxUKuH5VRMuybkHa/EUH975IZm3f0jWb1s0ycvgPODCH9u1k7w5mV7JV7sz+H/Xh/LB1hRaO7p4aFnoZTnA87x+S/bZZ5+xcOFCZs6cyfPPP09Xly6fS6PRkJCQAMDWrVvRaDRcf/31Q1taYcSk5NXS3qkWqSsjSCKRIJddfJebu6MFr/55MiZGcsxN5MRnKnl/S0q/87tmn5vju7cUm8GYEubCrpNFlNe04juMy3Y72ZhiaaYgp7SBcH8HjqVWMDPC7Q8z5z7oFgWSSGDf6RJsLY25rp/Bfb9lYargzoXBQ1g6oTemxrqFt9IL67h20sD/ZleTMD973nx0GhU1rVTUttLcphqWPGXhyqOQS7l7UQjrvo7nX1/HY2tpzLN/irqo9SiGQ79Nbnv27OGmm24CwN3dHa1Wy8KFC5FKpfrW8UceeYQNGzYMbUmFEXUyowoLU0W3BTyEK5eDtSkWprop98YFORIR4MCWI3ko69t6fU1WcT3mJnL9XLsXQyaVcve1ISyb5jusAbFEIiHA3Zqc0kb2nS5Go9Uy/yIHy11pFHKZfkDcLbMDLmgWE2FkLJniw00z/QY17d/VxsJUQYCHNdPCdbOUiEkHhN4EeFhz3RQfAj2s+fsd4y77gBwG0FJeWVmJq6tupPumTZvYvXs3CoWCyZMns3TpUh577DFCQ0PJzc0d8sIKI6NDpSYpu5qJo51F6spV6Pz8rn//3wm+2pPJE8vHGswJzy5pIMDdut8ljAcqwN26x7LSwyHA3ZrE7GoOJJYyPsipz0UmrlaRoxxxtW8VPV9XmGBvW9EwIgiDcOOMkZkx6UL1G2FZWFhQXa2bhkkikZCTo1tCPDc3l85O3XQzLS0tmJiM3Mh0YWidza2hQyVSV65mdlYm3DjDj5S8Wv63I53CiqZu+xtbO6mobWXUAFeLu5z5n3sQ6OhUX7LBcleam2f588iNYZftDASCIAh/RP22lE+aNIm9e/dy22238eSTT3L33Xfj5eVFcXExa9euBSA2Npbx48cPeWGFkXEyowpLMwVBXld+QCb0bk6UB8q6NmKTyziWWoG/mxU3zvAjxMeO7GJdPnlgL4M8ryQ+LpbIZbo0lj9yGoAgCIJweek3KL/33nt54IEHmDNnDtdeey1Tp06lsLAQb29vrK2tqa6u5p133uGdd94ZjvIKw6y9s4vknGqmhrn2OTOHcOWTSiWsnBfIsum+xJ2tYO/pYl7fkMTccR50abTIZdKrYpYDI4WMR28Kv2wXGhEEQRD+mPqNsvz8/Hj66ae54447+OWXXzAzMyM8PBxzc3P27NnD7bffzurVqwkOFiPyr0Zncmro7NKI1JU/ELNzy3S/fN9E5o7zYF98CQcTS/FztRzUypGXszA/+wuaK1kQBEEQhsqAht3Pnz+fgIAAPv74Y9544w0ApFIpkZGRvPvuu4waNWpICymMnFMZVVhbGPU6N7Vw9TJWyFg5L5DIUQ58sy+biZfxgguCIAiCcKUb8FxYfn5+rFu3bijLIlxm2jq6SM6tYWaE24gsay1cHkJ87HjlvokjXQxBEARBuKoNKChXqVQoFLplYU+fPo1Wq9Xvi4yMRC4X89xejZKyq+lSi9QVQRAEQRCEodZvNP3tt9+SmJjI66+/DugGftrY6FIZ2tvb+etf/8ry5cv7PVF+fj5r1qyhvr4eGxsbXn31VXx8fLods3nzZj7//HOkUikajYbly5dz5513AvD000+TmZmpPzYzM5P33nuPOXPm8O677/Ltt9/i5KQLHqOiovQzwwgD19DSSX1TB17OFkgkEk5lVGFraayfQk4QBEEQBEEYGv0G5Vu3buWll17S/9/IyIhDhw4BkJ6ezosvvjigoHzt2rWsXLmSpUuXsnXrVl544QW+/PLLbscsWLCAG2+8EYlEQnNzM0uWLCE6Oprg4GBee+01/XEZGRmsWrWK6dOn67ctW7aMZ555pv9PLPRQ19TBzhOFHEoqQ9Wlwc/NivkTPEnJr+GaKI9LtliMIAiCIAiCYFi/UymUlJR0m1nF399f/+/g4GCKi4v7PUlNTQ1paWksXrwYgMWLF5OWlkZtbW234ywsLPSLWbS3t6NSqQwubvHDDz+wZMkSjIyGb3nuq9XJ9Eqe+fAYB+JLmRjizG1zR9HQ3MGHW1PpUmuZIFJXBEEQBEEQhly/LeWtra20trZiZqab03fDhg3d9rW1tfV7kvLycpydnZHJZADIZDKcnJwoLy/Hzs6u27H79+9n/fr1FBUV8eSTTxIUFNRtf2dnJ9u3b+fzzz/vtv3nn3/myJEjODo68uijjxIZGdlvuQSISSjF3sqYJ1ZE6Jcbnx3pztGUCpT1bfiJxVUEQRAEQRCGXL9B+ahRo4iLi2PevHk99h05coSAgIBLWqA5c+YwZ84cysrKePjhh5kxYwZ+fn76/fv27cPNzY2QkBD9tltvvZUHH3wQhUJBXFwcDz30EL/88gu2trYDPq+9vcUl/RyD4eg4MguyqLrU5Jc3snCKD2NGdW8Rv8nl8s0jH6n6ulKJ+ho8UWeDI+pr8ESdDY6or8ETdTY4l0N99RuUr1q1ipdeegmJRMI111yjH4S5f/9+Xn75ZdasWdPvSVxdXamsrEStViOTyVCr1VRVVeHq6trra9zc3AgLC+PgwYPdgvLNmzdz0003dTvW0dFR/++pU6fi6upKdnY20dHR/ZbtvJqaZjQabf8HXmKOjpYolU3Dfl6AnJIGOrs0eNqbjVgZBmsk6+tKJOpr8ESdDY6or8ETdTY4or4GT9TZ4AxnfUmlkl4bgvsNyq+77joqKyt56qmnUKlU2NjYUF9fj0Kh4OGHH9bniffF3t6ekJAQduzYwdKlS9mxYwchISE9Uldyc3P1Oeu1tbWcOHGC+fPn6/dXVFQQHx/P+vXru72usrISZ2fdwibp6emUlpbi6+vbb7n+6LJK6gHEwkCCIAiCIAgjbEATjN9zzz3ccsstJCYmUldXh42NDZGRkVhaDryp/8UXX2TNmjW8//77WFlZ8eqrrwJw//33s3r1asLCwti4cSNxcXHI5XK0Wi23334706ZN07/HTz/9xOzZs7G27p5asX79elJTU5FKpSgUCl577bVureeCYVnF9bjYmWFlLgbMCoIgCIIgjCSJ9rcrARlQX19PcnIyM2bM6LEvNjaWsWPH9giSr0R/tPQVjUbLo28fZkKwI3ctCun/BZcJ0SU3OKK+Bk/U2eCI+ho8UWeDI+pr8ESdDc7lkr7S75SIH3zwAampqQb3paen8+GHH15c6YQRUaJspq2ji0BPkboiCIIgCIIw0voNymNiYlixYoXBfbfccgv79++/5IUShl52SQMAgSKfXBAEQRAEYcT1G5RXV1f3GJB5no2NDdXV1Ze8UMLQyyqux9bSGHtrk5EuiiAIgiAIwh9ev0G5tbU1eXl5Bvfl5+djZSUWl7nSaLVaskrqCfS0MbhiqiAIgiAIgjC8+g3K586dyz//+U/a29u7bW9vb2fdunUsWLBgyAonDA1lfRsNzZ0Eelz5A3QFQRAEQRCuBv1OifjYY4+xatUq5s6dy/Tp03F0dESpVHL48GFcXV159NFHh6OcwiWUVazLJx8lBnkKgiAIgiBcFvoNyi0sLNiwYQNbtmzh2LFjpKSkYGNjw2OPPcbSpUsxMhJzXF8Jvt6TyaGkMjRaLVotmJvIcXMwH+liCYIgCIIgCAxw8SCFQsHy5ctZvnz5UJdHGAL1zR0cSioj0NMGf3drpBLwc7NGKvLJ4DC1JwAAIABJREFUBUEQBEEQLgsDCsqrq6v59NNPiY+Pp76+HhsbG8aPH89dd90lVs68AsQmlaHWaLlzQRDOdmYjXRxBEARBEAThd/oNypVKJTfeeCN2dnbMmTMHJycnKisriYmJYevWrfz44484OTkNR1mFC9Cl1nAwqZRQXzsRkAuCIAiCIFym+g3KP/zwQyIjI3nrrbeQSn+drGX16tU88cQTfPjhh7zwwgtDWkjhwiVlV1Pf3MmdCzxGuiiCIAiCIAhCL/qdEjEuLo7HHnusW0AOIJFIePTRR4mLixuywgkX70BCCfZWJoT72490UQRBEARBEIRe9BuUK5VKfHx8DO7z8fGhqqrqUpdJuERKlc1kFNUzO8odqVQM6hQEQRAEQbhc9RuUA8hksl63ixUhL197ThUjl0mZHu460kURBEEQBEEQ+tBvTnlHRwdPP/20wX1arZbOzs5LXijh4u06UcTh5HLmjvPA0kzMJS8IgiAIgnA56zcof/DBBy9qvzD89p0uZlNMDhOCnVgxJ2CkiyMIgiAIgiD0o9+g/JFHHrkkJ8rPz2fNmjX6ec5fffXVHrnqmzdv5vPPP0cqlaLRaFi+fDl33nknAO+++y7ffvutfvrFqKgo1q5dC0BbWxvPPvssqampyGQynnnmGWbPnn1Jyn0l0Wq17Isv4bt92UQFOnL/ktHIpAPKUBIEQRAEQRBGUL9B+f9v796jqqrz/48/zwG84hFBwIOXFL+K5OWbK9OpFEssnQnzUjZmVGNpFx0rUyfGZsCyVaFrubIZzO9Y6di4HPMSFJmVNMyoZepPJy21zEzHOIIe5CYieNi/P6wzEXA424ADnNdjrdba7svZ7/Nee3968zmf/dl79uyp80Ouu+66OvdJSUlh6tSpjB8/noyMDJKTk1mzZk2VfcaMGcOkSZOwWCyUlJQwbtw4hg4dSr9+/QCYMGECTz31VLXPfu211wgODubDDz/k22+/5Z577uGDDz6gfXv/eY382cILrNn6JZ8fz+ea/+nMI+P7ExigglxERESkOaizKJ83b16N6y0WC0VFRVy4cIHDhw97/Ayn08mhQ4dYtWoVAAkJCSxatIj8/HxCQ0Pd+wUHB7uXy8rKqKio8OpB0vfee48XX3wRuDwjzIABA/jXv/7FL3/5yzqPbQk++eI0a97/Egy455a+l2db0QO4IiIiIs1GnUX5P//5z2rrnE4nr7zyCps3b2bKlCl1nsThcBAZGemexSUgIICIiAgcDkeVohwgKyuLpUuXcvLkSebOnUtMTIx727vvvsuOHTsIDw9n9uzZDB48GICcnBy6du3q3s9ut3P69Ok642op1m07SpfQdsyaMIDOIW19HY6IiIiImFRnUf5jRUVFrFy5knXr1nHLLbfw9ttv061b/b4pMj4+nvj4eHJycpg1axZxcXFER0czZcoUHnnkEYKCgti5cyczZ85ky5YtdOrUqV7OGxYWXPdODSQ8vMMVH1taVkHJhQruGNWH2D4R9RhV0/Vz8uWPlC/zlDNzlC/zlDNzlC/zlDNzmkK+vCrKS0tLef3111mzZg033HADb775JtHR0V6fxG63k5ubi8vlIiAgAJfLRV5eHnZ77fNnR0VFMXDgQLKzs4mOjiY8PNy97cYbb8Rut3P06FGGDh1KVFQU3333nbvX3eFwMGzYMK/jA3A6S6isNEwdUx/Cwztw5kzxFR9/6kwJAG0DLT/rc5qLn5svf6N8maecmaN8maecmaN8maecmdOY+bJaLbV2BNf5JOBrr71GfHw8X3zxBWvWrOGll14yVZADhIWFERsbS2ZmJgCZmZnExsZWG7py7Ngx93J+fj6ffvopffv2BSA3N9e97fDhw3z33Xf06tULgLFjx7J+/XoAvv32Ww4ePMiIESNMxdhcnS0sAyCsYxsfRyIiIiIiV6rOnvIlS5bQsWNHCgsLWbRoUY37rF27ts4TLVy4kKSkJJYvX47NZiM1NRWAGTNm8NhjjzFw4EDWr1/Pzp07CQwMxDAMEhMTGT58OABLly7liy++wGq1EhQUxOLFi9295w8++CBJSUnccsstWK1Wnn322SoPjbZkzu+L8s4dNZZcREREpLmqsyh/4YUX6uVEvXv3ZsOGDdXWr1y50r28YMGCWo//oYivSbt27Xj55Zd/XoDN1NnCCwQFWrG1C/J1KCIiIiJyheosyidOnNgYccgVchaWEWZr49XUkSIiIiLSNOntMs3c2cIyOms8uYiIiEizpqK8mVNRLiIiItL8qShvxsrKL1FyoUIzr4iIiIg0cyrKmzGnpkMUERERaRG8fqNneXk5b731FocPH6a0tLTKtsWLF9d7YFI3Z5GmQxQRERFpCbwuypOSkjhy5Ag333wznTt3bsiYxEtn3XOUq6dcREREpDnzuijfvn07WVlZ2Gy2hoxHTDhbWEZggBVb+1a+DkVEREREfgavx5Tb7XbKy8sbMhYx6WxhGWEd22DVHOUiIiIizZrXPeUTJkxg5syZ3HfffYSFhVXZdv3119d7YFI3Z2EZnW2tfR2GiIiIiPxMXhflf/vb3wBYunRplfUWi4WsrKz6jUq84iy8QPc+4b4OQ0RERER+Jq+L8o8++qgh4xCTLla4KCqt0EOeIiIiIi2A10U5wKVLl9i/fz+5ubl06dKFa665hsBAUx8h9cSpmVdEREREWgyvK+pjx47x6KOPUlZWht1ux+Fw0Lp1a1asWEHv3r0bMkapwX+nQ9Qc5SIiIiLNnddF+TPPPMNdd93Fgw8+iOX72T5ee+01Fi5cyBtvvNFgAUrNfnhxkN7mKSIiItL8eT0l4pEjR5g2bZq7IAe4//77OXLkSIMEJp6dLbxAgNVCx2DNUS4iIiLS3HndUx4REcHu3burTH+4d+9eIiIivDr++PHjJCUlUVBQQEhICKmpqfTs2bPKPps2bWL16tVYrVYqKyuZPHky9913HwBpaWls2bIFq9VKUFAQc+bMYcSIEcDlt41+/PHHdOrUCYCxY8fy6KOPevvVmiWn5igXERERaTG8LsrnzJnDzJkzuemmm4iKiiInJ4fs7GyWLFni1fEpKSlMnTqV8ePHk5GRQXJyMmvWrKmyz5gxY5g0aRIWi4WSkhLGjRvH0KFD6devH4MGDeKBBx6gbdu2HDlyhMTERHbs2EGbNpeHbzz00EMkJiaa+OrN29nCMj3kKSIiItJCeD18JT4+ns2bN9OnTx/Onz9Pnz592Lx5M6NHj67zWKfTyaFDh0hISAAgISGBQ4cOkZ+fX2W/4OBg9/CYsrIyKioq3P8eMWIEbdtefqgxJiYGwzAoKCjwNvwWxTAMzhRcIMymolxERESkJTA1n2GvXr2YOXOm6ZM4HA4iIyMJCAgAICAggIiICBwOB6GhoVX2zcrKYunSpZw8eZK5c+cSExNT7fPS09Pp0aMHXbp0ca9btWoV69evp3v37sydO7dFzwiT4yyluLSCXnabr0MRERERkXrgsSj/4x//yKJFiwCYP39+lYc8f2zx4sX1FlB8fDzx8fHk5OQwa9Ys4uLiiI6Odm/fvXs3y5Yt4/XXX3evmzNnDuHh4VitVtLT05k+fTrbtm1z/xHgjbCw4Hr7DmaFh3cwtf/2z08DcPPQq+gc4n9TIprNl79TvsxTzsxRvsxTzsxRvsxTzsxpCvnyWJR369bNvXzVVVdd8Unsdju5ubm4XC4CAgJwuVzk5eVht9trPSYqKoqBAweSnZ3tLsr379/P/PnzWb58eZVCPTIy0r08YcIEXnjhBU6fPk3Xrl29jtHpLKGy0riCb/fzhId34MyZYlPH7Pwshx4RwRgVl0wf29xdSb78mfJlnnJmjvJlnnJmjvJlnnJmTmPmy2q11NoR7LEof/jhh93Lv/71rwkPD6+2z5kzZ+oMICwsjNjYWDIzMxk/fjyZmZnExsZWG7py7Ngx97CT/Px8Pv30U2699VYADhw4wJw5c3j55Zfp379/leNyc3Pdhfn27duxWq1VCvWWpORCBV+fKuRX11/5H0kiIiIi0rR4PaZ8zJgx7Nu3r9r62267jd27d9d5/MKFC0lKSmL58uXYbDZSU1MBmDFjBo899hgDBw5k/fr17Ny5k8DAQAzDIDExkeHDhwOXX15UVlZGcnKy+zMXL15MTEwMTz31FE6nE4vFQnBwMK+88gqBgaaGyzcbnx93UmkY/O//hPk6FBERERGpJ15XroZRfWhHSUlJrePMf6p3795s2LCh2vqVK1e6lxcsWFDr8Zs2bap12+rVq72KoSU48LWTDu2C9JCniIiISAtSZ1E+cuRILBYLFy9e5KabbqqyraCggNtuu62hYpOfcFVWcvAbJ9f06ayXBomIiIi0IHUW5UuWLMEwDB566KEqs6xYLBbCwsKqPHApDevYd0WcL7vE//bu7OtQRERERKQe1VmUDx06FIBdu3a5X94jvvHZ12cJsFro3yu07p1FREREpNnwekx527ZtOXz4MHv37uXcuXNVxpg//vjjDRKc/JdhGPz767PE9AihbeuW+RCriIiIiL+yervj+vXrufvuu9m1axcrV67kq6++YtWqVZw8ebIh45Pvbf30JA5nKcNiW+ZUjyIiIiL+zOui/NVXX+XVV18lLS2NNm3akJaWxrJly1rs1INNycFvnGzMPsbQ2AiGD6r9hUsiIiIi0jx5XZQ7nU6GDBly+SCrlcrKSkaOHMk//vGPBgtOIPdcKf+X8QXdIoKZ9stYr6egFBEREZHmw+tu7i5dunDq1Cm6detGz549ycrKolOnTgQFBTVkfH6r4pKL//flGTJ2HMdqtTB70kBatwrwdVgiIiIi0gC8LsqnT5/OsWPH6NatGzNnzuTxxx+noqKCp59+uiHj8zuuyko2ZX/D9gM5nC+7ROeObZg1cQCdQzTzjYiIiEhL5XVRPmnSJPfyyJEj2b17NxUVFbRv375BAvNXH+37jq27TzKkXwQ3XRNFv6s66UVBIiIiIi2cx6K8srKy9gMDAwkMDKSyshKr1euh6eJBUWk56duP079nJx4d31/jx0VERET8hMei/Oqrr/aqMDx8+HC9BeTP3vrXN5RXuLh7dF8V5CIiIiJ+xGNRnpWV5V7Ozs7m/fff5+GHHyYqKoqcnBxWrlzJrbfe2uBB+oMTp4v5179zuOW67kR11pAgEREREX/isSjv2rWre3n16tVs2rQJm80GQK9evRgwYAB33HEHU6dObdgoWzjDMFj74Vd0aBfE7Tf28nU4IiIiItLIvB4MXlxczIULF6qsKysro7i4uN6D8jenzpzn6+8KGXdjL9q10cuYRERERPyN1xXgxIkTmTZtGvfffz9dunTh9OnTvPHGG0ycOLEh4/MLBSUXAbiqSwcfRyIiIiIivuB1UT5//nx69OjBli1byMvLIzw8nHvuuYe77rrLq+OPHz9OUlISBQUFhISEkJqaSs+ePavss2nTJlavXu1+Y+jkyZO57777AHC5XDz33HNs374di8XCQw89xOTJk+vc1hwUnS8HwNZOL2ISERER8UdeF+VWq5W7776bu++++4pOlJKSwtSpUxk/fjwZGRkkJyezZs2aKvuMGTOGSZMmYbFYKCkpYdy4cQwdOpR+/frxzjvvcPLkST744AMKCgqYMGEC119/Pd26dfO4rTlwF+XtW/k4EhERERHxBY9FeXp6OhMmTABg48aNte535513ejyJ0+nk0KFDrFq1CoCEhAQWLVpEfn4+oaGh7v2Cg4Pdy2VlZVRUVLinBtyyZQuTJ0/GarUSGhrK6NGj2bp1K9OnT/e4rTkoKi2nVZCVNq00nlxERETEH3msAt999113UZ6RkVHjPhaLpc6i3OFwEBkZSUBAAAABAQFERETgcDiqFOVweRrGpUuXcvLkSebOnUtMTIz7M6Kiotz72e12Tp8+Xee25qDofDm2duolFxEREfFXHovylStXupffeOONBg8GID4+nvj4eHJycpg1axZxcXFER0c3+HnDwoLr3qmBXKioJKxjW8LD9aCnN5Qnc5Qv85Qzc5Qv85Qzc5Qv85Qzc5pCvjwW5ZWVlV59iNXqeWZFu91Obm4uLpeLgIAAXC4XeXl52O32Wo+Jiopi4MCBZGdnEx0djd1uJycnh0GDBgFVe8c9bfOW01lCZaVh6pj6EB7eAWfBBcJsbThzRtNL1iU8vIPyZILyZZ5yZo7yZZ5yZo7yZZ5yZk5j5stqtdTaEeyxKL/66qs9vu7dMAwsFguHDx/2GEBYWBixsbFkZmYyfvx4MjMziY2NrTZ05dixY/Tu3RuA/Px8Pv30U/cbQ8eOHcuGDRu49dZbKSgoYNu2baxdu7bObc1B0flyetltvg5DRERERHzEY1GelZVVbydauHAhSUlJLF++HJvNRmpqKgAzZszgscceY+DAgaxfv56dO3cSGBiIYRgkJiYyfPhwAMaPH89nn33mLtJnzZpF9+7d69zW1FVWGhSXVmBrr+kQRURERPyVxTCMxh+z0QT5avhKq7atSEzZytTRfRg9pHn8IeFL+knOHOXLPOXMHOXLPOXMHOXLPOXMnGYxfOWnsrKy2LNnD+fOnePHtfzixYt/XoR+7Ie3eWqOchERERH/5fkJzR/585//TEpKCpWVlWzdupWQkBB27NiBzaax0D9HQfH3RbmmRBQRERHxW14X5Zs2beL1119nwYIFBAUFsWDBAlasWMGpU6caMr4Wz12Uq6dcRERExG95XZQXFRXRt29fAIKCgqioqGDQoEHs2bOnwYLzB4UaviIiIiLi97weU96jRw+OHj1Knz596NOnD+vWrcNms9GxY8eGjK/FKyi5SIDVQrs2pob3i4iIiEgL4nUl+MQTT1BQUADAvHnzmDt3LqWlpaSkpDRYcP6goPgiHdoFYfUwH7yIiIiItGx1FuWVlZVYrVZGjhzpXjdo0CA+/PDDBg3MXxSUXNTQFRERERE/V+eY8ri4OBYvXsxXX33VGPH4nYJiFeUiIiIi/q7OonzhwoWcOnWKO++8k4kTJ/LXv/6V/Pz8xojNLxSUXNR0iCIiIiJ+rs7hK6NHj2b06NEUFRWxZcsWMjIyWLJkCcOHD2fixImMGjWKoCC9Iv5KGIahnnIRERER8X5KRJvNxpQpU1i3bh3vvfceAwYM4IUXXmD48OENGV+LVlbuouJSpXrKRURERPyc10X5D8rLyzl48CAHDhzg7Nmz7rnLxbyi8+UA2NrrlwYRERERf+b1lIh79+4lIyODrVu3Ehoayu23305KSgpdu3ZtyPhatEJ3Ua6echERERF/VmdR/qc//Ym3336bgoICxo4dy4oVK7j22msbI7YWr7j0+6Jcw1dERERE/FqdRflnn33GE088wejRo2ndunVjxOQ3fhi+0lE95SIiIiJ+rc6i/NVXX22MOPxS4flyLBYIbqcx5SIiIiL+zOsx5T/X8ePHSUpKoqCggJCQEFJTU+nZs2eVfdLS0tiyZQtWq5WgoCDmzJnDiBEjAPjNb37DuXPnAHC5XBw9epSMjAz69etHUlISH3/8MZ06dQJg7NixPProo4311a5YUWkFHdq1IsBq+nlbEREREWlBGq0oT0lJYerUqYwfP56MjAySk5NZs2ZNlX0GDRrEAw88QNu2bTly5AiJiYns2LGDNm3asHr1avd+27Zt46WXXqJfv37udQ899BCJiYmN9XXqRfH5ckI6aEiQiIiIiL9rlC5ap9PJoUOHSEhIACAhIYFDhw5VezPoiBEjaNu2LQAxMTGXX65TUFDt8zZu3Mgdd9zR8IE3sMLSckKCVZSLiIiI+LtG6Sl3OBxERkYSEBAAQEBAABERETgcDkJDQ2s8Jj09nR49etClS5cq68+cOcMnn3zC888/X2X9qlWrWL9+Pd27d2fu3Ln07t3bVIxhYcGm9q8P58suEdU5mPDwDo1+7uZM+TJH+TJPOTNH+TJPOTNH+TJPOTOnKeSr0YavmLF7926WLVvG66+/Xm1beno6I0aMqFLMz5kzh/DwcKxWK+np6UyfPp1t27a5/wjwhtNZQmWlUS/xe6uguIyQDq05c6a4Uc/bnIWHd1C+TFC+zFPOzFG+zFPOzFG+zFPOzGnMfFmtllo7ghtl+Irdbic3NxeXywVcflAzLy8Pu91ebd/9+/czf/580tLSiI6OrrZ98+bN1YauREZGYv3+YckJEyZQWlrK6dOnG+Cb1J+KSy4uXHTRUcNXRERERPxeoxTlYWFhxMbGkpmZCUBmZiaxsbHVhq4cOHCAOXPm8PLLL9O/f/9qn7Nv3z6Ki4uJi4ursj43N9e9vH37dqxWK5GRkQ3wTerPD2/z1IOeIiIiItJow1cWLlxIUlISy5cvx2azkZqaCsCMGTN47LHHGDhwIM888wxlZWUkJye7j1u8eDExMTHA5V7yCRMmVBuW8tRTT+F0OrFYLAQHB/PKK68QGNgkR+a4lVyoAFSUi4iIiAhYDMNo3IHUTVRjjymvuFRJ5sffct+4/hQXXmi08zZ3GidnjvJlnnJmjvJlnnJmjvJlnnJmjl+NKZfqggKtTIyLpk2rpt2jLyIiIiINT0W5iIiIiIiPqSgXEREREfExFeUiIiIiIj6molxERERExMf0lOH3rFaLX567OVK+zFG+zFPOzFG+zFPOzFG+zFPOzGmsfHk6j6ZEFBERERHxMQ1fERERERHxMRXlIiIiIiI+pqJcRERERMTHVJSLiIiIiPiYinIRERERER9TUS4iIiIi4mMqykVEREREfExFuYiIiIiIj6koFxERERHxsUBfB+Cvjh8/TlJSEgUFBYSEhJCamkrPnj19HVaTce7cOX73u99x8uRJWrVqxVVXXcWzzz5LaGgoMTEx9O3bF6v18t+UixcvJiYmxscR+96oUaNo1aoVrVu3BmDevHmMGDGCf//73yQnJ3Px4kW6du3KkiVLCAsL83G0vnfq1ClmzZrl/ndxcTElJSXs3r271lz6m9TUVN5//32+++473nnnHfr27Qt4br/8vW2rKWee2jPAr9u02q4xT/egv7dpNeXMU3sGnvPZ0nm6/zxdSz65zgzxiXvvvddIT083DMMw0tPTjXvvvdfHETUt586dM3bt2uX+94svvmj8/ve/NwzDMPr27WuUlJT4KrQm6+abbza+/PLLKutcLpcxevRoY8+ePYZhGEZaWpqRlJTki/CavOeee8545plnDMOoOZf+aM+ePUZOTk61fHhqv/y9baspZ57aM8Pw7zattmustntQbVrtOfuxH7dnhuHfbVpt95+na8lX15mGr/iA0+nk0KFDJCQkAJCQkMChQ4fIz8/3cWRNR0hICMOGDXP/+5prriEnJ8eHETVPn3/+Oa1bt2bIkCEATJkyha1bt/o4qqanvLycd955hzvuuMPXoTQpQ4YMwW63V1nnqf1S21ZzztSe1a6mfHmiNq3unKk9q6q2+8/TteSr60zDV3zA4XAQGRlJQEAAAAEBAUREROBwONw/Z8p/VVZWsm7dOkaNGuVed++99+JyuYiLi2P27Nm0atXKhxE2HfPmzcMwDK699lqefPJJHA4HUVFR7u2hoaFUVla6hxbIZR999BGRkZH079/fve6nubTZbD6MsOnw1H4ZhqG2rQ41tWegNq0mNd2DatPqVlN7BmrToOr95+la8tV1pp5yafIWLVpEu3btSExMBCA7O5vNmzezdu1avv76a9LS0nwcYdOwdu1a3n77bTZt2oRhGDz77LO+DqnZ2LRpU5VeJeVSGspP2zNQm1YT3YNX7qftGSifP6jp/mtKVJT7gN1uJzc3F5fLBYDL5SIvL8/UT3j+IjU1lRMnTvDSSy+5H4L6IU/BwcFMnjyZffv2+TLEJuOHvLRq1YqpU6eyb98+7HZ7lZ/J8/PzsVqt6lH6kdzcXPbs2cO4cePc62rKpVzmqf1S2+ZZTe0ZqE2rSW33oNo0z2pqz0BtGlS//zxdS766zlSU+0BYWBixsbFkZmYCkJmZSWxsrH7e/YmlS5fy+eefk5aW5v4pt7CwkLKyMgAuXbrE+++/T2xsrC/DbBJKS0spLi4GwDAMtmzZQmxsLAMGDKCsrIy9e/cC8Pe//52xY8f6MtQm56233mLkyJF06tQJqD2Xcpmn9kttW+1qas9AbVpNPN2DatM8+2l7BmrToOb7z9O15KvrzGIYhtHgZ5Fqjh07RlJSEkVFRdhsNlJTU4mOjvZ1WE3G0aNHSUhIoGfPnrRp0waAbt26MX36dJKTk7FYLFy6dInBgwezYMEC2rdv7+OIfes///kPs2fPxuVyUVlZSe/evfnDH/5AREQE+/btIyUlpcq0Tp07d/Z1yE3GmDFjePrpp4mLiwM859LfPPfcc3zwwQecPXuWTp06ERISwrvvvuux/fL3tq2mnL300ks1tmdpaWns37/fr9u0mvK1YsUKj/egv7dptd2XUL09A7VptdUTaWlpHq8lX1xnKspFRERERHxMw1dERERERHxMRbmIiIiIiI+pKBcRERER8TEV5SIiIiIiPqaiXERERETEx1SUi4hIg4iJieHEiRO+DkNEpFkI9HUAIiLSOEaNGsXZs2cJCAhwr5s4cSLJyck+jEpEREBFuYiIX1mxYgU33HCDr8MQEZGf0PAVERE/t3nzZqZMmcKzzz7Ltddey9ixY/nkk0/c23Nzc3nkkUcYOnQot9xyC2+++aZ7m8vlYsWKFYwePZrBgwczadIkHA6He/vHH3/MrbfeypAhQ3jmmWf44X11J06cIDExkWuvvZZhw4bxxBNPNN4XFhFpgtRTLiIiHDhwgLFjx7Jr1y4+/PBDfvvb35KVlUVISAhPPvkkffr0Yfv27XzzzTdMmzaN7t27c/3117Nq1Sreffdd/vKXv9CrVy++/PJL96usAbKzs9m4cSMlJSVMmjSJm2++mbi4OJYtW8aNN97ImjVrqKio4ODBgz789iJPs0CoAAACd0lEQVQivqeechERPzJr1iyGDBni/u+HXu/Q0FDuv/9+goKC+NWvfkWvXr3Izs7G4XCwb98+5s2bR+vWrYmNjWXy5MlkZGQAsGHDBh5//HGio6OxWCz069ePTp06uc83Y8YMbDYbUVFRDBs2jCNHjgAQGBhITk4OeXl5tG7dmiFDhjR+MkREmhAV5SIifiQtLY29e/e6/7vrrrsAiIyMxGKxuPeLiooiLy+PvLw8OnbsSHBwcJVtubm5AJw+fZoePXrUer7w8HD3ctu2bTl//jwA8+fPxzAM7rzzTm677TY2btxYr99TRKS50fAVEREhNzcXwzDchbnD4WDUqFFERERQWFhISUmJuzB3OBxERkYC0KVLF06ePEnfvn1NnS88PJznnnsOgL179zJt2jSuu+46rrrqqnr8ViIizYd6ykVEhPz8fPf47vfee49jx44xcuRI7HY7gwcPZunSpVy8eJEjR46wceNGbr/9dgAmT57MsmXL+PbbbzEMgyNHjnDu3Lk6z/fee+9x+vRpADp27IjFYsFq1f+SRMR/qadcRMSPPPLII1XmKb/hhhuIj49n0KBBnDhxgl/84hd07tyZl19+2T02fOnSpaSkpDBixAhsNhuzZ892T6s4bdo0ysvLeeCBBzh37hzR0dGkpaXVGcfBgwd5/vnnKSkpISwsjKeffpru3bs3zJcWEWkGLMYP81OJiIhf2rx5Mxs2bGDdunW+DkVExG/pt0IRERERER9TUS4iIiIi4mMaviIiIiIi4mPqKRcRERER8TEV5SIiIiIiPqaiXERERETEx1SUi4iIiIj4mIpyEREREREfU1EuIiIiIuJj/x/FfYHGmKYXTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@10\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr, test_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'test_tr.csv'),\n",
    "    os.path.join(pro_dir, 'test_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)\n",
    "\n",
    "batch_size_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "#     int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "# print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I/model\n"
     ]
    }
   ],
   "source": [
    "n10_list = []\n",
    "r1_list, r5_list = [], []\n",
    "# p1_list, p5_list = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        \n",
    "        n10_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=10))\n",
    "        MAP = MAP(pred_val, test_data_te[idxlist_test[st_idx:end_idx]])\n",
    "\n",
    "#         p1_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        p1 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "#         r1_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        recall, rec_1 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "        r1_list.append(recall)\n",
    "        \n",
    "#         p5_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        p5 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "#         r5_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        recall, rec_5 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "        r5_list.append(recall)\n",
    "\n",
    "n10_list = np.concatenate(n10_list)\n",
    "\n",
    "# p1_list = np.concatenate(p1_list)\n",
    "r1_list = np.concatenate(r1_list)\n",
    "\n",
    "# p5_list = np.concatenate(p5_list)\n",
    "r5_list = np.concatenate(r5_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@10=0.44678587338775005\n",
      "Test MAP=0.3925959123623205\n",
      "Test Prec@1=0.54\n",
      "Recall: 0.03246492985971944\n",
      "F1@1 0.06124763705103969\n",
      "Test Prec@5=0.4653333333333333\n",
      "Recall: 0.13987975951903808\n",
      "F1@5 0.21510015408320493\n"
     ]
    }
   ],
   "source": [
    "# print(\"Test NDCG@10=%f (%f)\" % (np.mean(n10_list), np.std(n10_list) / np.sqrt(len(n10_list))))\n",
    "print(\"Test NDCG@10={}\".format(np.mean(n10_list)))\n",
    "print(\"Test MAP={}\".format(MAP))\n",
    "# print(\"Test Prec@1=%f (%f)\" % (np.mean(p1_list), np.std(p1_list) / np.sqrt(len(p1_list))))\n",
    "print(\"Test Prec@1={}\".format(p1))\n",
    "# print(\"Test Recall@1=%f (%f)\" % (np.mean(r1_list), np.std(r1_list) / np.sqrt(len(r1_list))))\n",
    "# print(\"Test Recall@1={}\".format(np.mean(r1_list)))\n",
    "# print('F1@1', F1_score(p1, np.mean(r1_list)))\n",
    "\n",
    "print('Recall:', rec_1)\n",
    "print('F1@1', F1_score(p1, rec_1))\n",
    "\n",
    "# print(\"Test Prec@5=%f (%f)\" % (np.mean(p5_list), np.std(p5_list) / np.sqrt(len(p5_list))))\n",
    "print(\"Test Prec@5={}\".format(p5))\n",
    "# print(\"Test Recall@5=%f (%f)\" % (np.mean(r5_list), np.std(r5_list) / np.sqrt(len(r5_list))))\n",
    "# print(\"Test Recall@5={}\".format(np.mean(r5_list)))\n",
    "# print('F1@1', F1_score(p5, np.mean(r5_list)))\n",
    "print('Recall:', rec_5)\n",
    "print('F1@5', F1_score(p5, rec_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
