{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders for collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies the paper \"*Variational autoencoders for collaborative filtering*\" by Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara, in The Web Conference (aka WWW) 2018.\n",
    "\n",
    "In this notebook, we will show a complete self-contained example of training a variational autoencoder (as well as a denoising autoencoder) with multinomial likelihood (described in the paper) on the public Movielens-20M dataset, including both data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### change `DATA_DIR` to the location where movielens-20m dataset sits\n",
    "DATA_DIR = './'\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective for Multi-DAE for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
    "$$\n",
    "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiVAE(MultiDAE):\n",
    "\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "\n",
    "        # placeholders with default values when scoring\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        \n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # q-network\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "\n",
    "        sampled_z = mu_q + self.is_training_ph *\\\n",
    "            epsilon * std_q\n",
    "\n",
    "        # p-network\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        \n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        \n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                # we need two sets of parameters for mean and variance,\n",
    "                # respectively\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            \n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "unique_sid = list()\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)\n",
    "print(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = load_train_data(os.path.join(pro_dir, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vad_data_tr, vad_data_te = load_tr_te_data(os.path.join(pro_dir, 'validation_tr.csv'),\n",
    "                                           os.path.join(pro_dir, 'validation_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1282, 165)\n",
      "(150, 165) (150, 165)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(vad_data_tr.shape, vad_data_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "# training batch size\n",
    "batch_size = 500 #MRM=500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = range(N_vad)\n",
    "\n",
    "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
    "batch_size_vad = 50 #MRM=50 # 2000\n",
    "\n",
    "# the total number of gradient updates for annealing\n",
    "total_anneal_steps = 200000\n",
    "# largest annealing parameter\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0] # 150\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "    recall = tmp / X_true_binary.sum(axis=1)\n",
    "    rec = np.sum(tmp) / np.sum(X_true_binary.sum(axis=1))\n",
    "    return recall, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prec_at_k_batch(X_pred, heldout_batch, k=5):\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    \n",
    "#     prec = tmp / np.minimum(k, X_pred_binary.sum(axis=1))\n",
    "    prec = np.sum(tmp) / (batch_users * k)\n",
    "    return prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(X_pred,heldout_batch):\n",
    "    X_pred[X_pred == -np.inf] = -9999999999\n",
    "    batch_users = X_pred.shape[0]\n",
    "    X_true_binary = heldout_batch.toarray()\n",
    "    \n",
    "    total_prec = 0\n",
    "    for u in range(batch_users):\n",
    "        y_true = X_true_binary[u]\n",
    "        y_scores = X_pred[u]\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/batch_users\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Multi-VAE^{PR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_dims = [200, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-881e9e51e708>:41: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging and checkpoint directory\n",
    "\n",
    "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
    "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: ./volmount/log/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "log_dir = './volmount/log/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = './volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "    int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            \n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, \n",
    "                                           global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_tr, test_data_te = load_tr_te_data(\n",
    "    os.path.join(pro_dir, 'test_tr.csv'),\n",
    "    os.path.join(pro_dir, 'test_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_test = test_data_tr.shape[0] #150\n",
    "idxlist_test = range(N_test)\n",
    "\n",
    "batch_size_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:.0E}/{}'.format(\n",
    "#     int(total_anneal_steps/1000), anneal_cap, arch_str)\n",
    "# print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./volmount/chkpt/ml-20m/VAE_anneal200K_cap2E-01/I-600-200-600-I/model\n",
      "0 - 150\n",
      "X.shape: (150, 165)\n",
      "pred_val.shape: (150, 165)\n"
     ]
    }
   ],
   "source": [
    "n10_list = []\n",
    "r1_list, r5_list = [], []\n",
    "# p1_list, p5_list = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        print(st_idx, '-', end_idx)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "        print('X.shape:', X.shape) #(150, 165)\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        print('pred_val.shape:', pred_val.shape) #(150, 165)\n",
    "#         # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        \n",
    "        n10_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=10))\n",
    "        MAP = MAP(pred_val, test_data_te[idxlist_test[st_idx:end_idx]])\n",
    "\n",
    "#         p1_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        p1 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "#         r1_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1))\n",
    "        recall, rec_1 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=1)\n",
    "        r1_list.append(recall)\n",
    "        \n",
    "#         p5_list.append(Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        p5 = Prec_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "#         r5_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5))\n",
    "        recall, rec_5 = Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=5)\n",
    "        r5_list.append(recall)\n",
    "\n",
    "n10_list = np.concatenate(n10_list)\n",
    "\n",
    "# p1_list = np.concatenate(p1_list)\n",
    "r1_list = np.concatenate(r1_list)\n",
    "\n",
    "# p5_list = np.concatenate(p5_list)\n",
    "r5_list = np.concatenate(r5_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@10=0.4513467424376526\n",
      "Test MAP=0.39721683920703876\n",
      "Test Prec@1=0.52\n",
      "Recall: 0.0312625250501002\n",
      "F1@1 0.058979206049149344\n",
      "Test Prec@5=0.484\n",
      "Recall: 0.14549098196392785\n",
      "F1@5 0.22372881355932203\n"
     ]
    }
   ],
   "source": [
    "# print(\"Test NDCG@10=%f (%f)\" % (np.mean(n10_list), np.std(n10_list) / np.sqrt(len(n10_list))))\n",
    "print(\"Test NDCG@10={}\".format(np.mean(n10_list)))\n",
    "print(\"Test MAP={}\".format(MAP))\n",
    "# print(\"Test Prec@1=%f (%f)\" % (np.mean(p1_list), np.std(p1_list) / np.sqrt(len(p1_list))))\n",
    "print(\"Test Prec@1={}\".format(p1))\n",
    "# print(\"Test Recall@1=%f (%f)\" % (np.mean(r1_list), np.std(r1_list) / np.sqrt(len(r1_list))))\n",
    "# print(\"Test Recall@1={}\".format(np.mean(r1_list)))\n",
    "# print('F1@1', F1_score(p1, np.mean(r1_list)))\n",
    "\n",
    "print('Recall:', rec_1)\n",
    "print('F1@1', F1_score(p1, rec_1))\n",
    "\n",
    "# print(\"Test Prec@5=%f (%f)\" % (np.mean(p5_list), np.std(p5_list) / np.sqrt(len(p5_list))))\n",
    "print(\"Test Prec@5={}\".format(p5))\n",
    "# print(\"Test Recall@5=%f (%f)\" % (np.mean(r5_list), np.std(r5_list) / np.sqrt(len(r5_list))))\n",
    "# print(\"Test Recall@5={}\".format(np.mean(r5_list)))\n",
    "# print('F1@1', F1_score(p5, np.mean(r5_list)))\n",
    "print('Recall:', rec_5)\n",
    "print('F1@5', F1_score(p5, rec_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "def MAP(X_pred,heldout_batch, test_num = 32):\n",
    "    movie_num = X_pred.shape[1] # 165\n",
    "    print('Oringinal movie num:', movie_num)\n",
    "    movie_idx = [i for i in range(movie_num)]\n",
    "    \n",
    "    X_pred[X_pred == -np.inf] = -9999999999\n",
    "    batch_users = X_pred.shape[0] # 150\n",
    "    print('Oringinal user num:', batch_users)\n",
    "    \n",
    "    X_true_binary = heldout_batch.toarray()\n",
    "    \n",
    "    total_prec = 0\n",
    "    for u in range(batch_users):\n",
    "#         idx = random.sample([i for i in range(movie_num)], test_num)\n",
    "        y_true = X_true_binary[u]\n",
    "        half = int(sum(y_true)/2)\n",
    "        idx = random.sample(list(np.nonzero(y_true == 1)[0]), half)\n",
    "        if len(idx) != half:\n",
    "            print('Error!!!')\n",
    "            break\n",
    "        \n",
    "        if len(idx) < test_num:\n",
    "            rest = test_num - len(idx)\n",
    "            others = random.sample([i for i in movie_idx if not i in idx], rest)\n",
    "            idx.extend(others)\n",
    "        else:\n",
    "            idx = random.sample(idx, test_num)\n",
    "            \n",
    "        if not len(idx) == test_num:\n",
    "            print('Error!!!')\n",
    "            break\n",
    "            \n",
    "#         print(y_true.shape)\n",
    "        y_true = y_true[idx]\n",
    "#         print(y_true.shape)\n",
    "        y_scores = X_pred[u][idx]\n",
    "#         print(y_scores.shape)\n",
    "        total_prec += average_precision_score(y_true, y_scores)\n",
    "        \n",
    "    Map_value = total_prec/batch_users\n",
    "    \n",
    "    return Map_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCG(prec_list): #n[1,1,1,0,...]\n",
    "    dcg = 0\n",
    "    for i in range(len(prec_list)):\n",
    "        dcg += (2**prec_list[i]-1)/math.log2(i+2)\n",
    "    return dcg\n",
    "\n",
    "def NDCG(pred_val, true_matrix, num_ndcg): #test_truthUserpositiveitem\n",
    "    ndcg_ls = []\n",
    "    for u in range(pred_val.shape[0]):\n",
    "#         print('user:', u)\n",
    "        true = true_matrix[u]\n",
    "        score = pred_val[u]\n",
    "        \n",
    "        len_for_truth = sum(true)\n",
    "        target = [] #idcg list\n",
    "        for i in range(len(true)):\n",
    "            if i < len_for_truth:\n",
    "                target.append(1)\n",
    "            else:\n",
    "                target.append(0)\n",
    "#         print(sum(target), target)\n",
    "        \n",
    "        if not sum(target) == len_for_truth:\n",
    "            print('Error!!!')\n",
    "            break\n",
    "        \n",
    "        idcg = DCG(target[:num_ndcg])\n",
    "        \n",
    "        rank = list(np.argsort(score))\n",
    "        pre_list = np.zeros(len(score))\n",
    "        total = 0 # just for troubleshooting\n",
    "        for idx in range(len(rank)):\n",
    "            bi = true[idx]\n",
    "            r = rank[idx]\n",
    "            pre_list[r] = bi\n",
    "            \n",
    "            if r < num_ndcg and bi == 1: # just for troubleshooting\n",
    "                total += 1\n",
    "\n",
    "        if sum(pre_list) != len_for_truth:\n",
    "            print('sum(pre_list) not len_for_truth Error!!!')\n",
    "            break\n",
    "            \n",
    "        if not (total == sum(pre_list[:num_ndcg])):\n",
    "            print('total Error!!!')\n",
    "            break\n",
    "            \n",
    "        dcg = DCG(pre_list[:num_ndcg])\n",
    "        ndcg = dcg/idcg\n",
    "        ndcg_ls.append(ndcg)\n",
    "        \n",
    "#     print('len(ndcg_ls):', len(ndcg_ls)) #150\n",
    "    return np.mean(ndcg_ls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
