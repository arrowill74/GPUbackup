{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os \n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJson(name):\n",
    "    with open(name+'test_truth.json') as json_file:\n",
    "        test_truth = json.load(json_file)\n",
    "    with open(name+'test_rank.json') as json_file:\n",
    "        test_rank = json.load(json_file)\n",
    "    with open(name+'test_score.json') as json_file:\n",
    "        test_score = json.load(json_file)\n",
    "#         test_score = eval(test_score)\n",
    "    with open(name+'test_item.json') as json_file:\n",
    "        test_item = json.load(json_file)\n",
    "        \n",
    "#     print(type(test_truth), type(test_rank), type(test_score), type(test_item)) # all dict\n",
    "#     print(len(test_truth), len(test_rank), len(test_score), len(test_item)) # all 150\n",
    "    \n",
    "    return test_truth,test_rank,test_score,test_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCG(prec_list): #找出前n名的[1,1,1,0,...]\n",
    "    dcg = 0\n",
    "    for i in range(len(prec_list)):\n",
    "        dcg += (2**prec_list[i]-1)/math.log2(i+2)\n",
    "    return dcg\n",
    "\n",
    "def NDCG(test_truth, test_rank, num_ndcg): #test_truth是每位User真正positive的item\n",
    "    total_ndcg = 0\n",
    "\n",
    "    for user in test_truth.keys():\n",
    "#         print('user:', user)\n",
    "        user_truth = test_truth[user]\n",
    "        user_rank = test_rank[user]\n",
    "#         print(len(user_truth), user_truth)\n",
    "#         print(len(user_rank), user_rank)\n",
    "        if len(user_truth) >= 32:\n",
    "            print('Error!!!')\n",
    "            break\n",
    "        \n",
    "        if not len(user_rank) == 32:\n",
    "            print('Error!!!')\n",
    "            break\n",
    "        \n",
    "        len_for_truth = len(user_truth)\n",
    "        target = []\n",
    "        for i in range(len(user_rank)):\n",
    "            if i < len_for_truth:\n",
    "                target.append(1)\n",
    "            else:\n",
    "                target.append(0)\n",
    "#         print(sum(target), target)\n",
    "        \n",
    "        if not sum(target) == len_for_truth:\n",
    "            print('Error!!!')\n",
    "            break\n",
    "        \n",
    "        idcg = DCG(target[:num_ndcg])\n",
    "        \n",
    "        pre_list = []\n",
    "        for item in user_rank[:num_ndcg]:\n",
    "            if item in user_truth:\n",
    "                pre_list.append(1)\n",
    "            else:\n",
    "                pre_list.append(0)\n",
    "#         print('pre_list:', pre_list)\n",
    "        if sum(pre_list) > len_for_truth:\n",
    "            print('Error!!!')\n",
    "            break\n",
    "            \n",
    "        dcg = DCG(pre_list)\n",
    "        ndcg = dcg/idcg\n",
    "        total_ndcg += ndcg\n",
    "#         print('==================================================')\n",
    "    avg_ndcg = total_ndcg/len(test_truth)\n",
    "#     print('len(test_truth):', len(test_truth))\n",
    "    return avg_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def MAP(test_item, test_truth, test_score):\n",
    "    Map_value = []\n",
    "    for user in test_item.keys():\n",
    "#         print('user:', user)\n",
    "        user_item = test_item[user]\n",
    "        user_truth = test_truth[user]\n",
    "#         print('user_item:', user_item)\n",
    "#         print('user_truth:', user_truth)\n",
    "        if not len(user_item) == 32:\n",
    "            print('Error!!!')\n",
    "            break\n",
    "        \n",
    "        y_true = np.zeros(len(user_item))\n",
    "        for tp in user_truth:\n",
    "            y_true[user_item.index(tp)] = 1\n",
    "#         print('y_true:', y_true)\n",
    "        \n",
    "        y_scores = test_score[user]\n",
    "        Map_value.append(average_precision_score(y_true, y_scores))\n",
    "    \n",
    "#     print('len(test_truth):', len(Map_value),len(test_truth))\n",
    "    return np.mean(Map_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(prec,rec):\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "    return f1\n",
    "\n",
    "def topN(test_rank, test_truth, n):\n",
    "    print('Top', n)\n",
    "    sumtarget = 0\n",
    "    correct = 0\n",
    "    for user in test_rank.keys():\n",
    "#         print('user:', user)\n",
    "        user_rank = test_rank[user]\n",
    "        user_truth = test_truth[user]\n",
    "        if not len(user_rank) == 32:\n",
    "            print('Error!!!')\n",
    "            break\n",
    "            \n",
    "        pos = np.zeros(len(user_rank))\n",
    "        for tp in user_truth:\n",
    "            pos[user_rank.index(tp)] = 1\n",
    "#         print('pos:', pos)\n",
    "#         print('sum(pos[:n]):',sum(pos[:n]))\n",
    "        correct += sum(pos[:n])\n",
    "        sumtarget += len(user_truth)\n",
    "#         print('len(user_truth):', len(user_truth))\n",
    "\n",
    "    print('correct:', correct) \n",
    "    print('sumtarget:', sumtarget)\n",
    "    prec = correct/(len(test_rank)*n) #150*n\n",
    "    recall = correct/sumtarget\n",
    "\n",
    "    print('prec:', prec)\n",
    "    print('recall:', recall)\n",
    "    print('F1_score:', F1_score(prec, recall))\n",
    "    print('*****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "NDCG@10: 0.5291227070395198\n",
      "MAP: 0.44294631023012415\n",
      "Top 1\n",
      "correct: 77.0\n",
      "sumtarget: 1078\n",
      "prec: 0.5133333333333333\n",
      "recall: 0.07142857142857142\n",
      "F1_score: 0.1254071661237785\n",
      "*****\n",
      "Top 5\n",
      "correct: 335.0\n",
      "sumtarget: 1078\n",
      "prec: 0.44666666666666666\n",
      "recall: 0.310760667903525\n",
      "F1_score: 0.3665207877461707\n",
      "*****\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#nameList = ['','ColdU','ColdY']\n",
    "nameList = ['']#,'ColdY', 'ColdU']\n",
    "num_of_y_test = 32\n",
    "for name in nameList:\n",
    "    test_truth,test_rank,test_score,test_item = getJson(name)\n",
    "    print('Name:',name)\n",
    "    print('NDCG@10:', NDCG(test_truth, test_rank, 10))\n",
    "    print('MAP:', MAP(test_item, test_truth, test_score))\n",
    "    topN(test_rank, test_truth, 1)\n",
    "    topN(test_rank, test_truth, 5)\n",
    "    print('==================================================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
