{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN in keras with pretrained word2vec weights\n",
    "https://www.kaggle.com/marijakekic/cnn-in-keras-with-pretrained-word2vec-weights/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def writeProgress(msg, count, total):\n",
    "    sys.stdout.write(msg + \"{:.2%}\\r\".format(count/total))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def newPath(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "def read_json(src_path):\n",
    "    with open(src_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "\n",
    "def write_json(data,dst_path):\n",
    "    with open(dst_path, 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery', 'Romance', 'Sci-Fi', 'Sport', 'Thriller', 'War', 'Western']\n"
     ]
    }
   ],
   "source": [
    "columns = read_json('../orderdListGenres.json')\n",
    "print(len(columns), columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562\n"
     ]
    }
   ],
   "source": [
    "data = read_json('./input/mergeGenresMat.json')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_IG=pd.read_csv('./stopword/train_IG.csv')\n",
    "train_data_IG = train_data_IG.dropna()\n",
    "train_data_IG = train_data_IG.reset_index(drop=True)\n",
    "# train_data_IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_imdb=pd.read_csv('./stopword/train_imdb.csv')\n",
    "train_data_imdb = train_data_imdb.dropna()\n",
    "train_data_imdb = train_data_imdb.reset_index(drop=True)\n",
    "train_data_imdb = train_data_imdb.rename(columns={'tconst':'username'})\n",
    "# train_data_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>convert_text</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47metersdown</td>\n",
       "      <td>catch meters uncaged spot last night nbafinals...</td>\n",
       "      <td>['Adventure', 'Drama', 'Horror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47metersdown</td>\n",
       "      <td>know swims beneath deep meters uncaged comes t...</td>\n",
       "      <td>['Adventure', 'Drama', 'Horror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47metersdown</td>\n",
       "      <td>stay alive meters uncaged theaters nationwide ...</td>\n",
       "      <td>['Adventure', 'Drama', 'Horror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47metersdown</td>\n",
       "      <td>take bite summer takes bite meters uncaged dev...</td>\n",
       "      <td>['Adventure', 'Drama', 'Horror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47metersdown</td>\n",
       "      <td>upside irl sharkbait</td>\n",
       "      <td>['Adventure', 'Drama', 'Horror']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11735</th>\n",
       "      <td>tt5189828</td>\n",
       "      <td>late war young mohawk woman two lovers battle ...</td>\n",
       "      <td>Action,Drama,History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11736</th>\n",
       "      <td>tt6334884</td>\n",
       "      <td>legendary lawman gunslinger wild bill hickok t...</td>\n",
       "      <td>Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11737</th>\n",
       "      <td>tt6243274</td>\n",
       "      <td>tough nonsense marine vet alden rockwell lost ...</td>\n",
       "      <td>Action,Drama,Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11738</th>\n",
       "      <td>tt6217608</td>\n",
       "      <td>suffering near fatal head injury young cowboy ...</td>\n",
       "      <td>Drama,Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11739</th>\n",
       "      <td>tt5862542</td>\n",
       "      <td>return zion ranch allegorical story israel set...</td>\n",
       "      <td>Western</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11740 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           username                                       convert_text  \\\n",
       "0      47metersdown  catch meters uncaged spot last night nbafinals...   \n",
       "1      47metersdown  know swims beneath deep meters uncaged comes t...   \n",
       "2      47metersdown  stay alive meters uncaged theaters nationwide ...   \n",
       "3      47metersdown  take bite summer takes bite meters uncaged dev...   \n",
       "4      47metersdown                               upside irl sharkbait   \n",
       "...             ...                                                ...   \n",
       "11735     tt5189828  late war young mohawk woman two lovers battle ...   \n",
       "11736     tt6334884  legendary lawman gunslinger wild bill hickok t...   \n",
       "11737     tt6243274  tough nonsense marine vet alden rockwell lost ...   \n",
       "11738     tt6217608  suffering near fatal head injury young cowboy ...   \n",
       "11739     tt5862542  return zion ranch allegorical story israel set...   \n",
       "\n",
       "                                 genres  \n",
       "0      ['Adventure', 'Drama', 'Horror']  \n",
       "1      ['Adventure', 'Drama', 'Horror']  \n",
       "2      ['Adventure', 'Drama', 'Horror']  \n",
       "3      ['Adventure', 'Drama', 'Horror']  \n",
       "4      ['Adventure', 'Drama', 'Horror']  \n",
       "...                                 ...  \n",
       "11735              Action,Drama,History  \n",
       "11736                           Western  \n",
       "11737              Action,Drama,Western  \n",
       "11738                     Drama,Western  \n",
       "11739                           Western  \n",
       "\n",
       "[11740 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.concat([train_data_IG, train_data_imdb],ignore_index=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>convert_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47metersdown</td>\n",
       "      <td>four teen girls diving ruined underwater city ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adogsjourneymovie</td>\n",
       "      <td>dog finds meaning existence lives humans meets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aftermathmovie</td>\n",
       "      <td>post world war ii british colonel wife assigne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aftermovie</td>\n",
       "      <td>young woman falls guy dark secret two embark r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alitamovie</td>\n",
       "      <td>deactivated cyborg revived remember anything p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>usmovie</td>\n",
       "      <td>family serene beach vacation turns chaos doppe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>whatmenwant</td>\n",
       "      <td>woman boxed male sports agents profession gain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>wonderparkmovie</td>\n",
       "      <td>wonder park tells story amusement park imagina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>xmenmovies</td>\n",
       "      <td>jean grey begins develop incredible powers cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>yesterdaymovie</td>\n",
       "      <td>struggling musician realizes person earth reme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             username                                       convert_text\n",
       "0        47metersdown  four teen girls diving ruined underwater city ...\n",
       "1   adogsjourneymovie     dog finds meaning existence lives humans meets\n",
       "2      aftermathmovie  post world war ii british colonel wife assigne...\n",
       "3          aftermovie  young woman falls guy dark secret two embark r...\n",
       "4          alitamovie  deactivated cyborg revived remember anything p...\n",
       "..                ...                                                ...\n",
       "92            usmovie  family serene beach vacation turns chaos doppe...\n",
       "93        whatmenwant  woman boxed male sports agents profession gain...\n",
       "94    wonderparkmovie  wonder park tells story amusement park imagina...\n",
       "95         xmenmovies  jean grey begins develop incredible powers cor...\n",
       "96     yesterdaymovie  struggling musician realizes person earth reme...\n",
       "\n",
       "[97 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('./stopword/test.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11740, 3) (97, 2)\n",
      "username        0\n",
      "convert_text    0\n",
      "genres          0\n",
      "dtype: int64\n",
      "username        0\n",
      "convert_text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape,test_data.shape)\n",
    "print(train_data.isnull().sum())\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11740 11740\n"
     ]
    }
   ],
   "source": [
    "ids = train_data['username'].tolist()\n",
    "texts = train_data['convert_text'].tolist()\n",
    "print(len(ids), len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11740"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [data[id] for id in ids]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9392, 3) (2348, 3)\n"
     ]
    }
   ],
   "source": [
    "val_data=train_data.sample(frac=0.2,random_state=42)\n",
    "train_data= train_data.drop(val_data.index)\n",
    "print(train_data.shape, val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tonylab/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train_data.convert_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18046 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS=30000\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS,filters='—!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'',\n",
    "                      lower=True)\n",
    "\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(word_index.items(), key=lambda d: d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X train and X validation tensor: (9392, 330) (2348, 330)\n",
      "Shape of label train and validation tensor: (9392, 20) (2348, 20)\n"
     ]
    }
   ],
   "source": [
    "sequences_train = tokenizer.texts_to_sequences(texts)\n",
    "sequences_valid = tokenizer.texts_to_sequences(val_data.convert_text)\n",
    "\n",
    "X_train = pad_sequences(sequences_train)\n",
    "X_val = pad_sequences(sequences_valid,maxlen=X_train.shape[1])\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "y_train = np.asarray(labels[train_data.index.values])\n",
    "y_val = np.asarray(labels[val_data.index.values])\n",
    "\n",
    "print('Shape of X train and X validation tensor:', X_train.shape,X_val.shape)\n",
    "print('Shape of label train and validation tensor:', y_train.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "outOfDict = []\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format('./model/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "EMBEDDING_DIM=300\n",
    "vocabulary_size=min(len(word_index)+1,NUM_WORDS)\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i>=NUM_WORDS:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n",
    "        outOfDict.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(outOfDict, 'unstemmed_outOfDict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(word_vectors)\n",
    "\n",
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(vocabulary_size,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 儲存路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = 'merge_stride6'\n",
    "HISTORY_SAVE = './history/' + SAVE_NAME + '.csv'\n",
    "WEIGHTS_SAVE = './weight/' + SAVE_NAME + '.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPooling2D, Dropout,concatenate\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "sequence_length = X_train.shape[1]\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 100\n",
    "drop = 0.5\n",
    "stride = 6\n",
    "\n",
    "inputs = Input(shape=(sequence_length,))\n",
    "embedding = embedding_layer(inputs)\n",
    "reshape = Reshape((sequence_length,EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, (filter_sizes[0], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "conv_1 = Conv2D(num_filters, (filter_sizes[1], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "conv_2 = Conv2D(num_filters, (filter_sizes[2], EMBEDDING_DIM),activation='relu',kernel_regularizer=regularizers.l2(0.01))(reshape)\n",
    "\n",
    "maxpool_0 = MaxPooling2D((sequence_length - filter_sizes[0] + 1, 1), strides=(stride,1))(conv_0)\n",
    "maxpool_1 = MaxPooling2D((sequence_length - filter_sizes[1] + 1, 1), strides=(stride,1))(conv_1)\n",
    "maxpool_2 = MaxPooling2D((sequence_length - filter_sizes[2] + 1, 1), strides=(stride,1))(conv_2)\n",
    "\n",
    "merged_tensor = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1)\n",
    "flatten = Flatten()(merged_tensor)\n",
    "reshape = Reshape((3*num_filters,))(flatten)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "output = Dense(units=20, activation='sigmoid',kernel_regularizer=regularizers.l2(0.01))(dropout)\n",
    "\n",
    "# this creates a model that includes\n",
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-3)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['acc'])\n",
    "callbacks = [EarlyStopping(monitor='val_loss')]\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1, validation_data=(X_val, y_val), callbacks=callbacks)  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights\n",
    "model.save(WEIGHTS_SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "his_df = pd.DataFrame(data = {\n",
    "    'Epoch' : epochs,\n",
    "    'Loss' : loss,\n",
    "    'Acc' : acc,\n",
    "    'Val_loss' : val_loss,\n",
    "    'Val_acc' : val_acc\n",
    "})\n",
    "his_df = his_df[['Epoch', 'Loss', 'Acc', 'Val_loss', 'Val_acc']]\n",
    "his_df.to_csv(HISTORY_SAVE, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製結果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequences_test=tokenizer.texts_to_sequences(test_data.convert_text)\n",
    "X_test = pad_sequences(sequences_test,maxlen=X_train.shape[1])\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pred #pred_bool.astype(int)\n",
    "\n",
    "results=pd.DataFrame(predictions, columns=columns)\n",
    "results[\"username\"] = test_data.username\n",
    "ordered_cols = [\"username\"] + columns\n",
    "results = results[ordered_cols] #To get the same column order\n",
    "results.to_csv(\"./output/\"+ SAVE_NAME + \"_result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label top n dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_df = pd.read_csv('./input/true_df.csv')\n",
    "true_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"./output/\"+ SAVE_NAME + \"_result.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = read_json('../genresDic.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countAcc(predList, trueList):\n",
    "    fraction = 0\n",
    "    denominator = len(trueList)\n",
    "    for g in predList:\n",
    "        if g in trueList:\n",
    "            fraction += 1 \n",
    "    return fraction / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for i, row in true_df.iterrows():\n",
    "    username = row['username']\n",
    "    if username == results.loc[i,:]['username']: # username equals\n",
    "        print(i, username)\n",
    "        truth = labels[username]\n",
    "        numTrue = sum(row[1:])\n",
    "        print('count:', numTrue)\n",
    "        \n",
    "        s = results.loc[i,:][1:]\n",
    "        top_n = s.sort_values(ascending=False)[:numTrue]\n",
    "        inList = list(top_n.index)\n",
    "        \n",
    "        onehot = []\n",
    "        for g in columns:\n",
    "            onehot.append(int(g in inList))\n",
    "            \n",
    "        acc = countAcc(inList, truth)\n",
    "        print(acc, inList, truth)\n",
    "        \n",
    "        appList = [username, acc, truth, inList] + onehot\n",
    "        li.append(appList)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame(li, columns = ['username', 'acc', 'truth', 'top_n'] + columns)\n",
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df.to_csv(\"./output/\"+ SAVE_NAME + \"_bi.csv\", index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df['acc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "## 測試reload model準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_LOAD = './weight/merge_stride4.h5'\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(WEIGHTS_LOAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test=tokenizer.texts_to_sequences(test_data.convert_text)\n",
    "X_test = pad_sequences(sequences_test,maxlen=X_train.shape[1])\n",
    "pred = model.predict(X_test)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pred\n",
    "\n",
    "results=pd.DataFrame(predictions, columns=columns)\n",
    "results[\"username\"] = test_data.username\n",
    "ordered_cols = [\"username\"] + columns\n",
    "results = results[ordered_cols] #To get the same column order\n",
    "results.to_csv(\"./output/\"+ SAVE_NAME + \"_result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = read_json('../genresDic.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for i, row in true_df.iterrows():\n",
    "    username = row['username']\n",
    "    if username == results.loc[i,:]['username']: # username equals\n",
    "        print(i, username)\n",
    "        truth = labels[username]\n",
    "        numTrue = sum(row[1:])\n",
    "        print('count:', numTrue)\n",
    "        \n",
    "        s = results.loc[i,:][1:]\n",
    "        top_n = s.sort_values(ascending=False)[:numTrue]\n",
    "        inList = list(top_n.index)\n",
    "        \n",
    "        onehot = []\n",
    "        for g in columns:\n",
    "            onehot.append(int(g in inList))\n",
    "            \n",
    "        acc = countAcc(inList, truth)\n",
    "        print(acc, inList, truth)\n",
    "        \n",
    "        appList = [username, acc, truth, inList] + onehot\n",
    "        li.append(appList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame(li, columns = ['username', 'acc', 'truth', 'top_n'] + columns)\n",
    "acc_df['acc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 萃取97部電影imdb的feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_layer = Model(inputs=model.input,\n",
    "                      outputs=model.get_layer('flatten_4').output)\n",
    "#以这个model的预测值作为输出\n",
    "extract_output = extract_layer.predict(X_test)\n",
    "print(extract_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = test_data.username.tolist()\n",
    "print(len(idx), idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res=pd.DataFrame(extract_output, index = idx)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"./output/TextFeatureVec.csv\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
